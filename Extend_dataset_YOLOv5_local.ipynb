{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled37.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GO extend dataset YOLOv5**"
      ],
      "metadata": {
        "id": "LXR--60tO5mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "id": "SKQDA3lPUISE",
        "outputId": "dbff6a39-5a96-45c7-f0d3-53c58181275f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.8\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.backends.mps.is_available()"
      ],
      "metadata": {
        "id": "ZEhRCqfkjIID",
        "outputId": "1e9e3ae3-9499-41d6-abfa-6be80c0c0f11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xvbecME5IS",
        "outputId": "3bbef9cb-db57-4864-f074-25cf66c642e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from random import randint\n",
        "from time import sleep\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "plt.ion()   # interactive mode\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zsh:1: command not found: nvidia-smi\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZI4pHmFDXZ"
      },
      "source": [
        "#Google colabã‚’ãƒã‚¦ãƒ³ãƒˆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrhEditFGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d54eae3-95b6-4894-fb17-e80a1d51cf5a"
      },
      "source": [
        "# '''\n",
        "# ãƒ»dlibã‚’ç”¨ã„ã¦ç›®ã‚’åˆ‡ã‚ŠæŠœã\n",
        "# ãƒ»æ¨ªå¹…ã‚’2å€ã€ç¸¦å¹…ã‚’ä¸Šã«1å€è¿½åŠ /ä¸‹ã«0.5å€è¿½åŠ ã—ãŸä¸¡çœ¼ã®ç”»åƒãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«åˆ‡ã‚Šå–ã‚‹ï¼ˆç›®ã®å…¨å¹…ã€çœ‰æ¯›ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n",
        "# '''\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7fAuwXxNka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b61f93e-06c4-4d0d-c769-76c7938a97f3"
      },
      "source": [
        "#æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ®‹ã‚Šæ™‚é–“ : 11.61"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSA2Rm9MFXoZ"
      },
      "source": [
        "#ãƒ†ã‚¹ãƒˆç”»åƒ\n",
        "test_path = '/content/drive/MyDrive/Deep_learning/Face_Images/IMG_3110.JPG'\n",
        "\n",
        "# GO_extended_datasetã‚’ colabä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€ã«å±•é–‹\n",
        "zip_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip'\n",
        "!unzip $zip_path -d \"/content\"\n",
        "in_path_list  = ['/content/GO_extended_dataset/Control_photo_1886mai', '/content/GO_extended_dataset/treatable']\n",
        "#ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_path_list = ['/content/GO_extended_dataset/cont_for_yolo', '/content/GO_extended_dataset/grav_for_yolo']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2mKFMmwfTOi"
      },
      "source": [
        "#é¡”ã®ç”»åƒã‹ã‚‰ç›®ã‚’æ¤œå‡ºã—ã¦åˆ‡ã‚ŠæŠœãã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n",
        "ãƒ»Haarcascade_eyeã‚’ä½¿ç”¨<br>\n",
        "ãƒ»ç›®ãŒæ¤œå‡ºã§ããªã„ã‚‚ã®ã¯skipã™ã‚‹<br>\n",
        "ãƒ»æ¨ªå¹…ã‚’1/4å€ã€ç¸¦å¹…ã‚’ä¸Šä¸‹ã«1/4å€è¿½åŠ ã—ã¦ç”»åƒã‚’åˆ‡ã‚Šå–ã‚‹ï¼ˆç›®ã®å…¨å¹…ã€çœ‰æ¯›ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n",
        "\n",
        "ãƒ»åˆ‡ã‚Šå–ã£ãŸç”»åƒã‚’æ¨ªå¹…640pxã«resizeã™ã‚‹<br>\n",
        "ãƒ»ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã‚’ä¸€æ‹¬å¤‰æ›ã—ã¦åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0shkziUPn1c"
      },
      "source": [
        "#Haarcascadeã‚’æŒ‡å®š"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfu_RX-kIlmx"
      },
      "source": [
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "# righteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_righteye_2splits.xml'\n",
        "# lefteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_lefteye_2splits.xml'\n",
        "\n",
        "\n",
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ†é¡å™¨ã®ç‰¹å¾´é‡å–å¾—\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# righteye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# lefteye_cascade = cv2.CascadeClassifier(eye_cascade_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãŸã¾ã¾æ¨ªã‚’400pixelã«ç¸®å°ã™ã‚‹\n",
        "def scale_to_width(img, width):\n",
        "    scale = width / img.shape[1]\n",
        "    return cv2.resize(img, dsize=None, fx=scale, fy=scale)\n",
        "\n",
        "#å›³ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "def show_image(img):\n",
        "    #img = cv2.imread(out_path)\n",
        "    dst = scale_to_width(img, 200)\n",
        "    cv2_imshow(dst)\n",
        "\n",
        "# def show_image_pillow(img):\n",
        "#     src = cv2.cvtColor(img_resized_list[0], cv2.COLOR_BGR2RGB)\n",
        "#     plt.imshow(src)\n",
        "\n",
        "def my_round(val, digit=0):\n",
        "    p = 10 ** digit\n",
        "    return int((val * p * 2 + 1) // 2 / p)\n",
        "\n",
        "def scale_to_width(img, width):\n",
        "    \"\"\"å¹…ãŒæŒ‡å®šã—ãŸå€¤ã«ãªã‚‹ã‚ˆã†ã«ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’å›ºå®šã—ã¦ã€ãƒªã‚µã‚¤ã‚ºã™ã‚‹ã€‚\n",
        "    \"\"\"\n",
        "    h, w = img.shape[:2]\n",
        "    height = round(h * (width / w))\n",
        "    dst = cv2.resize(img, dsize=(width, height))\n",
        "\n",
        "    return dst"
      ],
      "metadata": {
        "id": "SMbQsnPTHf-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_bilateral(in_path, class_num, size, showImage=True):\n",
        "    img_resized_list,side_list = [],[]\n",
        "\n",
        "    img = cv2.imread(in_path) \n",
        "    img2 = img.copy()\n",
        "\n",
        "    if showImage:\n",
        "        show_image(img)\n",
        "\n",
        "    # ç”»åƒã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–\n",
        "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    #300pixä»¥ä¸Šã®ã‚‚ã®ã§ç›®ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚’æŠ½å‡º\n",
        "    eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "    print(\"\")\n",
        "    print('image path = ',in_path)\n",
        "\n",
        "    # çœ¼æ¤œå‡ºåˆ¤å®š\n",
        "    if len(eye_list) >= 1:\n",
        "        print('ç›®ãŒ' + str(len(eye_list)) +'å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸ')\n",
        "        pass\n",
        "    else:\n",
        "        print(\"no eye detected\")\n",
        "        pass\n",
        "\n",
        "    print(f\"eye_list: {eye_list}\")\n",
        "\n",
        "    #ç”»åƒã®åˆ‡ã‚ŠæŠœãã¨ä¿å­˜ï¼ˆé€£ç•ªã«ã™ã‚‹ï¼‰\n",
        "    if len(eye_list)== 2: \n",
        "\n",
        "        \n",
        "        for (ex, ey, ew, eh) in eye_list:\n",
        "            print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "            \n",
        "            try:\n",
        "                cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "                #åˆ‡ã‚ŠæŠœãç¯„å›²ãŒå…ƒç”»åƒã‚’ã¯ã¿å‡ºã‚‹å ´åˆã¯é»’ç”»åƒã§åŸ‹ã‚ã‚‹\n",
        "                top = max(0, ey-int(eh/4))\n",
        "                bottom = min(grayscale_img.shape[0], int(ey + eh*5/4))\n",
        "                left = max(0,int(ex-int(ew/4)))\n",
        "                right = min(grayscale_img.shape[1], int(ex + ew*5/4))\n",
        "\n",
        "                #print(f\"top:{top}, bottom:{bottom}, left:{left}, right:{right}\")\n",
        "\n",
        "                img_cropped = img[top: bottom,left:right]\n",
        "                height, width = img_cropped.shape[:2]\n",
        "\n",
        "                #ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã‚’è¡¨ç¤º\n",
        "                if showImage:\n",
        "                    show_image(img_cropped)\n",
        "            except: \n",
        "                pass\n",
        "\n",
        "       \n",
        "        ex = min(eye_list[0][0], eye_list[1][0])\n",
        "        ey = min(eye_list[0][1], eye_list[1][1])\n",
        "        ew = max(eye_list[0][0]+eye_list[0][2], eye_list[1][0]+eye_list[1][2]) - ex\n",
        "        eh = max(eye_list[0][1]+eye_list[0][3], eye_list[1][1]+eye_list[1][3]) - ey\n",
        "\n",
        "        print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "\n",
        "        try:\n",
        "            cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "            #åˆ‡ã‚ŠæŠœãç¯„å›²ãŒå…ƒç”»åƒã‚’ã¯ã¿å‡ºã‚‹å ´åˆã¯é»’ç”»åƒã§åŸ‹ã‚ã‚‹\n",
        "            top = max(0, int(ey-eh/4))\n",
        "            bottom = min(grayscale_img.shape[0], int(ey+7/6*eh))\n",
        "            left = max(0,int(ex-ew/10))\n",
        "            right = min(grayscale_img.shape[1], int(ex + 11/10*ew))\n",
        "\n",
        "            print(f\"top:{top}, bottom:{bottom}, left:{left}, right:{right}\")\n",
        "\n",
        "            img_cropped = img[top: bottom,left:right]\n",
        "            height, width = img_cropped.shape[:2]\n",
        "\n",
        "            img_resized = scale_to_width(img_cropped, size) #1è¾ºã‚’æŒ‡å®šã—ãŸpixã«resize \n",
        "\n",
        "            #ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã‚’è¡¨ç¤º\n",
        "            if showImage:\n",
        "                show_image(img_resized)\n",
        "            print(img2.shape)\n",
        "\n",
        "            #ç¸¦ã€æ¨ªã«å¯¾ã™ã‚‹å‰²åˆ\n",
        "            X = round((right+left)/2/img2.shape[1], 6)\n",
        "            Y = round((top+bottom)/2/img2.shape[0], 6)\n",
        "            W = round((right-left)/img.shape[1], 6)\n",
        "            H = round((bottom-top)/img.shape[0], 6)\n",
        "            txt = f\"{class_num} {X} {Y} {W} {H}\"\n",
        "            return img_resized, txt\n",
        "\n",
        "        except:\n",
        "            print('crop error')\n"
      ],
      "metadata": {
        "id": "aR56JrxipDoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, txt = crop_bilateral(test_path, class_num=0, size=640)\n",
        "print(txt)\n",
        "\n",
        "with open(\"test.txt\", mode='w') as f:\n",
        "    f.write(txt)\n",
        "\n",
        "\n",
        "# #æ¤œå‡ºã•ã‚ŒãŸç”»åƒã‚’ç¢ºèª\n",
        "# src = cv2.cvtColor(img_resized_list[0], cv2.COLOR_BGR2RGB)\n",
        "# plt.imshow(src)\n"
      ],
      "metadata": {
        "id": "sQkblQvvgl9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Aquisition of bounding boxes**\n",
        "\n",
        "ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"
      ],
      "metadata": {
        "id": "Z8R1kiD9lU-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# orig_folder = \"/content/GO_extended_dataset/Control_photo_1886mai\" \n",
        "# dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/cont\"\n",
        "# class_num = 0 #classã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ›¸ãè¾¼ã‚€(0:cont, 1:grav)\n",
        "\n",
        "\n",
        "orig_folder = \"/content/GO_extended_dataset/treatable\" \n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/grav\"\n",
        "class_num = 1 #classã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ›¸ãè¾¼ã‚€(0:cont, 1:grav)\n",
        "\n",
        "path_list = glob.glob(orig_folder+\"/*\")\n",
        "path = path_list[1]\n",
        "path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8gIkLcQWmH9d",
        "outputId": "2288c940-9d4d-4fdd-b40a-fe9376e67bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GO_extended_dataset/treatable/5906-20190509-75-102501_1b7f8b82f6c7c4a016f4dae73d0c91cc3e05404f4cdd6eca55b2b48e4dba2c08.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = glob.glob(orig_folder+\"/*\")\n",
        "#path_list = [path_list[0]] #ãƒ†ã‚¹ãƒˆç”¨\n",
        "dst_folder = dst_folder\n",
        "\n",
        "#å‡¦ç†æ™‚é–“ã®è¨ˆæ¸¬\n",
        "start = time.time()\n",
        "\n",
        "#ã‚‚ã—dst_folderãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦æ–°ã—ãä½œã‚Šç›´ã™\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "os.makedirs(f\"{dst_folder}/images\") #imageæ ¼ç´ç”¨\n",
        "os.makedirs(f\"{dst_folder}/images_cropped\") #cropped_imageæ ¼ç´ç”¨ (YOLOã§ã¯ä½¿ç”¨ã—ãªã„)\n",
        "os.makedirs(f\"{dst_folder}/labels\") #labelæ ¼ç´ç”¨\n",
        "\n",
        "\n",
        "num=0\n",
        "for path in path_list:\n",
        "    try: #ç›®ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼å›é¿\n",
        "        img, txt = crop_bilateral(path, class_num=class_num, size=640, showImage=False)  #ä¸¡çœ¼æŠœãå‡ºã—ã¦640pxã§ä¿å­˜ï¼ˆcropæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã‚‚ã®ã¯å‰Šé™¤ã•ã‚Œã‚‹ï¼‰\n",
        "        img2 = cv2.imread(path).copy()\n",
        "        img2 = scale_to_width(img2, 640)  #åˆ‡ã‚ŠæŠœãå‰ã®ç”»åƒã‚’æ¨ªã®ã‚µã‚¤ã‚ºã‚’640ã«ãªã‚‹ã‚ˆã†ã«ç¸®å°\n",
        "        cv2.imwrite(f\"{dst_folder}/images/{os.path.basename(path).split('.')[0]}.JPG\", img2) #cropã›ãšã«ç¸®å°ã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¿å­˜\n",
        "        cv2.imwrite(f\"{dst_folder}/images_cropped/{os.path.basename(path).split('.')[0]}.JPG\", img) #cropã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹å ´åˆ\n",
        "\n",
        "        with open(f\"{dst_folder}/labels/{os.path.basename(path).split('.')[0]}.txt\", mode='w') as f:\n",
        "            f.write(txt)\n",
        "        num+=1\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"\")\n",
        "print('Process done!!')\n",
        "elapsed_time = time.time() - start\n",
        "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
        "print (f\"image_num:{num}\")\n"
      ],
      "metadata": {
        "id": "R8k494hphZs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLO_v5 trainingç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ**\n",
        "\n",
        "datasetã‚’trainã¨valã«åˆ†ã‘ã‚‹\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/\n",
        "\n"
      ],
      "metadata": {
        "id": "VPi74ZCZrVDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "-----dataset-----train-----images\n",
        "              |         |--labels \n",
        "              |--valid-----images\n",
        "              |         |--labels\n",
        "              |--dataset.yaml\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YiuPobEMYWKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "random_seed = 0\n",
        "\n",
        "dataset_dir = \"/Users/kitaguchi/Dataset/periocular_for_YOLO\"\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testã«åå‰ãŒä¸€è‡´ã™ã‚‹txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠœãå‡ºã™\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "    \n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n"
      ],
      "metadata": {
        "id": "hHiTlYEnLx_u",
        "outputId": "8708cb20-823a-4166-a86e-72beac506c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_train: 2649\n",
            "img_val: 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kfolds\n",
        "num_folds = 5 #number of folds\n",
        "\n",
        "img_train, img_val, label_train, label_val =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "img_train, img_val, label_train, label_val =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(cont_image_list):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(cont_image_list[idx])\n",
        "        label_train[i].append(cont_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(cont_image_list[idx])\n",
        "        label_val[i].append(cont_label_list[idx])    \n",
        "    i+=1\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(grav_image_list):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(grav_image_list[idx])\n",
        "        label_train[i].append(grav_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(grav_image_list[idx])\n",
        "        label_val[i].append(grav_label_list[idx])    \n",
        "    i+=1\n",
        "\n",
        "print(f\"img_train: {len(img_train[0])}\")    \n",
        "print(f\"img_val: {len(img_val[0])}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UigMHCDcRwiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupKfolds\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "img_train, img_val, label_train, label_val =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(cont_image_list, groups=cont_id_idx):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(cont_image_list[idx])\n",
        "        label_train[i].append(cont_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(cont_image_list[idx])\n",
        "        label_val[i].append(cont_label_list[idx])    \n",
        "    i+=1\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(grav_image_list, groups=grav_id_idx):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(grav_image_list[idx])\n",
        "        label_train[i].append(grav_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(grav_image_list[idx])\n",
        "        label_val[i].append(grav_label_list[idx])    \n",
        "    i+=1\n",
        "\n",
        "print(f\"img_train: {len(img_train[0])}\")    \n",
        "print(f\"img_val: {len(img_val[0])}\")\n"
      ],
      "metadata": {
        "id": "CTnrkwkfQocv",
        "outputId": "11a907f2-8f99-4daa-96fa-519685d33471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_train: 2649\n",
            "img_val: 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv5ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨\n",
        "#ã‚‚ã—dst_folderãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦æ–°ã—ãä½œã‚Šç›´ã™\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\"\n",
        "\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "for i in [\"train\", \"valid\"]:\n",
        "    for j in [\"images\", \"labels\"]:\n",
        "        os.makedirs(f\"{dst_folder}/{i}/{j}\")\n",
        "        #os.makedirs(f\"{dst_folder}/labels\")\n",
        "\n",
        "for file in img_train_grav:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/images/{os.path.basename(file)}\")\n",
        "for file in img_train_cont:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/images/{os.path.basename(file)}\")\n",
        "for file in img_test_grav:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/images/{os.path.basename(file)}\")\n",
        "for file in img_test_cont:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/images/{os.path.basename(file)}\")\n",
        "for file in label_train_grav:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/labels/{os.path.basename(file)}\")\n",
        "for file in label_train_grav:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/labels/{os.path.basename(file)}\")            \n",
        "for file in label_test_cont:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/labels/{os.path.basename(file)}\")\n",
        "for file in label_test_cont:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/labels/{os.path.basename(file)}\") \n",
        "\n"
      ],
      "metadata": {
        "id": "lKe9k8SirUGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAUdjy9A0YZw",
        "outputId": "b061dbdd-c2cf-4095-a235-e5ea1e606a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # classåã‚’å®šç¾©"
      ],
      "metadata": {
        "id": "giDFflceMi9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52db6d4b-b48f-4a67-ed30-aca6118c3be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "cdEoEk_996YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjV_xXLpd5__",
        "outputId": "69cb5412-7a0b-48e8-c03d-c5d87cc7f532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (4 CPUs, 25.5 GB RAM, 23.6/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train YOLOv5**"
      ],
      "metadata": {
        "id": "shiv0uvTdH7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 640 --batch 16 --epochs 15 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/dataset.yaml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "spn1bRX60hYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best.pyã‚’renameã—ã¦gdriveã«ç§»å‹•ã—ã¦ãŠã\n",
        "orig_pt = \"\"\n",
        "dst_pt = \"\"\n",
        "shutil.copy(orig_pt, dst_pt)"
      ],
      "metadata": {
        "id": "2_mRrhFn-ONj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5 Intereference**"
      ],
      "metadata": {
        "id": "kX9AdOK31h1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference (folderå†…å…¨éƒ¨)\n",
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images"
      ],
      "metadata": {
        "id": "Du5NiwCDdTcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\")\n",
        "train = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\")\n",
        "\n",
        "print(len(train), len(valid))"
      ],
      "metadata": {
        "id": "oA6h6A4u_K7Z",
        "outputId": "1a918e6b-ad31-48cf-e9b2-39eb32fe4bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2318 995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference (per image)\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[2]"
      ],
      "metadata": {
        "id": "jmg05lZkDKnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt --img 640 --conf 0.25 --source $img"
      ],
      "metadata": {
        "id": "mQxqh5QMDrYR",
        "outputId": "57a3e9b9-5554-47be-de8c-dcc865d26fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt'], source=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/4713-20120831-20-130053_809f5621ff4eda57025be02c14ba15c3c71f40c65a28fa3ae5cfb011c32825c5.JPG, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/4713-20120831-20-130053_809f5621ff4eda57025be02c14ba15c3c71f40c65a28fa3ae5cfb011c32825c5.JPG: 448x640 1 grav, 11.6ms\n",
            "Speed: 0.8ms pre-process, 11.6ms inference, 36.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "mLCs5mn32MvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[2]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "id": "54vbyhSR-EY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cpKHAnmE_wFQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}