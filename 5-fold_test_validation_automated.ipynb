{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_test_validation_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "e3c4d9c4-72f7-4b29-8e34-7bcfce370653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.11.0+cu113)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 1 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "glav_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/grav\"\n",
        "cont_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/cont\"\n",
        "pretrained_model_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/RepVGG-A2.pth\"\n",
        "gradcam_folder_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/GradCam_EfficientNetB4_test_seed{}\".format(random_seed)\n",
        "result_csv_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/result_EfficientNetB4_test_seed{}.csv\".format(random_seed)\n",
        "confusion_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/confusion_EfficientNetB4_test_seed{}.png\".format(random_seed)\n",
        "ROC_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/ROC_EfficientNetB4_test_seed{}.png\".format(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradCAMんフォルダを作成\n",
        "if os.path.exists(gradcam_folder_path):\n",
        "    shutil.rmtree(gradcam_folder_path) \n",
        "os.makedirs(gradcam_folder_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "8LhOc6OjJQEt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ODB-njjTzV",
        "outputId": "58edfb4e-5757-4796-8e35-0dc3e4b00b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 333, cont: 333\n"
          ]
        }
      ],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(glav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "f8c6fd0e-3b43-494c-eec2-3e95f304ca03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239\n",
            "60\n",
            "239\n",
            "60\n",
            "34\n",
            "34\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "#まず全体の1割をテストセットとしてよけておく\n",
        "remain_dataset_cont, test_dataset_cont = train_test_split(cont_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "remain_dataset_grav, test_dataset_grav = train_test_split(grav_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_cont):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_grav):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n",
        "print(len(test_dataset_cont))\n",
        "print(len(test_dataset_grav))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "a290a0f0-b488-48d1-8e9b-416d14b87d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained repVGG model already exists\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ranger_adabelief\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "478\n",
            "120\n",
            "68\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "            \n",
        "            \n",
        "          \n",
        "\n",
        "            \"\"\"\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        p=0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}' + f'({running_corrects:.0f}/{len(test_dataset):.0f})') \n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "destination = pretrained_model_path\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "###############################\n",
        "##  GradCAM\n",
        "###############################\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset,  row=0, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"grav\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_folder_path+\"/row{}-label{}-pred{}.png\".format(row,classes[test_dataset[j][1]], classes[c]))\n",
        "            row += 1\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "test_list = test_dataset_grav + test_dataset_cont\n",
        "test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "print(len(test_list))\n",
        "\n",
        "\n",
        "\n",
        "######################\n",
        "##   Selecting model        \n",
        "######################\n",
        "from torchvision.models.regnet import RegNet\n",
        "!pip install ranger_adabelief\n",
        "def model_selection(model_name):\n",
        "    if model_name == \"EfficientNet-b4\":\n",
        "        model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "        num_ftrs = model_ft.classifier[1].in_features\n",
        "        model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "    elif model_name == \"RppVGG-A2\":\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2) \n",
        "    elif model_name == \"ResNet50\":\n",
        "        model_ft = torchvision.models.ResNet50(pretrained = True)\n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "    return model_ft\n",
        "\n",
        "######################\n",
        "##   Selecting optimizer     \n",
        "######################\n",
        "def optimizer_selection(optim_name):\n",
        "    scheduler = None\n",
        "    if optim_name == \"SGD\":\n",
        "        optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "    elif optim_name == \"AdamW\":\n",
        "        optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "    elif optim_name == \"AdaBound\":\n",
        "        optimizer_ft = optim.AdaBound(\n",
        "                model_ft.parameters(),\n",
        "                lr= 1e-3,\n",
        "                betas= (0.9, 0.999),\n",
        "                final_lr = 0.1,\n",
        "                gamma=1e-3,\n",
        "                eps= 1e-8,\n",
        "                weight_decay=0,\n",
        "                amsbound=False,\n",
        "            )\n",
        "    elif optim_name == \"AdaBelief\":\n",
        "        from ranger_adabelief import RangerAdaBelief\n",
        "        optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "    return optimizer_ft, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Select model and optimizer**"
      ],
      "metadata": {
        "id": "vFeEqzMoXHYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = model_selection(\"RppVGG-A2\")\n",
        "optimizer_ft, scheduler = optimizer_selection(\"AdaBelief\")"
      ],
      "metadata": {
        "id": "7zXoWcaKWs-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "Emm8lbTkXQOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2gmKzk9yPOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradcam(model_ft, test_dataset, row=0, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "id, number, path, label = [], [], [], []\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "for j in test_dataset_grav:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(1)\n",
        "    k+=1\n",
        "for j in test_dataset_cont:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(0)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "# k=0\n",
        "# for i in val_dataset_grav:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(1)\n",
        "#     k+=1\n",
        "# k=0\n",
        "# for i in val_dataset_cont:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(0)\n",
        "#     k+=1\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"img_id\", \"img_number\", \"path\",\"label\", \"pred_fold0\", \"pred_fold1\", \"pred_fold2\", \"pred_fold3\", \"pred_fold4\", \"prob_fold0\", \"prob_fold1\", \"prob_fold2\", \"prob_fold3\", \"prob_fold4\"])\n",
        "df_result[\"img_id\"] = id\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "print(result_csv_path)\n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) "
      ],
      "metadata": {
        "id": "s_XNgvXXImWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select model and optimizer\n",
        "model_name = \"RppVGG-A2\"\n",
        "optim_name = \"AdaBelief\""
      ],
      "metadata": {
        "id": "FTDD3IVDXoBG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 0\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "    test_list = test_dataset_grav + test_dataset_cont\n",
        "    test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "    test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    model_ft = model_selection(model_name)\n",
        "    optimizer_ft, scheduler = optimizer_selection(optim_name)\n",
        "    # # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # # num_ftrs = model_ft.fc.in_features\n",
        "    # # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    # model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "    # #model_ft = create_RepVGG_A2(deploy=False)\n",
        "    # #model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    # num_ftrs = model_ft.classifier[1].in_features\n",
        "    # model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    # from ranger_adabelief import RangerAdaBelief\n",
        "    # optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    #optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "    # optimizer_ft = optim.AdaBound(\n",
        "    #         model_ft.parameters(),\n",
        "    #         lr= 1e-3,\n",
        "    #         betas= (0.9, 0.999),\n",
        "    #         final_lr = 0.1,\n",
        "    #         gamma=1e-3,\n",
        "    #         eps= 1e-8,\n",
        "    #         weight_decay=0,\n",
        "    #         amsbound=False,\n",
        "    #     )\n",
        "    \n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    \n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    column_pred = 4 + fold\n",
        "    column_prob = 9 + fold\n",
        "\n",
        "    df_result.iloc[row:row+len(y_pred), column_pred] = y_pred\n",
        "    df_result.iloc[row:row+len(y_pred), column_prob] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    #gradcam(model_ft, val_dataset, row, save=True) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "Uh_aAup_hd5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "LxNos2lRIQao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#################################################\n",
        "threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "#################################################\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "FEATURE_COLS=df_result.columns.values[0:].tolist()\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "\n",
        "df_result['statistics'] = np.nan\n",
        "df_result.loc[0:8, 'statistics'] = [\"Accuracy\", \"Positive predictive value\", \"Sensitivity\", \"Specificity\", \"F-score\", \"Area_under_ROC\", \"model\", \"optimizer\", \"Rand_seed\"]\n",
        "\n",
        "k=0\n",
        "for idx, i in enumerate(range(9,14), 0):\n",
        "    print(\"fold\",idx)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    print(X)\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "    acc = accuracy_score(Y, Y_pred)\n",
        "    print('Accuracy:',acc)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    print(tp, fn, fp, tn)\n",
        "    \n",
        "    #5-fold分のconfusion matrixを加算\n",
        "    confusion_arr += confusion_matrix(Y, Y_pred)\n",
        "\n",
        "\n",
        "    def specificity_score(label, pred):\n",
        "        tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "        return tn / (tn + fp)\n",
        "\n",
        "    print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "    #ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "    plt.plot(fpr, tpr, marker='o')\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.grid()\n",
        "    print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "    #plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "    df_result[\"fold_{}\".format(idx)] = np.nan\n",
        "    df_result.loc[0:5, \"fold_{}\".format(idx)] = [accuracy_score(Y, Y_pred), precision_score(Y, Y_pred), recall_score(Y, Y_pred), specificity_score(Y, Y_pred), f1_score(Y, Y_pred), roc_auc_score(Y, Y_pred_proba)]\n",
        "\n",
        "\n",
        "    accuracy.append(accuracy_score(Y, Y_pred))\n",
        "    precision.append(precision_score(Y, Y_pred))\n",
        "    recall.append(recall_score(Y, Y_pred))\n",
        "    specificity.append(specificity_score(Y, Y_pred))\n",
        "    f1score.append(f1_score(Y, Y_pred))\n",
        "    area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "print(\"Result of 5-fold crossvalidation\")\n",
        "print(\"accuracy: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(accuracy), statistics.mean(accuracy)-1.96*statistics.stdev(accuracy), statistics.mean(accuracy)+1.96*statistics.stdev(accuracy)))\n",
        "print(\"precision: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(precision), statistics.mean(precision)-1.96*statistics.stdev(precision), statistics.mean(precision)+1.96*statistics.stdev(precision)))\n",
        "print(\"recall (sensitivity): {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(recall), statistics.mean(recall)-1.96*statistics.stdev(recall), statistics.mean(recall)+1.96*statistics.stdev(recall)))\n",
        "print(\"specificity: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(specificity), statistics.mean(specificity)-1.96*statistics.stdev(specificity), statistics.mean(specificity)+1.96*statistics.stdev(specificity)))\n",
        "print(\"f1_score: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(f1score), statistics.mean(f1score)-1.96*statistics.stdev(f1score), statistics.mean(f1score)+1.96*statistics.stdev(f1score)))\n",
        "print(\"area_u_ROC: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(area_u_ROC), statistics.mean(area_u_ROC)-1.96*statistics.stdev(area_u_ROC), statistics.mean(area_u_ROC)+1.96*statistics.stdev(area_u_ROC)))\n",
        "\n",
        "df_result.loc[0, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(accuracy), statistics.mean(accuracy)-1.96*statistics.stdev(accuracy), statistics.mean(accuracy)+1.96*statistics.stdev(accuracy))]\n",
        "df_result.loc[1, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(precision), statistics.mean(precision)-1.96*statistics.stdev(precision), statistics.mean(precision)+1.96*statistics.stdev(precision))]\n",
        "df_result.loc[2, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(recall), statistics.mean(recall)-1.96*statistics.stdev(recall), statistics.mean(recall)+1.96*statistics.stdev(recall))]\n",
        "df_result.loc[3, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(specificity), statistics.mean(specificity)-1.96*statistics.stdev(specificity), statistics.mean(specificity)+1.96*statistics.stdev(specificity))]\n",
        "df_result.loc[4, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(f1score), statistics.mean(f1score)-1.96*statistics.stdev(f1score), statistics.mean(f1score)+1.96*statistics.stdev(f1score))]\n",
        "df_result.loc[5, \"range\"] = [\"{:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(area_u_ROC), statistics.mean(area_u_ROC)-1.96*statistics.stdev(area_u_ROC), statistics.mean(area_u_ROC)+1.96*statistics.stdev(area_u_ROC))]\n",
        "df_result.loc[6, \"range\"] = model_name  \n",
        "df_result.loc[7, \"range\"] = optim_name\n",
        "df_result.loc[8, \"range\"] = random_seed\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#ヒートマップを作成\n",
        "arr_2d = np.round(confusion_arr/5).astype(int) #5foldの合計をfold数で割って平均を出す、整数に丸めて整数型にする\n",
        "df_matrix = pd.DataFrame(data=arr_2d, index=[\"Normal\", \"Glaucoma\"], columns=[\"Normal\", \"Glaucoma\"])\n",
        "print(df_matrix)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(df_matrix, annot=True,fmt=\"d\", cmap='Blues')\n",
        "plt.savefig(r\"C:\\Users\\ykita\\Downloads\\per_image_confusion_matrix.png\", dpi=700)\n",
        "plt.show()\n",
        "plt.close('all')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NmOJDYqaQEwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61a9cf4e-b752-4aeb-cc39-b3e553f37b7f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['img_id', 'img_number', 'path', 'label', 'pred_fold0', 'pred_fold1', 'pred_fold2', 'pred_fold3', 'pred_fold4', 'prob_fold0', 'prob_fold1', 'prob_fold2', 'prob_fold3', 'prob_fold4', 'statistics', 'fold_0', 'fold_1', 'fold_2', 'fold_3', 'fold_4', 'range']\n",
            "fold 0\n",
            "0     0.970870\n",
            "1     0.972487\n",
            "2     0.995442\n",
            "3     0.996655\n",
            "4     0.893761\n",
            "5     0.991097\n",
            "6     0.488850\n",
            "7     0.178603\n",
            "8     0.847660\n",
            "9     0.339571\n",
            "10    0.616606\n",
            "11    0.654624\n",
            "12    0.982193\n",
            "13    0.107017\n",
            "14    0.846186\n",
            "15    0.440337\n",
            "16    0.998695\n",
            "17    0.758219\n",
            "18    0.995757\n",
            "19    0.785806\n",
            "20    0.996526\n",
            "21    0.999515\n",
            "22    0.958747\n",
            "23    0.706524\n",
            "24    0.992446\n",
            "25    0.995248\n",
            "26    0.478922\n",
            "27    0.983918\n",
            "28    0.677612\n",
            "29    0.861812\n",
            "30    0.453912\n",
            "31    0.765069\n",
            "32    0.927477\n",
            "33    0.890825\n",
            "34    0.111976\n",
            "35    0.383184\n",
            "36    0.151612\n",
            "37    0.175844\n",
            "38    0.360991\n",
            "39    0.275679\n",
            "40    0.588758\n",
            "41    0.932422\n",
            "42    0.845167\n",
            "43    0.135064\n",
            "44    0.293325\n",
            "45    0.265413\n",
            "46    0.057654\n",
            "47    0.059402\n",
            "48    0.307824\n",
            "49    0.560647\n",
            "50    0.124544\n",
            "51    0.755924\n",
            "52    0.236024\n",
            "53    0.381112\n",
            "54    0.200009\n",
            "55    0.498922\n",
            "56    0.693690\n",
            "57    0.067107\n",
            "58    0.031459\n",
            "59    0.088620\n",
            "60    0.127549\n",
            "61    0.447030\n",
            "62    0.672137\n",
            "63    0.586659\n",
            "64    0.577181\n",
            "65    0.811703\n",
            "66    0.163895\n",
            "67    0.061177\n",
            "Name: prob_fold0, dtype: float64\n",
            "Accuracy: 0.75\n",
            "27 7 10 24\n",
            "confusion matrix = \n",
            " [[24 10]\n",
            " [ 7 27]]\n",
            "Accuracy : 0.75\n",
            "Precision (true positive rate) : 0.7297297297297297\n",
            "Recall (sensitivity): 0.7941176470588235\n",
            "Specificity : 0.7058823529411765\n",
            "F1 score : 0.7605633802816901\n",
            "Area_under_ROC : 0.8745674740484429\n",
            "\n",
            "fold 1\n",
            "0     0.999716\n",
            "1     0.958145\n",
            "2     0.973049\n",
            "3     0.999746\n",
            "4     0.552155\n",
            "5     0.998814\n",
            "6     0.173383\n",
            "7     0.290108\n",
            "8     0.929368\n",
            "9     0.170156\n",
            "10    0.517638\n",
            "11    0.988733\n",
            "12    0.999573\n",
            "13    0.031277\n",
            "14    0.815550\n",
            "15    0.352047\n",
            "16    0.994677\n",
            "17    0.049432\n",
            "18    0.856845\n",
            "19    0.060587\n",
            "20    0.824478\n",
            "21    0.960963\n",
            "22    0.676798\n",
            "23    0.366057\n",
            "24    0.994584\n",
            "25    0.998407\n",
            "26    0.440755\n",
            "27    0.972259\n",
            "28    0.845815\n",
            "29    0.991934\n",
            "30    0.027060\n",
            "31    0.345355\n",
            "32    0.977205\n",
            "33    0.907439\n",
            "34    0.747036\n",
            "35    0.388848\n",
            "36    0.075407\n",
            "37    0.575994\n",
            "38    0.022393\n",
            "39    0.040317\n",
            "40    0.390923\n",
            "41    0.970269\n",
            "42    0.003662\n",
            "43    0.017362\n",
            "44    0.117677\n",
            "45    0.023457\n",
            "46    0.019000\n",
            "47    0.013928\n",
            "48    0.147980\n",
            "49    0.217177\n",
            "50    0.001751\n",
            "51    0.054322\n",
            "52    0.012929\n",
            "53    0.305473\n",
            "54    0.617885\n",
            "55    0.242150\n",
            "56    0.404977\n",
            "57    0.046322\n",
            "58    0.029653\n",
            "59    0.484220\n",
            "60    0.050952\n",
            "61    0.018577\n",
            "62    0.063269\n",
            "63    0.145182\n",
            "64    0.102682\n",
            "65    0.049817\n",
            "66    0.040690\n",
            "67    0.039082\n",
            "Name: prob_fold1, dtype: float64\n",
            "Accuracy: 0.7794117647058824\n",
            "23 11 4 30\n",
            "confusion matrix = \n",
            " [[30  4]\n",
            " [11 23]]\n",
            "Accuracy : 0.7794117647058824\n",
            "Precision (true positive rate) : 0.8518518518518519\n",
            "Recall (sensitivity): 0.6764705882352942\n",
            "Specificity : 0.8823529411764706\n",
            "F1 score : 0.7540983606557378\n",
            "Area_under_ROC : 0.8581314878892734\n",
            "\n",
            "fold 2\n",
            "0     0.925896\n",
            "1     0.746095\n",
            "2     0.986112\n",
            "3     0.997798\n",
            "4     0.527242\n",
            "5     0.996259\n",
            "6     0.386147\n",
            "7     0.113201\n",
            "8     0.524096\n",
            "9     0.458113\n",
            "10    0.641767\n",
            "11    0.421226\n",
            "12    0.975631\n",
            "13    0.174246\n",
            "14    0.915977\n",
            "15    0.169934\n",
            "16    0.999497\n",
            "17    0.242544\n",
            "18    0.977316\n",
            "19    0.385291\n",
            "20    0.842954\n",
            "21    0.978409\n",
            "22    0.253111\n",
            "23    0.228376\n",
            "24    0.989547\n",
            "25    0.996725\n",
            "26    0.147883\n",
            "27    0.991390\n",
            "28    0.353882\n",
            "29    0.990647\n",
            "30    0.465092\n",
            "31    0.444435\n",
            "32    0.968381\n",
            "33    0.889815\n",
            "34    0.110759\n",
            "35    0.241724\n",
            "36    0.039702\n",
            "37    0.163995\n",
            "38    0.102685\n",
            "39    0.269858\n",
            "40    0.275040\n",
            "41    0.782134\n",
            "42    0.272139\n",
            "43    0.057250\n",
            "44    0.325304\n",
            "45    0.296780\n",
            "46    0.019544\n",
            "47    0.020490\n",
            "48    0.105380\n",
            "49    0.264516\n",
            "50    0.009853\n",
            "51    0.146209\n",
            "52    0.145265\n",
            "53    0.255561\n",
            "54    0.114328\n",
            "55    0.381218\n",
            "56    0.716076\n",
            "57    0.063721\n",
            "58    0.093588\n",
            "59    0.064359\n",
            "60    0.123271\n",
            "61    0.023086\n",
            "62    0.402802\n",
            "63    0.545001\n",
            "64    0.493996\n",
            "65    0.231164\n",
            "66    0.024496\n",
            "67    0.106086\n",
            "Name: prob_fold2, dtype: float64\n",
            "Accuracy: 0.75\n",
            "20 14 3 31\n",
            "confusion matrix = \n",
            " [[31  3]\n",
            " [14 20]]\n",
            "Accuracy : 0.75\n",
            "Precision (true positive rate) : 0.8695652173913043\n",
            "Recall (sensitivity): 0.5882352941176471\n",
            "Specificity : 0.9117647058823529\n",
            "F1 score : 0.7017543859649124\n",
            "Area_under_ROC : 0.8719723183391004\n",
            "\n",
            "fold 3\n",
            "0     0.996183\n",
            "1     0.999580\n",
            "2     0.998199\n",
            "3     0.999997\n",
            "4     0.295002\n",
            "5     0.999533\n",
            "6     0.905765\n",
            "7     0.282480\n",
            "8     0.924842\n",
            "9     0.953091\n",
            "10    0.414348\n",
            "11    0.996910\n",
            "12    0.999888\n",
            "13    0.056537\n",
            "14    0.994098\n",
            "15    0.882862\n",
            "16    0.999994\n",
            "17    0.248582\n",
            "18    0.999338\n",
            "19    0.427170\n",
            "20    0.998874\n",
            "21    0.999720\n",
            "22    0.949052\n",
            "23    0.997296\n",
            "24    0.999953\n",
            "25    0.999905\n",
            "26    0.784534\n",
            "27    0.964332\n",
            "28    0.989971\n",
            "29    0.999711\n",
            "30    0.011641\n",
            "31    0.407101\n",
            "32    0.997935\n",
            "33    0.999764\n",
            "34    0.616606\n",
            "35    0.048569\n",
            "36    0.004495\n",
            "37    0.095000\n",
            "38    0.175789\n",
            "39    0.029223\n",
            "40    0.588897\n",
            "41    0.703248\n",
            "42    0.005590\n",
            "43    0.451185\n",
            "44    0.013155\n",
            "45    0.014614\n",
            "46    0.047928\n",
            "47    0.002562\n",
            "48    0.421179\n",
            "49    0.156127\n",
            "50    0.002413\n",
            "51    0.009869\n",
            "52    0.339349\n",
            "53    0.137586\n",
            "54    0.684588\n",
            "55    0.491571\n",
            "56    0.171660\n",
            "57    0.004905\n",
            "58    0.025617\n",
            "59    0.080446\n",
            "60    0.066678\n",
            "61    0.124501\n",
            "62    0.914565\n",
            "63    0.341103\n",
            "64    0.786810\n",
            "65    0.803070\n",
            "66    0.025096\n",
            "67    0.083423\n",
            "Name: prob_fold3, dtype: float64\n",
            "Accuracy: 0.7794117647058824\n",
            "26 8 7 27\n",
            "confusion matrix = \n",
            " [[27  7]\n",
            " [ 8 26]]\n",
            "Accuracy : 0.7794117647058824\n",
            "Precision (true positive rate) : 0.7878787878787878\n",
            "Recall (sensitivity): 0.7647058823529411\n",
            "Specificity : 0.7941176470588235\n",
            "F1 score : 0.7761194029850745\n",
            "Area_under_ROC : 0.8970588235294117\n",
            "\n",
            "fold 4\n",
            "0     1.000000\n",
            "1     0.980783\n",
            "2     0.999599\n",
            "3     0.999818\n",
            "4     0.776796\n",
            "5     0.999995\n",
            "6     0.878194\n",
            "7     0.490502\n",
            "8     0.999626\n",
            "9     0.146427\n",
            "10    0.994130\n",
            "11    1.000000\n",
            "12    1.000000\n",
            "13    0.000009\n",
            "14    0.999954\n",
            "15    0.925970\n",
            "16    1.000000\n",
            "17    0.240194\n",
            "18    0.988358\n",
            "19    0.575307\n",
            "20    0.985340\n",
            "21    0.999999\n",
            "22    0.870348\n",
            "23    0.999799\n",
            "24    0.998485\n",
            "25    0.999997\n",
            "26    0.869700\n",
            "27    0.996900\n",
            "28    0.896144\n",
            "29    1.000000\n",
            "30    0.106345\n",
            "31    0.954137\n",
            "32    0.999975\n",
            "33    0.999049\n",
            "34    0.878712\n",
            "35    0.139721\n",
            "36    0.000089\n",
            "37    0.655736\n",
            "38    0.107135\n",
            "39    0.702544\n",
            "40    0.734109\n",
            "41    0.327329\n",
            "42    0.001208\n",
            "43    0.046621\n",
            "44    0.054804\n",
            "45    0.137578\n",
            "46    0.766103\n",
            "47    0.000001\n",
            "48    0.067784\n",
            "49    0.159270\n",
            "50    0.014213\n",
            "51    0.000691\n",
            "52    0.012941\n",
            "53    0.998138\n",
            "54    0.976593\n",
            "55    0.316437\n",
            "56    0.813228\n",
            "57    0.000009\n",
            "58    0.663635\n",
            "59    0.251782\n",
            "60    0.261592\n",
            "61    0.227451\n",
            "62    0.382155\n",
            "63    0.175451\n",
            "64    0.897202\n",
            "65    0.936791\n",
            "66    0.003818\n",
            "67    0.028335\n",
            "Name: prob_fold4, dtype: float64\n",
            "Accuracy: 0.7647058823529411\n",
            "29 5 11 23\n",
            "confusion matrix = \n",
            " [[23 11]\n",
            " [ 5 29]]\n",
            "Accuracy : 0.7647058823529411\n",
            "Precision (true positive rate) : 0.725\n",
            "Recall (sensitivity): 0.8529411764705882\n",
            "Specificity : 0.6764705882352942\n",
            "F1 score : 0.7837837837837837\n",
            "Area_under_ROC : 0.8728373702422146\n",
            "\n",
            "Result of 5-fold crossvalidation\n",
            "accuracy: 0.76 (0.74-0.79)\n",
            "precision: 0.79 (0.66-0.92)\n",
            "recall (sensitivity): 0.74 (0.53-0.94)\n",
            "specificity: 0.79 (0.59-1.00)\n",
            "f1_score: 0.76 (0.69-0.82)\n",
            "area_u_ROC: 0.87 (0.85-0.90)\n",
            "\n",
            "          Normal  Glaucoma\n",
            "Normal        27         7\n",
            "Glaucoma       9        25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr,tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.savefig(ROC_path, format=\"png\", dpi=700)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "for i in range(9,14):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    label_list_list.append(Y)\n",
        "    model_pred_prob_list.append(Y_pred_proba)\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = list(range(5))\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "\n",
        "label_list_list2, model_pred_prob_list2, Y_TRUE2, Y_SCORE2 = [],[],[],[]\n",
        "\n",
        "roc_label_list = [0]\n",
        "for i in range(5):\n",
        "    label_list_list2.extend(label_list_list[i])\n",
        "    model_pred_prob_list2.extend(model_pred_prob_list[i])\n",
        "label_list_list2 = [label_list_list2]\n",
        "model_pred_prob_list2 = [model_pred_prob_list2]\n",
        "fig = Draw_roc_curve(label_list_list2, model_pred_prob_list2, roc_label_list, len(label_list_list2))"
      ],
      "metadata": {
        "id": "Cb48jClLk24l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "94b29b79-4fc6-46c2-e7fd-04da66e492e3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 9\n",
            "fold 10\n",
            "fold 11\n",
            "fold 12\n",
            "fold 13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#統計結果を追記 ※上のスクリプトに組み込み\n",
        "# df_result['statistics'] = np.nan\n",
        "# df_result['result'] = np.nan\n",
        "# df_result.loc[0:5, 'statistics'] = [\"Accuracy\", \"Positive predictive value\", \"Sensitivity\", \"Specificity\", \"F-score\", \"Area_under_ROC\", \"model\", \"optimizer\", \"Rand_seed\"]\n",
        "# df_result.loc[0:5, 'result'] = [accuracy_score(Y, Y_pred), precision_score(Y, Y_pred), recall_score(Y, Y_pred), specificity_score(Y, Y_pred), f1_score(Y, Y_pred), roc_auc_score(Y, Y_pred_proba), model_name, optim_name, random_seed]"
      ],
      "metadata": {
        "id": "oBo9g2XsnJA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) \n",
        "df_result"
      ],
      "metadata": {
        "id": "gSRr_lYTnF8Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49ee158d-3b16-4519-a260-c84eff5c13ed"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    img_id img_number                                               path  \\\n",
              "0        0   1270.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "1        1   4710.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "2        2   3667.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "3        3     57.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "4        4   5297.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "5        5   2510.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "6        6   7709.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "7        7   2274.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "8        8   5397.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "9        9   2801.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "10      10   1378.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "11      11   2900.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "12      12   4272.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "13      13   4125.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "14      14    977.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "15      15   2794.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "16      16   2508.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "17      17   5901.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "18      18   2851.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "19      19   5051.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "20      20   4359.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "21      21   5540.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "22      22   6515.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "23      23   4958.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "24      24   5378.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "25      25   6106.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "26      26   6725.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "27      27   2042.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "28      28   6283.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "29      29   3331.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "30      30   3176.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "31      31   7527.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "32      32   3532.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "33      33   7349.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "34      34   2164.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "35      35   5158.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "36      36   6060.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "37      37   4647.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "38      38   7691.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "39      39   3906.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "40      40   6185.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "41      41   6870.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "42      42   2866.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "43      43   4222.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "44      44   8027.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "45      45   6512.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "46      46   6693.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "47      47   5563.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "48      48   1381.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "49      49   1759.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "50      50   2979.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "51      51   6491.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "52      52   6160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "53      53   7741.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "54      54   6838.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "55      55    802.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "56      56   1488.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "57      57   8149.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "58      58   7511.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "59      59   7466.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "60      60   3663.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "61      61    863.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "62      62   1160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "63      63   4441.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "64      64   2180.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "65      65    147.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "66      66   1413.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "67      67   7905.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "\n",
              "    label  pred_fold0  pred_fold1  pred_fold2  pred_fold3  pred_fold4  \\\n",
              "0       1           1           1           1           1           1   \n",
              "1       1           1           1           1           1           1   \n",
              "2       1           1           1           1           1           1   \n",
              "3       1           1           1           1           1           1   \n",
              "4       1           1           1           1           0           1   \n",
              "5       1           1           1           1           1           1   \n",
              "6       1           0           0           0           1           1   \n",
              "7       1           0           0           0           0           0   \n",
              "8       1           1           1           1           1           1   \n",
              "9       1           0           0           0           1           0   \n",
              "10      1           1           1           1           0           1   \n",
              "11      1           1           1           0           1           1   \n",
              "12      1           1           1           1           1           1   \n",
              "13      1           0           0           0           0           0   \n",
              "14      1           1           1           1           1           1   \n",
              "15      1           0           0           0           1           1   \n",
              "16      1           1           1           1           1           1   \n",
              "17      1           1           0           0           0           0   \n",
              "18      1           1           1           1           1           1   \n",
              "19      1           1           0           0           0           1   \n",
              "20      1           1           1           1           1           1   \n",
              "21      1           1           1           1           1           1   \n",
              "22      1           1           1           0           1           1   \n",
              "23      1           1           0           0           1           1   \n",
              "24      1           1           1           1           1           1   \n",
              "25      1           1           1           1           1           1   \n",
              "26      1           0           0           0           1           1   \n",
              "27      1           1           1           1           1           1   \n",
              "28      1           1           1           0           1           1   \n",
              "29      1           1           1           1           1           1   \n",
              "30      1           0           0           0           0           0   \n",
              "31      1           1           0           0           0           1   \n",
              "32      1           1           1           1           1           1   \n",
              "33      1           1           1           1           1           1   \n",
              "34      0           0           1           0           1           1   \n",
              "35      0           0           0           0           0           0   \n",
              "36      0           0           0           0           0           0   \n",
              "37      0           0           1           0           0           1   \n",
              "38      0           0           0           0           0           0   \n",
              "39      0           0           0           0           0           1   \n",
              "40      0           1           0           0           1           1   \n",
              "41      0           1           1           1           1           0   \n",
              "42      0           1           0           0           0           0   \n",
              "43      0           0           0           0           0           0   \n",
              "44      0           0           0           0           0           0   \n",
              "45      0           0           0           0           0           0   \n",
              "46      0           0           0           0           0           1   \n",
              "47      0           0           0           0           0           0   \n",
              "48      0           0           0           0           0           0   \n",
              "49      0           1           0           0           0           0   \n",
              "50      0           0           0           0           0           0   \n",
              "51      0           1           0           0           0           0   \n",
              "52      0           0           0           0           0           0   \n",
              "53      0           0           0           0           0           1   \n",
              "54      0           0           1           0           1           1   \n",
              "55      0           0           0           0           0           0   \n",
              "56      0           1           0           1           0           1   \n",
              "57      0           0           0           0           0           0   \n",
              "58      0           0           0           0           0           1   \n",
              "59      0           0           0           0           0           0   \n",
              "60      0           0           0           0           0           0   \n",
              "61      0           0           0           0           0           0   \n",
              "62      0           1           0           0           1           0   \n",
              "63      0           1           0           1           0           0   \n",
              "64      0           1           0           0           1           1   \n",
              "65      0           1           0           0           1           1   \n",
              "66      0           0           0           0           0           0   \n",
              "67      0           0           0           0           0           0   \n",
              "\n",
              "    prob_fold0  ...  prob_fold2  prob_fold3  prob_fold4  \\\n",
              "0     0.970870  ...    0.925896    0.996183    1.000000   \n",
              "1     0.972487  ...    0.746095    0.999580    0.980783   \n",
              "2     0.995442  ...    0.986112    0.998199    0.999599   \n",
              "3     0.996655  ...    0.997798    0.999997    0.999818   \n",
              "4     0.893761  ...    0.527242    0.295002    0.776796   \n",
              "5     0.991097  ...    0.996259    0.999533    0.999995   \n",
              "6     0.488850  ...    0.386147    0.905765    0.878194   \n",
              "7     0.178603  ...    0.113201    0.282480    0.490502   \n",
              "8     0.847660  ...    0.524096    0.924842    0.999626   \n",
              "9     0.339571  ...    0.458113    0.953091    0.146427   \n",
              "10    0.616606  ...    0.641767    0.414348    0.994130   \n",
              "11    0.654624  ...    0.421226    0.996910    1.000000   \n",
              "12    0.982193  ...    0.975631    0.999888    1.000000   \n",
              "13    0.107017  ...    0.174246    0.056537    0.000009   \n",
              "14    0.846186  ...    0.915977    0.994098    0.999954   \n",
              "15    0.440337  ...    0.169934    0.882862    0.925970   \n",
              "16    0.998695  ...    0.999497    0.999994    1.000000   \n",
              "17    0.758219  ...    0.242544    0.248582    0.240194   \n",
              "18    0.995757  ...    0.977316    0.999338    0.988358   \n",
              "19    0.785806  ...    0.385291    0.427170    0.575307   \n",
              "20    0.996526  ...    0.842954    0.998874    0.985340   \n",
              "21    0.999515  ...    0.978409    0.999720    0.999999   \n",
              "22    0.958747  ...    0.253111    0.949052    0.870348   \n",
              "23    0.706524  ...    0.228376    0.997296    0.999799   \n",
              "24    0.992446  ...    0.989547    0.999953    0.998485   \n",
              "25    0.995248  ...    0.996725    0.999905    0.999997   \n",
              "26    0.478922  ...    0.147883    0.784534    0.869700   \n",
              "27    0.983918  ...    0.991390    0.964332    0.996900   \n",
              "28    0.677612  ...    0.353882    0.989971    0.896144   \n",
              "29    0.861812  ...    0.990647    0.999711    1.000000   \n",
              "30    0.453912  ...    0.465092    0.011641    0.106345   \n",
              "31    0.765069  ...    0.444435    0.407101    0.954137   \n",
              "32    0.927477  ...    0.968381    0.997935    0.999975   \n",
              "33    0.890825  ...    0.889815    0.999764    0.999049   \n",
              "34    0.111976  ...    0.110759    0.616606    0.878712   \n",
              "35    0.383184  ...    0.241724    0.048569    0.139721   \n",
              "36    0.151612  ...    0.039702    0.004495    0.000089   \n",
              "37    0.175844  ...    0.163995    0.095000    0.655736   \n",
              "38    0.360991  ...    0.102685    0.175789    0.107135   \n",
              "39    0.275679  ...    0.269858    0.029223    0.702544   \n",
              "40    0.588758  ...    0.275040    0.588897    0.734109   \n",
              "41    0.932422  ...    0.782134    0.703248    0.327329   \n",
              "42    0.845167  ...    0.272139    0.005590    0.001208   \n",
              "43    0.135064  ...    0.057250    0.451185    0.046621   \n",
              "44    0.293325  ...    0.325304    0.013155    0.054804   \n",
              "45    0.265413  ...    0.296780    0.014614    0.137578   \n",
              "46    0.057654  ...    0.019544    0.047928    0.766103   \n",
              "47    0.059402  ...    0.020490    0.002562    0.000001   \n",
              "48    0.307824  ...    0.105380    0.421179    0.067784   \n",
              "49    0.560647  ...    0.264516    0.156127    0.159270   \n",
              "50    0.124544  ...    0.009853    0.002413    0.014213   \n",
              "51    0.755924  ...    0.146209    0.009869    0.000691   \n",
              "52    0.236024  ...    0.145265    0.339349    0.012941   \n",
              "53    0.381112  ...    0.255561    0.137586    0.998138   \n",
              "54    0.200009  ...    0.114328    0.684588    0.976593   \n",
              "55    0.498922  ...    0.381218    0.491571    0.316437   \n",
              "56    0.693690  ...    0.716076    0.171660    0.813228   \n",
              "57    0.067107  ...    0.063721    0.004905    0.000009   \n",
              "58    0.031459  ...    0.093588    0.025617    0.663635   \n",
              "59    0.088620  ...    0.064359    0.080446    0.251782   \n",
              "60    0.127549  ...    0.123271    0.066678    0.261592   \n",
              "61    0.447030  ...    0.023086    0.124501    0.227451   \n",
              "62    0.672137  ...    0.402802    0.914565    0.382155   \n",
              "63    0.586659  ...    0.545001    0.341103    0.175451   \n",
              "64    0.577181  ...    0.493996    0.786810    0.897202   \n",
              "65    0.811703  ...    0.231164    0.803070    0.936791   \n",
              "66    0.163895  ...    0.024496    0.025096    0.003818   \n",
              "67    0.061177  ...    0.106086    0.083423    0.028335   \n",
              "\n",
              "                   statistics    fold_0    fold_1    fold_2    fold_3  \\\n",
              "0                    Accuracy  0.750000  0.779412  0.750000  0.779412   \n",
              "1   Positive predictive value  0.729730  0.851852  0.869565  0.787879   \n",
              "2                 Sensitivity  0.794118  0.676471  0.588235  0.764706   \n",
              "3                 Specificity  0.705882  0.882353  0.911765  0.794118   \n",
              "4                     F-score  0.760563  0.754098  0.701754  0.776119   \n",
              "5              Area_under_ROC  0.874567  0.858131  0.871972  0.897059   \n",
              "6                       model       NaN       NaN       NaN       NaN   \n",
              "7                   optimizer       NaN       NaN       NaN       NaN   \n",
              "8                   Rand_seed       NaN       NaN       NaN       NaN   \n",
              "9                         NaN       NaN       NaN       NaN       NaN   \n",
              "10                        NaN       NaN       NaN       NaN       NaN   \n",
              "11                        NaN       NaN       NaN       NaN       NaN   \n",
              "12                        NaN       NaN       NaN       NaN       NaN   \n",
              "13                        NaN       NaN       NaN       NaN       NaN   \n",
              "14                        NaN       NaN       NaN       NaN       NaN   \n",
              "15                        NaN       NaN       NaN       NaN       NaN   \n",
              "16                        NaN       NaN       NaN       NaN       NaN   \n",
              "17                        NaN       NaN       NaN       NaN       NaN   \n",
              "18                        NaN       NaN       NaN       NaN       NaN   \n",
              "19                        NaN       NaN       NaN       NaN       NaN   \n",
              "20                        NaN       NaN       NaN       NaN       NaN   \n",
              "21                        NaN       NaN       NaN       NaN       NaN   \n",
              "22                        NaN       NaN       NaN       NaN       NaN   \n",
              "23                        NaN       NaN       NaN       NaN       NaN   \n",
              "24                        NaN       NaN       NaN       NaN       NaN   \n",
              "25                        NaN       NaN       NaN       NaN       NaN   \n",
              "26                        NaN       NaN       NaN       NaN       NaN   \n",
              "27                        NaN       NaN       NaN       NaN       NaN   \n",
              "28                        NaN       NaN       NaN       NaN       NaN   \n",
              "29                        NaN       NaN       NaN       NaN       NaN   \n",
              "30                        NaN       NaN       NaN       NaN       NaN   \n",
              "31                        NaN       NaN       NaN       NaN       NaN   \n",
              "32                        NaN       NaN       NaN       NaN       NaN   \n",
              "33                        NaN       NaN       NaN       NaN       NaN   \n",
              "34                        NaN       NaN       NaN       NaN       NaN   \n",
              "35                        NaN       NaN       NaN       NaN       NaN   \n",
              "36                        NaN       NaN       NaN       NaN       NaN   \n",
              "37                        NaN       NaN       NaN       NaN       NaN   \n",
              "38                        NaN       NaN       NaN       NaN       NaN   \n",
              "39                        NaN       NaN       NaN       NaN       NaN   \n",
              "40                        NaN       NaN       NaN       NaN       NaN   \n",
              "41                        NaN       NaN       NaN       NaN       NaN   \n",
              "42                        NaN       NaN       NaN       NaN       NaN   \n",
              "43                        NaN       NaN       NaN       NaN       NaN   \n",
              "44                        NaN       NaN       NaN       NaN       NaN   \n",
              "45                        NaN       NaN       NaN       NaN       NaN   \n",
              "46                        NaN       NaN       NaN       NaN       NaN   \n",
              "47                        NaN       NaN       NaN       NaN       NaN   \n",
              "48                        NaN       NaN       NaN       NaN       NaN   \n",
              "49                        NaN       NaN       NaN       NaN       NaN   \n",
              "50                        NaN       NaN       NaN       NaN       NaN   \n",
              "51                        NaN       NaN       NaN       NaN       NaN   \n",
              "52                        NaN       NaN       NaN       NaN       NaN   \n",
              "53                        NaN       NaN       NaN       NaN       NaN   \n",
              "54                        NaN       NaN       NaN       NaN       NaN   \n",
              "55                        NaN       NaN       NaN       NaN       NaN   \n",
              "56                        NaN       NaN       NaN       NaN       NaN   \n",
              "57                        NaN       NaN       NaN       NaN       NaN   \n",
              "58                        NaN       NaN       NaN       NaN       NaN   \n",
              "59                        NaN       NaN       NaN       NaN       NaN   \n",
              "60                        NaN       NaN       NaN       NaN       NaN   \n",
              "61                        NaN       NaN       NaN       NaN       NaN   \n",
              "62                        NaN       NaN       NaN       NaN       NaN   \n",
              "63                        NaN       NaN       NaN       NaN       NaN   \n",
              "64                        NaN       NaN       NaN       NaN       NaN   \n",
              "65                        NaN       NaN       NaN       NaN       NaN   \n",
              "66                        NaN       NaN       NaN       NaN       NaN   \n",
              "67                        NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "      fold_4             range  \n",
              "0   0.764706  0.76 (0.74-0.79)  \n",
              "1   0.725000  0.79 (0.66-0.92)  \n",
              "2   0.852941  0.74 (0.53-0.94)  \n",
              "3   0.676471  0.79 (0.59-1.00)  \n",
              "4   0.783784  0.76 (0.69-0.82)  \n",
              "5   0.872837  0.87 (0.85-0.90)  \n",
              "6        NaN         RppVGG-A2  \n",
              "7        NaN         AdaBelief  \n",
              "8        NaN                 1  \n",
              "9        NaN               NaN  \n",
              "10       NaN               NaN  \n",
              "11       NaN               NaN  \n",
              "12       NaN               NaN  \n",
              "13       NaN               NaN  \n",
              "14       NaN               NaN  \n",
              "15       NaN               NaN  \n",
              "16       NaN               NaN  \n",
              "17       NaN               NaN  \n",
              "18       NaN               NaN  \n",
              "19       NaN               NaN  \n",
              "20       NaN               NaN  \n",
              "21       NaN               NaN  \n",
              "22       NaN               NaN  \n",
              "23       NaN               NaN  \n",
              "24       NaN               NaN  \n",
              "25       NaN               NaN  \n",
              "26       NaN               NaN  \n",
              "27       NaN               NaN  \n",
              "28       NaN               NaN  \n",
              "29       NaN               NaN  \n",
              "30       NaN               NaN  \n",
              "31       NaN               NaN  \n",
              "32       NaN               NaN  \n",
              "33       NaN               NaN  \n",
              "34       NaN               NaN  \n",
              "35       NaN               NaN  \n",
              "36       NaN               NaN  \n",
              "37       NaN               NaN  \n",
              "38       NaN               NaN  \n",
              "39       NaN               NaN  \n",
              "40       NaN               NaN  \n",
              "41       NaN               NaN  \n",
              "42       NaN               NaN  \n",
              "43       NaN               NaN  \n",
              "44       NaN               NaN  \n",
              "45       NaN               NaN  \n",
              "46       NaN               NaN  \n",
              "47       NaN               NaN  \n",
              "48       NaN               NaN  \n",
              "49       NaN               NaN  \n",
              "50       NaN               NaN  \n",
              "51       NaN               NaN  \n",
              "52       NaN               NaN  \n",
              "53       NaN               NaN  \n",
              "54       NaN               NaN  \n",
              "55       NaN               NaN  \n",
              "56       NaN               NaN  \n",
              "57       NaN               NaN  \n",
              "58       NaN               NaN  \n",
              "59       NaN               NaN  \n",
              "60       NaN               NaN  \n",
              "61       NaN               NaN  \n",
              "62       NaN               NaN  \n",
              "63       NaN               NaN  \n",
              "64       NaN               NaN  \n",
              "65       NaN               NaN  \n",
              "66       NaN               NaN  \n",
              "67       NaN               NaN  \n",
              "\n",
              "[68 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ce6517e-54bb-49cd-a203-a892d7627b41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred_fold0</th>\n",
              "      <th>pred_fold1</th>\n",
              "      <th>pred_fold2</th>\n",
              "      <th>pred_fold3</th>\n",
              "      <th>pred_fold4</th>\n",
              "      <th>prob_fold0</th>\n",
              "      <th>...</th>\n",
              "      <th>prob_fold2</th>\n",
              "      <th>prob_fold3</th>\n",
              "      <th>prob_fold4</th>\n",
              "      <th>statistics</th>\n",
              "      <th>fold_0</th>\n",
              "      <th>fold_1</th>\n",
              "      <th>fold_2</th>\n",
              "      <th>fold_3</th>\n",
              "      <th>fold_4</th>\n",
              "      <th>range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1270.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.970870</td>\n",
              "      <td>...</td>\n",
              "      <td>0.925896</td>\n",
              "      <td>0.996183</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Accuracy</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.76 (0.74-0.79)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4710.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.972487</td>\n",
              "      <td>...</td>\n",
              "      <td>0.746095</td>\n",
              "      <td>0.999580</td>\n",
              "      <td>0.980783</td>\n",
              "      <td>Positive predictive value</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>0.851852</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.79 (0.66-0.92)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3667.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.986112</td>\n",
              "      <td>0.998199</td>\n",
              "      <td>0.999599</td>\n",
              "      <td>Sensitivity</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.74 (0.53-0.94)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>57.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.997798</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>0.999818</td>\n",
              "      <td>Specificity</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.911765</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.79 (0.59-1.00)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5297.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.893761</td>\n",
              "      <td>...</td>\n",
              "      <td>0.527242</td>\n",
              "      <td>0.295002</td>\n",
              "      <td>0.776796</td>\n",
              "      <td>F-score</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.76 (0.69-0.82)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2510.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.991097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996259</td>\n",
              "      <td>0.999533</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>Area_under_ROC</td>\n",
              "      <td>0.874567</td>\n",
              "      <td>0.858131</td>\n",
              "      <td>0.871972</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.872837</td>\n",
              "      <td>0.87 (0.85-0.90)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7709.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386147</td>\n",
              "      <td>0.905765</td>\n",
              "      <td>0.878194</td>\n",
              "      <td>model</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RppVGG-A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2274.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.178603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.113201</td>\n",
              "      <td>0.282480</td>\n",
              "      <td>0.490502</td>\n",
              "      <td>optimizer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AdaBelief</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5397.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.847660</td>\n",
              "      <td>...</td>\n",
              "      <td>0.524096</td>\n",
              "      <td>0.924842</td>\n",
              "      <td>0.999626</td>\n",
              "      <td>Rand_seed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2801.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.339571</td>\n",
              "      <td>...</td>\n",
              "      <td>0.458113</td>\n",
              "      <td>0.953091</td>\n",
              "      <td>0.146427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>1378.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.616606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641767</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.994130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>2900.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.654624</td>\n",
              "      <td>...</td>\n",
              "      <td>0.421226</td>\n",
              "      <td>0.996910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>4272.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.982193</td>\n",
              "      <td>...</td>\n",
              "      <td>0.975631</td>\n",
              "      <td>0.999888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>4125.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.107017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.174246</td>\n",
              "      <td>0.056537</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>977.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.846186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.915977</td>\n",
              "      <td>0.994098</td>\n",
              "      <td>0.999954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>2794.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.440337</td>\n",
              "      <td>...</td>\n",
              "      <td>0.169934</td>\n",
              "      <td>0.882862</td>\n",
              "      <td>0.925970</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>2508.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998695</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999497</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>5901.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242544</td>\n",
              "      <td>0.248582</td>\n",
              "      <td>0.240194</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>2851.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995757</td>\n",
              "      <td>...</td>\n",
              "      <td>0.977316</td>\n",
              "      <td>0.999338</td>\n",
              "      <td>0.988358</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>5051.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785806</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385291</td>\n",
              "      <td>0.427170</td>\n",
              "      <td>0.575307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>4359.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996526</td>\n",
              "      <td>...</td>\n",
              "      <td>0.842954</td>\n",
              "      <td>0.998874</td>\n",
              "      <td>0.985340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>5540.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999515</td>\n",
              "      <td>...</td>\n",
              "      <td>0.978409</td>\n",
              "      <td>0.999720</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>6515.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.253111</td>\n",
              "      <td>0.949052</td>\n",
              "      <td>0.870348</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>4958.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.706524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.228376</td>\n",
              "      <td>0.997296</td>\n",
              "      <td>0.999799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>5378.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.992446</td>\n",
              "      <td>...</td>\n",
              "      <td>0.989547</td>\n",
              "      <td>0.999953</td>\n",
              "      <td>0.998485</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>6106.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995248</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996725</td>\n",
              "      <td>0.999905</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>6725.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.478922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147883</td>\n",
              "      <td>0.784534</td>\n",
              "      <td>0.869700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>2042.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.991390</td>\n",
              "      <td>0.964332</td>\n",
              "      <td>0.996900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>6283.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.677612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.353882</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.896144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>3331.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861812</td>\n",
              "      <td>...</td>\n",
              "      <td>0.990647</td>\n",
              "      <td>0.999711</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>3176.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.453912</td>\n",
              "      <td>...</td>\n",
              "      <td>0.465092</td>\n",
              "      <td>0.011641</td>\n",
              "      <td>0.106345</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>7527.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.765069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.444435</td>\n",
              "      <td>0.407101</td>\n",
              "      <td>0.954137</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>3532.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.968381</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>0.999975</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>7349.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.890825</td>\n",
              "      <td>...</td>\n",
              "      <td>0.889815</td>\n",
              "      <td>0.999764</td>\n",
              "      <td>0.999049</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>2164.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.110759</td>\n",
              "      <td>0.616606</td>\n",
              "      <td>0.878712</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>5158.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.383184</td>\n",
              "      <td>...</td>\n",
              "      <td>0.241724</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.139721</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>6060.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.151612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039702</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>4647.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.175844</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163995</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.655736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>7691.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.360991</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102685</td>\n",
              "      <td>0.175789</td>\n",
              "      <td>0.107135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>3906.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.275679</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269858</td>\n",
              "      <td>0.029223</td>\n",
              "      <td>0.702544</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>6185.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.588758</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275040</td>\n",
              "      <td>0.588897</td>\n",
              "      <td>0.734109</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>6870.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.932422</td>\n",
              "      <td>...</td>\n",
              "      <td>0.782134</td>\n",
              "      <td>0.703248</td>\n",
              "      <td>0.327329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>2866.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.845167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.272139</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>4222.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.135064</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057250</td>\n",
              "      <td>0.451185</td>\n",
              "      <td>0.046621</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>8027.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.293325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325304</td>\n",
              "      <td>0.013155</td>\n",
              "      <td>0.054804</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>6512.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.265413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.296780</td>\n",
              "      <td>0.014614</td>\n",
              "      <td>0.137578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>6693.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.057654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019544</td>\n",
              "      <td>0.047928</td>\n",
              "      <td>0.766103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>5563.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.059402</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020490</td>\n",
              "      <td>0.002562</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>1381.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105380</td>\n",
              "      <td>0.421179</td>\n",
              "      <td>0.067784</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>1759.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.264516</td>\n",
              "      <td>0.156127</td>\n",
              "      <td>0.159270</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>2979.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.124544</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009853</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.014213</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>6491.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.755924</td>\n",
              "      <td>...</td>\n",
              "      <td>0.146209</td>\n",
              "      <td>0.009869</td>\n",
              "      <td>0.000691</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>6160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.236024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145265</td>\n",
              "      <td>0.339349</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>7741.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.381112</td>\n",
              "      <td>...</td>\n",
              "      <td>0.255561</td>\n",
              "      <td>0.137586</td>\n",
              "      <td>0.998138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>6838.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114328</td>\n",
              "      <td>0.684588</td>\n",
              "      <td>0.976593</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>802.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.498922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.381218</td>\n",
              "      <td>0.491571</td>\n",
              "      <td>0.316437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>1488.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.693690</td>\n",
              "      <td>...</td>\n",
              "      <td>0.716076</td>\n",
              "      <td>0.171660</td>\n",
              "      <td>0.813228</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>8149.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.067107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063721</td>\n",
              "      <td>0.004905</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>7511.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093588</td>\n",
              "      <td>0.025617</td>\n",
              "      <td>0.663635</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59</td>\n",
              "      <td>7466.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.088620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064359</td>\n",
              "      <td>0.080446</td>\n",
              "      <td>0.251782</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>3663.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.127549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123271</td>\n",
              "      <td>0.066678</td>\n",
              "      <td>0.261592</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>863.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.447030</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023086</td>\n",
              "      <td>0.124501</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62</td>\n",
              "      <td>1160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.672137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402802</td>\n",
              "      <td>0.914565</td>\n",
              "      <td>0.382155</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>4441.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.586659</td>\n",
              "      <td>...</td>\n",
              "      <td>0.545001</td>\n",
              "      <td>0.341103</td>\n",
              "      <td>0.175451</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>2180.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.577181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.493996</td>\n",
              "      <td>0.786810</td>\n",
              "      <td>0.897202</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.811703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.803070</td>\n",
              "      <td>0.936791</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>1413.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.163895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024496</td>\n",
              "      <td>0.025096</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>7905.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.106086</td>\n",
              "      <td>0.083423</td>\n",
              "      <td>0.028335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ce6517e-54bb-49cd-a203-a892d7627b41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ce6517e-54bb-49cd-a203-a892d7627b41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ce6517e-54bb-49cd-a203-a892d7627b41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM7Dso33kDQVdrQ/kmW9geI",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}