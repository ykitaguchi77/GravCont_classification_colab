{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_test_validation_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "43ab3cd8-4a45-4bdc-9679-f49e54c2187f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 497 kB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 1 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "glav_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/grav\"\n",
        "cont_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/cont\"\n",
        "pretrained_model_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/RepVGG-A2.pth\"\n",
        "gradcam_folder_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/GradCam_EfficientNetB4_test_seed{}\".format(random_seed)\n",
        "result_csv_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/result_EfficientNetB4_test_seed{}.csv\".format(random_seed)\n",
        "confusion_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/confusion_EfficientNetB4_test_seed{}.png\".format(random_seed)\n",
        "ROC_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/ROC_EfficientNetB4_test_seed{}.png\".format(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradCAMんフォルダを作成\n",
        "if os.path.exists(gradcam_folder_path):\n",
        "    shutil.rmtree(gradcam_folder_path) \n",
        "os.makedirs(gradcam_folder_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "8LhOc6OjJQEt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ODB-njjTzV",
        "outputId": "38dfe960-2d71-410e-a8a2-aa8df23821c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 333, cont: 333\n"
          ]
        }
      ],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(glav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "b9dcd6ba-f113-45a1-fb11-044cf0dc88e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239\n",
            "60\n",
            "239\n",
            "60\n",
            "34\n",
            "34\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "#まず全体の1割をテストセットとしてよけておく\n",
        "remain_dataset_cont, test_dataset_cont = train_test_split(cont_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "remain_dataset_grav, test_dataset_grav = train_test_split(grav_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_cont):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_grav):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n",
        "print(len(test_dataset_cont))\n",
        "print(len(test_dataset_grav))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "3cd0b266-cbef-4aa2-cf3d-f84943478396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained repVGG model already exists\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ranger_adabelief\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "478\n",
            "120\n",
            "68\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "            \n",
        "            \n",
        "          \n",
        "\n",
        "            \"\"\"\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        p=0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}' + f'({running_corrects:.0f}/{len(test_dataset):.0f})') \n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "destination = pretrained_model_path\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "###############################\n",
        "##  GradCAM\n",
        "###############################\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset,  row=0, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"grav\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_folder_path+\"/row{}-label{}-pred{}.png\".format(row,classes[test_dataset[j][1]], classes[c]))\n",
        "            row += 1\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "test_list = test_dataset_grav + test_dataset_cont\n",
        "test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "print(len(test_list))\n",
        "\n",
        "\n",
        "\n",
        "######################\n",
        "##   Selecting model        \n",
        "######################\n",
        "from torchvision.models.regnet import RegNet\n",
        "!pip install ranger_adabelief\n",
        "def model_selection(model_name):\n",
        "    if model_name == \"EfficientNet-b4\":\n",
        "        model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "        num_ftrs = model_ft.classifier[1].in_features\n",
        "        model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "    elif model_name == \"RppVGG-A2\":\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2) \n",
        "    elif model_name == \"ResNet50\":\n",
        "        model_ft = torchvision.models.ResNet50(pretrained = True)\n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "    return model_ft\n",
        "\n",
        "######################\n",
        "##   Selecting optimizer     \n",
        "######################\n",
        "def optimizer_selection(optim_name):\n",
        "    scheduler = None\n",
        "    if optim_name == \"SGD\":\n",
        "        optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "    elif optim_name == \"AdamW\":\n",
        "        optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "    elif optim_name == \"AdaBound\":\n",
        "        optimizer_ft = optim.AdaBound(\n",
        "                model_ft.parameters(),\n",
        "                lr= 1e-3,\n",
        "                betas= (0.9, 0.999),\n",
        "                final_lr = 0.1,\n",
        "                gamma=1e-3,\n",
        "                eps= 1e-8,\n",
        "                weight_decay=0,\n",
        "                amsbound=False,\n",
        "            )\n",
        "    elif optim_name == \"AdaBelief\":\n",
        "        from ranger_adabelief import RangerAdaBelief\n",
        "        optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "    return optimizer_ft, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Select model and optimizer**"
      ],
      "metadata": {
        "id": "vFeEqzMoXHYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = model_selection(\"RppVGG-A2\")\n",
        "optimizer_ft, scheduler = optimizer_selection(\"AdaBelief\")"
      ],
      "metadata": {
        "id": "7zXoWcaKWs-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "Emm8lbTkXQOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2gmKzk9yPOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradcam(model_ft, test_dataset, row=0, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "id, number, path, label = [], [], [], []\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "for j in test_dataset_grav:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(1)\n",
        "    k+=1\n",
        "for j in test_dataset_cont:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(0)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "# k=0\n",
        "# for i in val_dataset_grav:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(1)\n",
        "#     k+=1\n",
        "# k=0\n",
        "# for i in val_dataset_cont:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(0)\n",
        "#     k+=1\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"img_id\", \"img_number\", \"path\",\"label\", \"pred_fold0\", \"pred_fold1\", \"pred_fold2\", \"pred_fold3\", \"pred_fold4\", \"prob_fold0\", \"prob_fold1\", \"prob_fold2\", \"prob_fold3\", \"prob_fold4\"])\n",
        "df_result[\"img_id\"] = id\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "print(result_csv_path)\n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9d33d8a-e69f-44dc-8431-dfc08e0b4da9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/666mai_dataset/result_EfficientNetB4_test_seed1.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    img_id img_number                                               path  \\\n",
              "0        0   1270.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "1        1   4710.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "2        2   3667.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "3        3     57.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "4        4   5297.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "5        5   2510.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "6        6   7709.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "7        7   2274.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "8        8   5397.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "9        9   2801.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "10      10   1378.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "11      11   2900.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "12      12   4272.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "13      13   4125.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "14      14    977.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "15      15   2794.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "16      16   2508.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "17      17   5901.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "18      18   2851.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "19      19   5051.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "20      20   4359.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "21      21   5540.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "22      22   6515.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "23      23   4958.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "24      24   5378.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "25      25   6106.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "26      26   6725.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "27      27   2042.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "28      28   6283.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "29      29   3331.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "30      30   3176.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "31      31   7527.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "32      32   3532.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "33      33   7349.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "34      34   2164.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "35      35   5158.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "36      36   6060.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "37      37   4647.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "38      38   7691.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "39      39   3906.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "40      40   6185.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "41      41   6870.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "42      42   2866.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "43      43   4222.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "44      44   8027.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "45      45   6512.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "46      46   6693.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "47      47   5563.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "48      48   1381.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "49      49   1759.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "50      50   2979.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "51      51   6491.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "52      52   6160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "53      53   7741.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "54      54   6838.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "55      55    802.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "56      56   1488.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "57      57   8149.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "58      58   7511.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "59      59   7466.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "60      60   3663.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "61      61    863.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "62      62   1160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "63      63   4441.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "64      64   2180.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "65      65    147.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "66      66   1413.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "67      67   7905.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "\n",
              "    label pred_fold0 pred_fold1 pred_fold2 pred_fold3 pred_fold4 prob_fold0  \\\n",
              "0       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "3       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "4       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "5       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "6       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "7       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "8       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "9       1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "10      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "11      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "12      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "13      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "14      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "15      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "16      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "17      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "18      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "19      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "20      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "21      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "22      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "23      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "24      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "25      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "26      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "27      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "28      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "29      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "30      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "31      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "32      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "33      1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "34      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "35      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "36      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "37      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "38      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "39      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "40      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "41      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "42      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "43      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "44      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "45      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "46      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "47      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "48      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "49      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "50      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "51      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "52      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "53      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "54      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "55      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "56      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "57      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "58      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "59      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "60      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "61      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "62      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "63      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "64      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "65      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "66      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "67      0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "\n",
              "   prob_fold1 prob_fold2 prob_fold3 prob_fold4  \n",
              "0         NaN        NaN        NaN        NaN  \n",
              "1         NaN        NaN        NaN        NaN  \n",
              "2         NaN        NaN        NaN        NaN  \n",
              "3         NaN        NaN        NaN        NaN  \n",
              "4         NaN        NaN        NaN        NaN  \n",
              "5         NaN        NaN        NaN        NaN  \n",
              "6         NaN        NaN        NaN        NaN  \n",
              "7         NaN        NaN        NaN        NaN  \n",
              "8         NaN        NaN        NaN        NaN  \n",
              "9         NaN        NaN        NaN        NaN  \n",
              "10        NaN        NaN        NaN        NaN  \n",
              "11        NaN        NaN        NaN        NaN  \n",
              "12        NaN        NaN        NaN        NaN  \n",
              "13        NaN        NaN        NaN        NaN  \n",
              "14        NaN        NaN        NaN        NaN  \n",
              "15        NaN        NaN        NaN        NaN  \n",
              "16        NaN        NaN        NaN        NaN  \n",
              "17        NaN        NaN        NaN        NaN  \n",
              "18        NaN        NaN        NaN        NaN  \n",
              "19        NaN        NaN        NaN        NaN  \n",
              "20        NaN        NaN        NaN        NaN  \n",
              "21        NaN        NaN        NaN        NaN  \n",
              "22        NaN        NaN        NaN        NaN  \n",
              "23        NaN        NaN        NaN        NaN  \n",
              "24        NaN        NaN        NaN        NaN  \n",
              "25        NaN        NaN        NaN        NaN  \n",
              "26        NaN        NaN        NaN        NaN  \n",
              "27        NaN        NaN        NaN        NaN  \n",
              "28        NaN        NaN        NaN        NaN  \n",
              "29        NaN        NaN        NaN        NaN  \n",
              "30        NaN        NaN        NaN        NaN  \n",
              "31        NaN        NaN        NaN        NaN  \n",
              "32        NaN        NaN        NaN        NaN  \n",
              "33        NaN        NaN        NaN        NaN  \n",
              "34        NaN        NaN        NaN        NaN  \n",
              "35        NaN        NaN        NaN        NaN  \n",
              "36        NaN        NaN        NaN        NaN  \n",
              "37        NaN        NaN        NaN        NaN  \n",
              "38        NaN        NaN        NaN        NaN  \n",
              "39        NaN        NaN        NaN        NaN  \n",
              "40        NaN        NaN        NaN        NaN  \n",
              "41        NaN        NaN        NaN        NaN  \n",
              "42        NaN        NaN        NaN        NaN  \n",
              "43        NaN        NaN        NaN        NaN  \n",
              "44        NaN        NaN        NaN        NaN  \n",
              "45        NaN        NaN        NaN        NaN  \n",
              "46        NaN        NaN        NaN        NaN  \n",
              "47        NaN        NaN        NaN        NaN  \n",
              "48        NaN        NaN        NaN        NaN  \n",
              "49        NaN        NaN        NaN        NaN  \n",
              "50        NaN        NaN        NaN        NaN  \n",
              "51        NaN        NaN        NaN        NaN  \n",
              "52        NaN        NaN        NaN        NaN  \n",
              "53        NaN        NaN        NaN        NaN  \n",
              "54        NaN        NaN        NaN        NaN  \n",
              "55        NaN        NaN        NaN        NaN  \n",
              "56        NaN        NaN        NaN        NaN  \n",
              "57        NaN        NaN        NaN        NaN  \n",
              "58        NaN        NaN        NaN        NaN  \n",
              "59        NaN        NaN        NaN        NaN  \n",
              "60        NaN        NaN        NaN        NaN  \n",
              "61        NaN        NaN        NaN        NaN  \n",
              "62        NaN        NaN        NaN        NaN  \n",
              "63        NaN        NaN        NaN        NaN  \n",
              "64        NaN        NaN        NaN        NaN  \n",
              "65        NaN        NaN        NaN        NaN  \n",
              "66        NaN        NaN        NaN        NaN  \n",
              "67        NaN        NaN        NaN        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db49caa7-932a-46eb-a985-47b4ea37c785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred_fold0</th>\n",
              "      <th>pred_fold1</th>\n",
              "      <th>pred_fold2</th>\n",
              "      <th>pred_fold3</th>\n",
              "      <th>pred_fold4</th>\n",
              "      <th>prob_fold0</th>\n",
              "      <th>prob_fold1</th>\n",
              "      <th>prob_fold2</th>\n",
              "      <th>prob_fold3</th>\n",
              "      <th>prob_fold4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1270.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4710.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3667.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>57.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5297.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2510.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7709.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2274.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5397.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2801.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>1378.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>2900.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>4272.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>4125.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>977.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>2794.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>2508.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>5901.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>2851.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>5051.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>4359.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>5540.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>6515.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>4958.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>5378.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>6106.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>6725.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>2042.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>6283.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>3331.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>3176.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>7527.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>3532.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>7349.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>2164.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>5158.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>6060.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>4647.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>7691.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>3906.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>6185.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>6870.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>2866.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>4222.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>8027.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>6512.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>6693.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>5563.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>1381.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>1759.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>2979.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>6491.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>6160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>7741.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>6838.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>802.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>1488.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>8149.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>7511.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59</td>\n",
              "      <td>7466.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>3663.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>863.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62</td>\n",
              "      <td>1160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>4441.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>2180.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>1413.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>7905.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db49caa7-932a-46eb-a985-47b4ea37c785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db49caa7-932a-46eb-a985-47b4ea37c785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db49caa7-932a-46eb-a985-47b4ea37c785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) "
      ],
      "metadata": {
        "id": "s_XNgvXXImWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select model and optimizer\n",
        "model_name = \"RppVGG-A2\"\n",
        "optim_name = \"AdaBelief\""
      ],
      "metadata": {
        "id": "FTDD3IVDXoBG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 0\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "    test_list = test_dataset_grav + test_dataset_cont\n",
        "    test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "    test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    model_ft = model_selection(model_name)\n",
        "    optimizer_ft, scheduler = optimizer_selection(optim_name)\n",
        "    # # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # # num_ftrs = model_ft.fc.in_features\n",
        "    # # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    # model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "    # #model_ft = create_RepVGG_A2(deploy=False)\n",
        "    # #model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    # num_ftrs = model_ft.classifier[1].in_features\n",
        "    # model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    # from ranger_adabelief import RangerAdaBelief\n",
        "    # optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    #optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "    # optimizer_ft = optim.AdaBound(\n",
        "    #         model_ft.parameters(),\n",
        "    #         lr= 1e-3,\n",
        "    #         betas= (0.9, 0.999),\n",
        "    #         final_lr = 0.1,\n",
        "    #         gamma=1e-3,\n",
        "    #         eps= 1e-8,\n",
        "    #         weight_decay=0,\n",
        "    #         amsbound=False,\n",
        "    #     )\n",
        "    \n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    \n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    column_pred = 4 + fold\n",
        "    column_prob = 9 + fold\n",
        "\n",
        "    df_result.iloc[row:row+len(y_pred)-1, column_pred] = y_pred\n",
        "    df_result.iloc[row:row+len(y_pred)-1, column_prob] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    #gradcam(model_ft, val_dataset, row, save=True) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "Uh_aAup_hd5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "LxNos2lRIQao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#################################################\n",
        "threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "#################################################\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "\n",
        "X = df_result[\"prob\"]\n",
        "Y = df_result[\"label\"]\n",
        "\n",
        "Y_pred_proba = X\n",
        "Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "acc = accuracy_score(Y, Y_pred)\n",
        "print('Accuracy:',acc)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "#5-fold分のconfusion matrixを加算\n",
        "confusion_arr += confusion_matrix(Y, Y_pred)\n",
        "\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "\n",
        "#ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "# accuracy.append(accuracy_score(Y, Y_pred))\n",
        "# precision.append(precision_score(Y, Y_pred))\n",
        "# recall.append(recall_score(Y, Y_pred))\n",
        "# specificity.append(specificity_score(Y, Y_pred))\n",
        "# f1score.append(f1_score(Y, Y_pred))\n",
        "# area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#ヒートマップを作成\n",
        "arr_2d = np.round(confusion_arr).astype(int) \n",
        "df_matrix = pd.DataFrame(data=arr_2d, index=[\"Normal\", \"TED\"], columns=[\"Normal\", \"TED\"])\n",
        "print(df_matrix)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(df_matrix, annot=True,fmt=\"d\", cmap='Blues')\n",
        "plt.savefig(confusion_path, dpi=700)\n",
        "plt.show()\n",
        "plt.close('all')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NmOJDYqaQEwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr,tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.savefig(ROC_path, format=\"png\", dpi=700)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = [1]\n",
        "fig = Draw_roc_curve([Y], [Y_pred_proba], roc_label_list, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cb48jClLk24l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#統計結果を追記\n",
        "df_result['statistics'] = np.nan\n",
        "df_result['result'] = np.nan\n",
        "df_result.loc[0:5, 'statistics'] = [\"Accuracy\", \"Positive predictive value\", \"Sensitivity\", \"Specificity\", \"F-score\", \"Area_under_ROC\", \"model\", \"optimizer\", \"Rand_seed\"]\n",
        "df_result.loc[0:5, 'result'] = [accuracy_score(Y, Y_pred), precision_score(Y, Y_pred), recall_score(Y, Y_pred), specificity_score(Y, Y_pred), f1_score(Y, Y_pred), roc_auc_score(Y, Y_pred_proba), model_name, optim_name, random_seed]"
      ],
      "metadata": {
        "id": "oBo9g2XsnJA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) \n",
        "df_result"
      ],
      "metadata": {
        "id": "gSRr_lYTnF8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HkMWSdP6oGxs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMUd65PEbrKjR6amPD8JHpd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}