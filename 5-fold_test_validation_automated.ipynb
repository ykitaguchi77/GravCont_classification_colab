{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_test_validation_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "65680c32-e7a2-4e11-fd46-8e6128d72427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 454 kB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 1 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "glav_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/grav\"\n",
        "cont_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/cont\"\n",
        "pretrained_model_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/RepVGG-A2.pth\"\n",
        "gradcam_folder_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/GradCam_EfficientNetB4_test_seed{}\".format(random_seed)\n",
        "result_csv_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/result_EfficientNetB4_test_seed{}.csv\".format(random_seed)\n",
        "confusion_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/confusion_EfficientNetB4_test_seed{}.png\".format(random_seed)\n",
        "ROC_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/ROC_EfficientNetB4_test_seed{}.png\".format(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradCAMんフォルダを作成\n",
        "if os.path.exists(gradcam_folder_path):\n",
        "    shutil.rmtree(gradcam_folder_path) \n",
        "os.makedirs(gradcam_folder_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "8LhOc6OjJQEt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ODB-njjTzV",
        "outputId": "58edfb4e-5757-4796-8e35-0dc3e4b00b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 333, cont: 333\n"
          ]
        }
      ],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(glav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "f8c6fd0e-3b43-494c-eec2-3e95f304ca03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239\n",
            "60\n",
            "239\n",
            "60\n",
            "34\n",
            "34\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "#まず全体の1割をテストセットとしてよけておく\n",
        "remain_dataset_cont, test_dataset_cont = train_test_split(cont_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "remain_dataset_grav, test_dataset_grav = train_test_split(grav_path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_cont):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(remain_dataset_cont[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_dataset_grav):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(remain_dataset_grav[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n",
        "print(len(test_dataset_cont))\n",
        "print(len(test_dataset_grav))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "a290a0f0-b488-48d1-8e9b-416d14b87d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained repVGG model already exists\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ranger_adabelief\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "478\n",
            "120\n",
            "68\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "            \n",
        "            \n",
        "          \n",
        "\n",
        "            \"\"\"\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        p=0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}' + f'({running_corrects:.0f}/{len(test_dataset):.0f})') \n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "destination = pretrained_model_path\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "###############################\n",
        "##  GradCAM\n",
        "###############################\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset,  row=0, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"grav\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_folder_path+\"/row{}-label{}-pred{}.png\".format(row,classes[test_dataset[j][1]], classes[c]))\n",
        "            row += 1\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "test_list = test_dataset_grav + test_dataset_cont\n",
        "test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "print(len(test_list))\n",
        "\n",
        "\n",
        "\n",
        "######################\n",
        "##   Selecting model        \n",
        "######################\n",
        "from torchvision.models.regnet import RegNet\n",
        "!pip install ranger_adabelief\n",
        "def model_selection(model_name):\n",
        "    if model_name == \"EfficientNet-b4\":\n",
        "        model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "        num_ftrs = model_ft.classifier[1].in_features\n",
        "        model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "    elif model_name == \"RppVGG-A2\":\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2) \n",
        "    elif model_name == \"ResNet50\":\n",
        "        model_ft = torchvision.models.ResNet50(pretrained = True)\n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "    return model_ft\n",
        "\n",
        "######################\n",
        "##   Selecting optimizer     \n",
        "######################\n",
        "def optimizer_selection(optim_name):\n",
        "    scheduler = None\n",
        "    if optim_name == \"SGD\":\n",
        "        optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "    elif optim_name == \"AdamW\":\n",
        "        optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "    elif optim_name == \"AdaBound\":\n",
        "        optimizer_ft = optim.AdaBound(\n",
        "                model_ft.parameters(),\n",
        "                lr= 1e-3,\n",
        "                betas= (0.9, 0.999),\n",
        "                final_lr = 0.1,\n",
        "                gamma=1e-3,\n",
        "                eps= 1e-8,\n",
        "                weight_decay=0,\n",
        "                amsbound=False,\n",
        "            )\n",
        "    elif optim_name == \"AdaBelief\":\n",
        "        from ranger_adabelief import RangerAdaBelief\n",
        "        optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "    return optimizer_ft, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Select model and optimizer**"
      ],
      "metadata": {
        "id": "vFeEqzMoXHYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = model_selection(\"RppVGG-A2\")\n",
        "optimizer_ft, scheduler = optimizer_selection(\"AdaBelief\")"
      ],
      "metadata": {
        "id": "7zXoWcaKWs-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "Emm8lbTkXQOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2gmKzk9yPOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradcam(model_ft, test_dataset, row=0, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "id, number, path, label = [], [], [], []\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "for j in test_dataset_grav:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(1)\n",
        "    k+=1\n",
        "for j in test_dataset_cont:\n",
        "    id.append(k)\n",
        "    number.append(os.path.basename(j))\n",
        "    path.append(j)\n",
        "    label.append(0)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "# k=0\n",
        "# for i in val_dataset_grav:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(1)\n",
        "#     k+=1\n",
        "# k=0\n",
        "# for i in val_dataset_cont:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(0)\n",
        "#     k+=1\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"img_id\", \"img_number\", \"path\",\"label\", \"pred_fold0\", \"pred_fold1\", \"pred_fold2\", \"pred_fold3\", \"pred_fold4\", \"prob_fold0\", \"prob_fold1\", \"prob_fold2\", \"prob_fold3\", \"prob_fold4\"])\n",
        "df_result[\"img_id\"] = id\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "print(result_csv_path)\n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) "
      ],
      "metadata": {
        "id": "s_XNgvXXImWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select model and optimizer\n",
        "model_name = \"RppVGG-A2\"\n",
        "optim_name = \"AdaBelief\""
      ],
      "metadata": {
        "id": "FTDD3IVDXoBG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 0\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "    test_list = test_dataset_grav + test_dataset_cont\n",
        "    test_list_label = list(itertools.repeat(1, len(test_dataset_grav)))+list(itertools.repeat(0, len(test_dataset_cont)))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "    test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    model_ft = model_selection(model_name)\n",
        "    optimizer_ft, scheduler = optimizer_selection(optim_name)\n",
        "    # # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # # num_ftrs = model_ft.fc.in_features\n",
        "    # # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    # model_ft = torchvision.models.efficientnet_b4(pretrained = True)\n",
        "    # #model_ft = create_RepVGG_A2(deploy=False)\n",
        "    # #model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    # num_ftrs = model_ft.classifier[1].in_features\n",
        "    # model_ft.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    # from ranger_adabelief import RangerAdaBelief\n",
        "    # optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    #optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "    # optimizer_ft = optim.AdaBound(\n",
        "    #         model_ft.parameters(),\n",
        "    #         lr= 1e-3,\n",
        "    #         betas= (0.9, 0.999),\n",
        "    #         final_lr = 0.1,\n",
        "    #         gamma=1e-3,\n",
        "    #         eps= 1e-8,\n",
        "    #         weight_decay=0,\n",
        "    #         amsbound=False,\n",
        "    #     )\n",
        "    \n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    \n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    column_pred = 4 + fold\n",
        "    column_prob = 9 + fold\n",
        "\n",
        "    df_result.iloc[row:row+len(y_pred), column_pred] = y_pred\n",
        "    df_result.iloc[row:row+len(y_pred), column_prob] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    #gradcam(model_ft, val_dataset, row, save=True) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "Uh_aAup_hd5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "LxNos2lRIQao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d8faa8e-e6b9-45bc-a344-d53661fc69fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    img_id img_number                                               path  \\\n",
              "0        0   1270.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "1        1   4710.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "2        2   3667.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "3        3     57.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "4        4   5297.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "5        5   2510.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "6        6   7709.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "7        7   2274.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "8        8   5397.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "9        9   2801.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "10      10   1378.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "11      11   2900.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "12      12   4272.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "13      13   4125.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "14      14    977.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "15      15   2794.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "16      16   2508.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "17      17   5901.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "18      18   2851.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "19      19   5051.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "20      20   4359.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "21      21   5540.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "22      22   6515.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "23      23   4958.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "24      24   5378.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "25      25   6106.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "26      26   6725.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "27      27   2042.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "28      28   6283.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "29      29   3331.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "30      30   3176.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "31      31   7527.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "32      32   3532.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "33      33   7349.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "34      34   2164.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "35      35   5158.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "36      36   6060.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "37      37   4647.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "38      38   7691.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "39      39   3906.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "40      40   6185.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "41      41   6870.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "42      42   2866.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "43      43   4222.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "44      44   8027.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "45      45   6512.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "46      46   6693.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "47      47   5563.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "48      48   1381.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "49      49   1759.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "50      50   2979.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "51      51   6491.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "52      52   6160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "53      53   7741.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "54      54   6838.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "55      55    802.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "56      56   1488.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "57      57   8149.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "58      58   7511.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "59      59   7466.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "60      60   3663.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "61      61    863.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "62      62   1160.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "63      63   4441.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "64      64   2180.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "65      65    147.JPG  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "66      66   1413.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "67      67   7905.jpg  /content/drive/MyDrive/Deep_learning/666mai_da...   \n",
              "\n",
              "    label  pred_fold0  pred_fold1  pred_fold2  pred_fold3  pred_fold4  \\\n",
              "0       1           1           1           1           1           1   \n",
              "1       1           1           1           1           1           1   \n",
              "2       1           1           1           1           1           1   \n",
              "3       1           1           1           1           1           1   \n",
              "4       1           1           1           1           0           1   \n",
              "5       1           1           1           1           1           1   \n",
              "6       1           0           0           0           1           1   \n",
              "7       1           0           0           0           0           0   \n",
              "8       1           1           1           1           1           1   \n",
              "9       1           0           0           0           1           0   \n",
              "10      1           1           1           1           0           1   \n",
              "11      1           1           1           0           1           1   \n",
              "12      1           1           1           1           1           1   \n",
              "13      1           0           0           0           0           0   \n",
              "14      1           1           1           1           1           1   \n",
              "15      1           0           0           0           1           1   \n",
              "16      1           1           1           1           1           1   \n",
              "17      1           1           0           0           0           0   \n",
              "18      1           1           1           1           1           1   \n",
              "19      1           1           0           0           0           1   \n",
              "20      1           1           1           1           1           1   \n",
              "21      1           1           1           1           1           1   \n",
              "22      1           1           1           0           1           1   \n",
              "23      1           1           0           0           1           1   \n",
              "24      1           1           1           1           1           1   \n",
              "25      1           1           1           1           1           1   \n",
              "26      1           0           0           0           1           1   \n",
              "27      1           1           1           1           1           1   \n",
              "28      1           1           1           0           1           1   \n",
              "29      1           1           1           1           1           1   \n",
              "30      1           0           0           0           0           0   \n",
              "31      1           1           0           0           0           1   \n",
              "32      1           1           1           1           1           1   \n",
              "33      1           1           1           1           1           1   \n",
              "34      0           0           1           0           1           1   \n",
              "35      0           0           0           0           0           0   \n",
              "36      0           0           0           0           0           0   \n",
              "37      0           0           1           0           0           1   \n",
              "38      0           0           0           0           0           0   \n",
              "39      0           0           0           0           0           1   \n",
              "40      0           1           0           0           1           1   \n",
              "41      0           1           1           1           1           0   \n",
              "42      0           1           0           0           0           0   \n",
              "43      0           0           0           0           0           0   \n",
              "44      0           0           0           0           0           0   \n",
              "45      0           0           0           0           0           0   \n",
              "46      0           0           0           0           0           1   \n",
              "47      0           0           0           0           0           0   \n",
              "48      0           0           0           0           0           0   \n",
              "49      0           1           0           0           0           0   \n",
              "50      0           0           0           0           0           0   \n",
              "51      0           1           0           0           0           0   \n",
              "52      0           0           0           0           0           0   \n",
              "53      0           0           0           0           0           1   \n",
              "54      0           0           1           0           1           1   \n",
              "55      0           0           0           0           0           0   \n",
              "56      0           1           0           1           0           1   \n",
              "57      0           0           0           0           0           0   \n",
              "58      0           0           0           0           0           1   \n",
              "59      0           0           0           0           0           0   \n",
              "60      0           0           0           0           0           0   \n",
              "61      0           0           0           0           0           0   \n",
              "62      0           1           0           0           1           0   \n",
              "63      0           1           0           1           0           0   \n",
              "64      0           1           0           0           1           1   \n",
              "65      0           1           0           0           1           1   \n",
              "66      0           0           0           0           0           0   \n",
              "67      0           0           0           0           0           0   \n",
              "\n",
              "    prob_fold0  prob_fold1  prob_fold2  prob_fold3  prob_fold4  \n",
              "0     0.970870    0.999716    0.925896    0.996183    1.000000  \n",
              "1     0.972487    0.958145    0.746095    0.999580    0.980783  \n",
              "2     0.995442    0.973049    0.986112    0.998199    0.999599  \n",
              "3     0.996655    0.999746    0.997798    0.999997    0.999818  \n",
              "4     0.893761    0.552155    0.527242    0.295002    0.776796  \n",
              "5     0.991097    0.998814    0.996259    0.999533    0.999995  \n",
              "6     0.488850    0.173383    0.386147    0.905765    0.878194  \n",
              "7     0.178603    0.290108    0.113201    0.282480    0.490502  \n",
              "8     0.847660    0.929368    0.524096    0.924842    0.999626  \n",
              "9     0.339571    0.170156    0.458113    0.953091    0.146427  \n",
              "10    0.616606    0.517638    0.641767    0.414348    0.994130  \n",
              "11    0.654624    0.988733    0.421226    0.996910    1.000000  \n",
              "12    0.982193    0.999573    0.975631    0.999888    1.000000  \n",
              "13    0.107017    0.031277    0.174246    0.056537    0.000009  \n",
              "14    0.846186    0.815550    0.915977    0.994098    0.999954  \n",
              "15    0.440337    0.352047    0.169934    0.882862    0.925970  \n",
              "16    0.998695    0.994677    0.999497    0.999994    1.000000  \n",
              "17    0.758219    0.049432    0.242544    0.248582    0.240194  \n",
              "18    0.995757    0.856845    0.977316    0.999338    0.988358  \n",
              "19    0.785806    0.060587    0.385291    0.427170    0.575307  \n",
              "20    0.996526    0.824478    0.842954    0.998874    0.985340  \n",
              "21    0.999515    0.960963    0.978409    0.999720    0.999999  \n",
              "22    0.958747    0.676798    0.253111    0.949052    0.870348  \n",
              "23    0.706524    0.366057    0.228376    0.997296    0.999799  \n",
              "24    0.992446    0.994584    0.989547    0.999953    0.998485  \n",
              "25    0.995248    0.998407    0.996725    0.999905    0.999997  \n",
              "26    0.478922    0.440755    0.147883    0.784534    0.869700  \n",
              "27    0.983918    0.972259    0.991390    0.964332    0.996900  \n",
              "28    0.677612    0.845815    0.353882    0.989971    0.896144  \n",
              "29    0.861812    0.991934    0.990647    0.999711    1.000000  \n",
              "30    0.453912    0.027060    0.465092    0.011641    0.106345  \n",
              "31    0.765069    0.345355    0.444435    0.407101    0.954137  \n",
              "32    0.927477    0.977205    0.968381    0.997935    0.999975  \n",
              "33    0.890825    0.907439    0.889815    0.999764    0.999049  \n",
              "34    0.111976    0.747036    0.110759    0.616606    0.878712  \n",
              "35    0.383184    0.388848    0.241724    0.048569    0.139721  \n",
              "36    0.151612    0.075407    0.039702    0.004495    0.000089  \n",
              "37    0.175844    0.575994    0.163995    0.095000    0.655736  \n",
              "38    0.360991    0.022393    0.102685    0.175789    0.107135  \n",
              "39    0.275679    0.040317    0.269858    0.029223    0.702544  \n",
              "40    0.588758    0.390923    0.275040    0.588897    0.734109  \n",
              "41    0.932422    0.970269    0.782134    0.703248    0.327329  \n",
              "42    0.845167    0.003662    0.272139    0.005590    0.001208  \n",
              "43    0.135064    0.017362    0.057250    0.451185    0.046621  \n",
              "44    0.293325    0.117677    0.325304    0.013155    0.054804  \n",
              "45    0.265413    0.023457    0.296780    0.014614    0.137578  \n",
              "46    0.057654    0.019000    0.019544    0.047928    0.766103  \n",
              "47    0.059402    0.013928    0.020490    0.002562    0.000001  \n",
              "48    0.307824    0.147980    0.105380    0.421179    0.067784  \n",
              "49    0.560647    0.217177    0.264516    0.156127    0.159270  \n",
              "50    0.124544    0.001751    0.009853    0.002413    0.014213  \n",
              "51    0.755924    0.054322    0.146209    0.009869    0.000691  \n",
              "52    0.236024    0.012929    0.145265    0.339349    0.012941  \n",
              "53    0.381112    0.305473    0.255561    0.137586    0.998138  \n",
              "54    0.200009    0.617885    0.114328    0.684588    0.976593  \n",
              "55    0.498922    0.242150    0.381218    0.491571    0.316437  \n",
              "56    0.693690    0.404977    0.716076    0.171660    0.813228  \n",
              "57    0.067107    0.046322    0.063721    0.004905    0.000009  \n",
              "58    0.031459    0.029653    0.093588    0.025617    0.663635  \n",
              "59    0.088620    0.484220    0.064359    0.080446    0.251782  \n",
              "60    0.127549    0.050952    0.123271    0.066678    0.261592  \n",
              "61    0.447030    0.018577    0.023086    0.124501    0.227451  \n",
              "62    0.672137    0.063269    0.402802    0.914565    0.382155  \n",
              "63    0.586659    0.145182    0.545001    0.341103    0.175451  \n",
              "64    0.577181    0.102682    0.493996    0.786810    0.897202  \n",
              "65    0.811703    0.049817    0.231164    0.803070    0.936791  \n",
              "66    0.163895    0.040690    0.024496    0.025096    0.003818  \n",
              "67    0.061177    0.039082    0.106086    0.083423    0.028335  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d6ca5f6-d70a-415a-bbb3-2c2c37e44739\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred_fold0</th>\n",
              "      <th>pred_fold1</th>\n",
              "      <th>pred_fold2</th>\n",
              "      <th>pred_fold3</th>\n",
              "      <th>pred_fold4</th>\n",
              "      <th>prob_fold0</th>\n",
              "      <th>prob_fold1</th>\n",
              "      <th>prob_fold2</th>\n",
              "      <th>prob_fold3</th>\n",
              "      <th>prob_fold4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1270.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.970870</td>\n",
              "      <td>0.999716</td>\n",
              "      <td>0.925896</td>\n",
              "      <td>0.996183</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4710.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.972487</td>\n",
              "      <td>0.958145</td>\n",
              "      <td>0.746095</td>\n",
              "      <td>0.999580</td>\n",
              "      <td>0.980783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3667.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995442</td>\n",
              "      <td>0.973049</td>\n",
              "      <td>0.986112</td>\n",
              "      <td>0.998199</td>\n",
              "      <td>0.999599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>57.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996655</td>\n",
              "      <td>0.999746</td>\n",
              "      <td>0.997798</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>0.999818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5297.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.893761</td>\n",
              "      <td>0.552155</td>\n",
              "      <td>0.527242</td>\n",
              "      <td>0.295002</td>\n",
              "      <td>0.776796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2510.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.991097</td>\n",
              "      <td>0.998814</td>\n",
              "      <td>0.996259</td>\n",
              "      <td>0.999533</td>\n",
              "      <td>0.999995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7709.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488850</td>\n",
              "      <td>0.173383</td>\n",
              "      <td>0.386147</td>\n",
              "      <td>0.905765</td>\n",
              "      <td>0.878194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2274.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.178603</td>\n",
              "      <td>0.290108</td>\n",
              "      <td>0.113201</td>\n",
              "      <td>0.282480</td>\n",
              "      <td>0.490502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5397.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.847660</td>\n",
              "      <td>0.929368</td>\n",
              "      <td>0.524096</td>\n",
              "      <td>0.924842</td>\n",
              "      <td>0.999626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2801.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.339571</td>\n",
              "      <td>0.170156</td>\n",
              "      <td>0.458113</td>\n",
              "      <td>0.953091</td>\n",
              "      <td>0.146427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>1378.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.616606</td>\n",
              "      <td>0.517638</td>\n",
              "      <td>0.641767</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.994130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>2900.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.654624</td>\n",
              "      <td>0.988733</td>\n",
              "      <td>0.421226</td>\n",
              "      <td>0.996910</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>4272.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.982193</td>\n",
              "      <td>0.999573</td>\n",
              "      <td>0.975631</td>\n",
              "      <td>0.999888</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>4125.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.107017</td>\n",
              "      <td>0.031277</td>\n",
              "      <td>0.174246</td>\n",
              "      <td>0.056537</td>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>977.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.846186</td>\n",
              "      <td>0.815550</td>\n",
              "      <td>0.915977</td>\n",
              "      <td>0.994098</td>\n",
              "      <td>0.999954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>2794.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.440337</td>\n",
              "      <td>0.352047</td>\n",
              "      <td>0.169934</td>\n",
              "      <td>0.882862</td>\n",
              "      <td>0.925970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>2508.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998695</td>\n",
              "      <td>0.994677</td>\n",
              "      <td>0.999497</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>5901.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>0.049432</td>\n",
              "      <td>0.242544</td>\n",
              "      <td>0.248582</td>\n",
              "      <td>0.240194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>2851.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995757</td>\n",
              "      <td>0.856845</td>\n",
              "      <td>0.977316</td>\n",
              "      <td>0.999338</td>\n",
              "      <td>0.988358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>5051.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785806</td>\n",
              "      <td>0.060587</td>\n",
              "      <td>0.385291</td>\n",
              "      <td>0.427170</td>\n",
              "      <td>0.575307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>4359.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996526</td>\n",
              "      <td>0.824478</td>\n",
              "      <td>0.842954</td>\n",
              "      <td>0.998874</td>\n",
              "      <td>0.985340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>5540.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999515</td>\n",
              "      <td>0.960963</td>\n",
              "      <td>0.978409</td>\n",
              "      <td>0.999720</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>6515.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958747</td>\n",
              "      <td>0.676798</td>\n",
              "      <td>0.253111</td>\n",
              "      <td>0.949052</td>\n",
              "      <td>0.870348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>4958.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.706524</td>\n",
              "      <td>0.366057</td>\n",
              "      <td>0.228376</td>\n",
              "      <td>0.997296</td>\n",
              "      <td>0.999799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>5378.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.992446</td>\n",
              "      <td>0.994584</td>\n",
              "      <td>0.989547</td>\n",
              "      <td>0.999953</td>\n",
              "      <td>0.998485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>6106.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995248</td>\n",
              "      <td>0.998407</td>\n",
              "      <td>0.996725</td>\n",
              "      <td>0.999905</td>\n",
              "      <td>0.999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>6725.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.478922</td>\n",
              "      <td>0.440755</td>\n",
              "      <td>0.147883</td>\n",
              "      <td>0.784534</td>\n",
              "      <td>0.869700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>2042.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983918</td>\n",
              "      <td>0.972259</td>\n",
              "      <td>0.991390</td>\n",
              "      <td>0.964332</td>\n",
              "      <td>0.996900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>6283.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.677612</td>\n",
              "      <td>0.845815</td>\n",
              "      <td>0.353882</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.896144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>3331.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861812</td>\n",
              "      <td>0.991934</td>\n",
              "      <td>0.990647</td>\n",
              "      <td>0.999711</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>3176.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.453912</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>0.465092</td>\n",
              "      <td>0.011641</td>\n",
              "      <td>0.106345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>7527.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.765069</td>\n",
              "      <td>0.345355</td>\n",
              "      <td>0.444435</td>\n",
              "      <td>0.407101</td>\n",
              "      <td>0.954137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>3532.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927477</td>\n",
              "      <td>0.977205</td>\n",
              "      <td>0.968381</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>0.999975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>7349.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.890825</td>\n",
              "      <td>0.907439</td>\n",
              "      <td>0.889815</td>\n",
              "      <td>0.999764</td>\n",
              "      <td>0.999049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>2164.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111976</td>\n",
              "      <td>0.747036</td>\n",
              "      <td>0.110759</td>\n",
              "      <td>0.616606</td>\n",
              "      <td>0.878712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>5158.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.383184</td>\n",
              "      <td>0.388848</td>\n",
              "      <td>0.241724</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.139721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>6060.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.151612</td>\n",
              "      <td>0.075407</td>\n",
              "      <td>0.039702</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.000089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>4647.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.175844</td>\n",
              "      <td>0.575994</td>\n",
              "      <td>0.163995</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.655736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>7691.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.360991</td>\n",
              "      <td>0.022393</td>\n",
              "      <td>0.102685</td>\n",
              "      <td>0.175789</td>\n",
              "      <td>0.107135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>3906.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.275679</td>\n",
              "      <td>0.040317</td>\n",
              "      <td>0.269858</td>\n",
              "      <td>0.029223</td>\n",
              "      <td>0.702544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>6185.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.588758</td>\n",
              "      <td>0.390923</td>\n",
              "      <td>0.275040</td>\n",
              "      <td>0.588897</td>\n",
              "      <td>0.734109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>6870.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.932422</td>\n",
              "      <td>0.970269</td>\n",
              "      <td>0.782134</td>\n",
              "      <td>0.703248</td>\n",
              "      <td>0.327329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>2866.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.845167</td>\n",
              "      <td>0.003662</td>\n",
              "      <td>0.272139</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.001208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>4222.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.135064</td>\n",
              "      <td>0.017362</td>\n",
              "      <td>0.057250</td>\n",
              "      <td>0.451185</td>\n",
              "      <td>0.046621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>8027.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.293325</td>\n",
              "      <td>0.117677</td>\n",
              "      <td>0.325304</td>\n",
              "      <td>0.013155</td>\n",
              "      <td>0.054804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>6512.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.265413</td>\n",
              "      <td>0.023457</td>\n",
              "      <td>0.296780</td>\n",
              "      <td>0.014614</td>\n",
              "      <td>0.137578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>6693.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.057654</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.019544</td>\n",
              "      <td>0.047928</td>\n",
              "      <td>0.766103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>5563.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.059402</td>\n",
              "      <td>0.013928</td>\n",
              "      <td>0.020490</td>\n",
              "      <td>0.002562</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>1381.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307824</td>\n",
              "      <td>0.147980</td>\n",
              "      <td>0.105380</td>\n",
              "      <td>0.421179</td>\n",
              "      <td>0.067784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>1759.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560647</td>\n",
              "      <td>0.217177</td>\n",
              "      <td>0.264516</td>\n",
              "      <td>0.156127</td>\n",
              "      <td>0.159270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>2979.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.124544</td>\n",
              "      <td>0.001751</td>\n",
              "      <td>0.009853</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.014213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>6491.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.755924</td>\n",
              "      <td>0.054322</td>\n",
              "      <td>0.146209</td>\n",
              "      <td>0.009869</td>\n",
              "      <td>0.000691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>6160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.236024</td>\n",
              "      <td>0.012929</td>\n",
              "      <td>0.145265</td>\n",
              "      <td>0.339349</td>\n",
              "      <td>0.012941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>7741.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.381112</td>\n",
              "      <td>0.305473</td>\n",
              "      <td>0.255561</td>\n",
              "      <td>0.137586</td>\n",
              "      <td>0.998138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>6838.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200009</td>\n",
              "      <td>0.617885</td>\n",
              "      <td>0.114328</td>\n",
              "      <td>0.684588</td>\n",
              "      <td>0.976593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>802.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.498922</td>\n",
              "      <td>0.242150</td>\n",
              "      <td>0.381218</td>\n",
              "      <td>0.491571</td>\n",
              "      <td>0.316437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>1488.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.693690</td>\n",
              "      <td>0.404977</td>\n",
              "      <td>0.716076</td>\n",
              "      <td>0.171660</td>\n",
              "      <td>0.813228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>8149.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.067107</td>\n",
              "      <td>0.046322</td>\n",
              "      <td>0.063721</td>\n",
              "      <td>0.004905</td>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>7511.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031459</td>\n",
              "      <td>0.029653</td>\n",
              "      <td>0.093588</td>\n",
              "      <td>0.025617</td>\n",
              "      <td>0.663635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59</td>\n",
              "      <td>7466.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.088620</td>\n",
              "      <td>0.484220</td>\n",
              "      <td>0.064359</td>\n",
              "      <td>0.080446</td>\n",
              "      <td>0.251782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>3663.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.127549</td>\n",
              "      <td>0.050952</td>\n",
              "      <td>0.123271</td>\n",
              "      <td>0.066678</td>\n",
              "      <td>0.261592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>863.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.447030</td>\n",
              "      <td>0.018577</td>\n",
              "      <td>0.023086</td>\n",
              "      <td>0.124501</td>\n",
              "      <td>0.227451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62</td>\n",
              "      <td>1160.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.672137</td>\n",
              "      <td>0.063269</td>\n",
              "      <td>0.402802</td>\n",
              "      <td>0.914565</td>\n",
              "      <td>0.382155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>4441.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.586659</td>\n",
              "      <td>0.145182</td>\n",
              "      <td>0.545001</td>\n",
              "      <td>0.341103</td>\n",
              "      <td>0.175451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>2180.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.577181</td>\n",
              "      <td>0.102682</td>\n",
              "      <td>0.493996</td>\n",
              "      <td>0.786810</td>\n",
              "      <td>0.897202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.811703</td>\n",
              "      <td>0.049817</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.803070</td>\n",
              "      <td>0.936791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>1413.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.163895</td>\n",
              "      <td>0.040690</td>\n",
              "      <td>0.024496</td>\n",
              "      <td>0.025096</td>\n",
              "      <td>0.003818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>7905.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>0.039082</td>\n",
              "      <td>0.106086</td>\n",
              "      <td>0.083423</td>\n",
              "      <td>0.028335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d6ca5f6-d70a-415a-bbb3-2c2c37e44739')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d6ca5f6-d70a-415a-bbb3-2c2c37e44739 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d6ca5f6-d70a-415a-bbb3-2c2c37e44739');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#################################################\n",
        "threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "#################################################\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "FEATURE_COLS=df_result.columns.values[0:].tolist()\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "k=0\n",
        "for idx, i in enumerate(range(9,14), 0):\n",
        "    print(\"fold\",idx)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "    acc = accuracy_score(Y, Y_pred)\n",
        "    print('Accuracy:',acc)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    print(tp, fn, fp, tn)\n",
        "    \n",
        "    #5-fold分のconfusion matrixを加算\n",
        "    confusion_arr += confusion_matrix(Y, Y_pred)\n",
        "\n",
        "\n",
        "    def specificity_score(label, pred):\n",
        "        tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "        return tn / (tn + fp)\n",
        "\n",
        "    print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "    #ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "    plt.plot(fpr, tpr, marker='o')\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.grid()\n",
        "    print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "    #plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "    accuracy.append(accuracy_score(Y, Y_pred))\n",
        "    precision.append(precision_score(Y, Y_pred))\n",
        "    recall.append(recall_score(Y, Y_pred))\n",
        "    specificity.append(specificity_score(Y, Y_pred))\n",
        "    f1score.append(f1_score(Y, Y_pred))\n",
        "    area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "print(\"Result of 5-fold crossvalidation\")\n",
        "print(\"accuracy: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(accuracy), statistics.mean(accuracy)-1.96*statistics.stdev(accuracy), statistics.mean(accuracy)+1.96*statistics.stdev(accuracy)))\n",
        "print(\"precision: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(precision), statistics.mean(precision)-1.96*statistics.stdev(precision), statistics.mean(precision)+1.96*statistics.stdev(precision)))\n",
        "print(\"recall (sensitivity): {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(recall), statistics.mean(recall)-1.96*statistics.stdev(recall), statistics.mean(recall)+1.96*statistics.stdev(recall)))\n",
        "print(\"specificity: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(specificity), statistics.mean(specificity)-1.96*statistics.stdev(specificity), statistics.mean(specificity)+1.96*statistics.stdev(specificity)))\n",
        "print(\"f1_score: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(f1score), statistics.mean(f1score)-1.96*statistics.stdev(f1score), statistics.mean(f1score)+1.96*statistics.stdev(f1score)))\n",
        "print(\"area_u_ROC: {:.2f} ({:.2f}-{:.2f})\".format(statistics.mean(area_u_ROC), statistics.mean(area_u_ROC)-1.96*statistics.stdev(area_u_ROC), statistics.mean(area_u_ROC)+1.96*statistics.stdev(area_u_ROC)))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#ヒートマップを作成\n",
        "arr_2d = np.round(confusion_arr/5).astype(int) #5foldの合計をfold数で割って平均を出す、整数に丸めて整数型にする\n",
        "df_matrix = pd.DataFrame(data=arr_2d, index=[\"Normal\", \"Glaucoma\"], columns=[\"Normal\", \"Glaucoma\"])\n",
        "print(df_matrix)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(df_matrix, annot=True,fmt=\"d\", cmap='Blues')\n",
        "plt.savefig(r\"C:\\Users\\ykita\\Downloads\\per_image_confusion_matrix.png\", dpi=700)\n",
        "plt.show()\n",
        "plt.close('all')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NmOJDYqaQEwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00545f6f-796a-4150-de90-f82beb262008"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['img_id', 'img_number', 'path', 'label', 'pred_fold0', 'pred_fold1', 'pred_fold2', 'pred_fold3', 'pred_fold4', 'prob_fold0', 'prob_fold1', 'prob_fold2', 'prob_fold3', 'prob_fold4']\n",
            "fold 0\n",
            "Accuracy: 0.75\n",
            "27 7 10 24\n",
            "confusion matrix = \n",
            " [[24 10]\n",
            " [ 7 27]]\n",
            "Accuracy : 0.75\n",
            "Precision (true positive rate) : 0.7297297297297297\n",
            "Recall (sensitivity): 0.7941176470588235\n",
            "Specificity : 0.7058823529411765\n",
            "F1 score : 0.7605633802816901\n",
            "Area_under_ROC : 0.8745674740484429\n",
            "\n",
            "fold 1\n",
            "Accuracy: 0.7794117647058824\n",
            "23 11 4 30\n",
            "confusion matrix = \n",
            " [[30  4]\n",
            " [11 23]]\n",
            "Accuracy : 0.7794117647058824\n",
            "Precision (true positive rate) : 0.8518518518518519\n",
            "Recall (sensitivity): 0.6764705882352942\n",
            "Specificity : 0.8823529411764706\n",
            "F1 score : 0.7540983606557378\n",
            "Area_under_ROC : 0.8581314878892734\n",
            "\n",
            "fold 2\n",
            "Accuracy: 0.75\n",
            "20 14 3 31\n",
            "confusion matrix = \n",
            " [[31  3]\n",
            " [14 20]]\n",
            "Accuracy : 0.75\n",
            "Precision (true positive rate) : 0.8695652173913043\n",
            "Recall (sensitivity): 0.5882352941176471\n",
            "Specificity : 0.9117647058823529\n",
            "F1 score : 0.7017543859649124\n",
            "Area_under_ROC : 0.8719723183391004\n",
            "\n",
            "fold 3\n",
            "Accuracy: 0.7794117647058824\n",
            "26 8 7 27\n",
            "confusion matrix = \n",
            " [[27  7]\n",
            " [ 8 26]]\n",
            "Accuracy : 0.7794117647058824\n",
            "Precision (true positive rate) : 0.7878787878787878\n",
            "Recall (sensitivity): 0.7647058823529411\n",
            "Specificity : 0.7941176470588235\n",
            "F1 score : 0.7761194029850745\n",
            "Area_under_ROC : 0.8970588235294117\n",
            "\n",
            "fold 4\n",
            "Accuracy: 0.7647058823529411\n",
            "29 5 11 23\n",
            "confusion matrix = \n",
            " [[23 11]\n",
            " [ 5 29]]\n",
            "Accuracy : 0.7647058823529411\n",
            "Precision (true positive rate) : 0.725\n",
            "Recall (sensitivity): 0.8529411764705882\n",
            "Specificity : 0.6764705882352942\n",
            "F1 score : 0.7837837837837837\n",
            "Area_under_ROC : 0.8728373702422146\n",
            "\n",
            "Result of 5-fold crossvalidation\n",
            "accuracy: 0.76 (0.74-0.79)\n",
            "precision: 0.79 (0.66-0.92)\n",
            "recall (sensitivity): 0.74 (0.53-0.94)\n",
            "specificity: 0.79 (0.59-1.00)\n",
            "f1_score: 0.76 (0.69-0.82)\n",
            "area_u_ROC: 0.87 (0.85-0.90)\n",
            "\n",
            "          Normal  Glaucoma\n",
            "Normal        27         7\n",
            "Glaucoma       9        25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr,tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.savefig(ROC_path, format=\"png\", dpi=700)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "for i in range(9,14):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    label_list_list.append(Y)\n",
        "    model_pred_prob_list.append(Y_pred_proba)\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = list(range(5))\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "\n",
        "label_list_list2, model_pred_prob_list2, Y_TRUE2, Y_SCORE2 = [],[],[],[]\n",
        "\n",
        "roc_label_list = [0]\n",
        "for i in range(5):\n",
        "    label_list_list2.extend(label_list_list[i])\n",
        "    model_pred_prob_list2.extend(model_pred_prob_list[i])\n",
        "label_list_list2 = [label_list_list2]\n",
        "model_pred_prob_list2 = [model_pred_prob_list2]\n",
        "fig = Draw_roc_curve(label_list_list2, model_pred_prob_list2, roc_label_list, len(label_list_list2))"
      ],
      "metadata": {
        "id": "Cb48jClLk24l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list_list2[1]"
      ],
      "metadata": {
        "id": "7TISVycytgFB",
        "outputId": "1cf117af-aa59-407e-b74c-1c6e1fde6bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#統計結果を追記\n",
        "df_result['statistics'] = np.nan\n",
        "df_result['result'] = np.nan\n",
        "df_result.loc[0:5, 'statistics'] = [\"Accuracy\", \"Positive predictive value\", \"Sensitivity\", \"Specificity\", \"F-score\", \"Area_under_ROC\", \"model\", \"optimizer\", \"Rand_seed\"]\n",
        "df_result.loc[0:5, 'result'] = [accuracy_score(Y, Y_pred), precision_score(Y, Y_pred), recall_score(Y, Y_pred), specificity_score(Y, Y_pred), f1_score(Y, Y_pred), roc_auc_score(Y, Y_pred_proba), model_name, optim_name, random_seed]"
      ],
      "metadata": {
        "id": "oBo9g2XsnJA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) \n",
        "df_result"
      ],
      "metadata": {
        "id": "gSRr_lYTnF8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6NDJV20Ww0q6pQDUBkyyL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}