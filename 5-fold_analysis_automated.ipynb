{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_analysis_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "ccdafa8b-6b8a-43b1-86e7-219adea4b6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 469 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.1+cu113)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# YYYYMMDD\n",
        "t_delta = datetime.timedelta(hours=9)\n",
        "JST = datetime.timezone(t_delta, 'JST')\n",
        "now = datetime.datetime.now(JST)\n",
        "d = now.strftime('%Y%m%d') \n",
        "\n",
        "# Model\n",
        "model_name = \"EfficientNetb2\"\n",
        "\n",
        "glav_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/grav\"\n",
        "cont_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/cont\"\n",
        "pretrained_model_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/RepVGG-A2.pth\"\n",
        "gradcam_folder_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/5-fold_{}/GradCam\".format(d)\n",
        "result_csv_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/5-fold_{}/result_{}.csv\".format(d, model_name)\n",
        "model_folder_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/5-fold_{}/Models\".format(d)\n",
        "\n",
        "for path in [gradcam_folder_path, model_folder_path]:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path) \n",
        "    os.makedirs(path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ODB-njjTzV",
        "outputId": "a55662d3-fcd7-438f-c48b-7443dc7e67d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 333, cont: 333\n"
          ]
        }
      ],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(glav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "c21793d7-c4d6-4567-fab7-9b511c333fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266\n",
            "67\n",
            "266\n",
            "67\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(cont_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(cont_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(cont_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(grav_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(grav_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(grav_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "b110c664-6d07-47dd-f2ba-a13f1b028b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained repVGG model already exists\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ranger_adabelief\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "532\n",
            "134\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL2ノルムの二乗を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l2_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l2_loss = l2_loss + torch.norm(w)**2\n",
        "            # loss = loss + lam * l2_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}')\n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "destination = pretrained_model_path\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet timm\n",
        "import timm\n",
        "model_ft = timm.create_model('efficientnet_b2', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Sequential(\n",
        "     nn.Dropout(0.5),\n",
        "     nn.Linear(num_ftrs, 2)\n",
        ")\n",
        "\n",
        "# model_ft = create_RepVGG_A2(deploy=False)\n",
        "# model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "# num_ftrs = model_ft.linear.in_features\n",
        "# model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# from ranger_adabelief import RangerAdaBelief\n",
        "# optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)\n",
        "\n",
        "#save the model\n",
        "PATH = model_folder_path+\"/efficientnet_b2.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8d37e4-fa66-48b3-fc9c-626abbab828e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 39.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 133 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 143 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 163 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 174 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 184 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 194 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 215 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 225 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 235 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 245 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 256 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 266 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 276 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 286 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 296 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 307 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 317 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 327 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 337 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 348 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 358 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 368 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 378 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 389 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 399 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 409 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 419 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 430 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 440 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 450 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 460 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 471 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 481 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 491 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 501 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 512 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 522 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 532 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 542 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 548 kB 4.7 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |██                              | 10 kB 47.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 64.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 40 kB 68.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51 kB 67.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61 kB 71.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71 kB 73.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81 kB 74.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92 kB 77.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 143 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 153 kB 78.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163 kB 78.3 MB/s \n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b2_ra-bcdf34b7.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_ra-bcdf34b7.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Epoch: [ 0/40\n",
            "train_loss: 0.70545 train_acc: 0.50940\n",
            "valid_loss: 0.66262 valid_acc: 0.63433\n",
            "Validation loss decreased (inf --> 0.662620).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 1/40\n",
            "train_loss: 0.62946 train_acc: 0.66353\n",
            "valid_loss: 0.60486 valid_acc: 0.66418\n",
            "Validation loss decreased (0.662620 --> 0.604863).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 2/40\n",
            "train_loss: 0.55053 train_acc: 0.77632\n",
            "valid_loss: 0.56051 valid_acc: 0.70149\n",
            "Validation loss decreased (0.604863 --> 0.560509).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 3/40\n",
            "train_loss: 0.50258 train_acc: 0.74624\n",
            "valid_loss: 0.49227 valid_acc: 0.76119\n",
            "Validation loss decreased (0.560509 --> 0.492271).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 4/40\n",
            "train_loss: 0.45841 train_acc: 0.80451\n",
            "valid_loss: 0.45269 valid_acc: 0.79851\n",
            "Validation loss decreased (0.492271 --> 0.452690).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 5/40\n",
            "train_loss: 0.41210 train_acc: 0.82519\n",
            "valid_loss: 0.41414 valid_acc: 0.79104\n",
            "Validation loss decreased (0.452690 --> 0.414144).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 6/40\n",
            "train_loss: 0.33779 train_acc: 0.84586\n",
            "valid_loss: 0.39688 valid_acc: 0.80597\n",
            "Validation loss decreased (0.414144 --> 0.396883).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 7/40\n",
            "train_loss: 0.32347 train_acc: 0.85902\n",
            "valid_loss: 0.39772 valid_acc: 0.78358\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 8/40\n",
            "train_loss: 0.26617 train_acc: 0.89662\n",
            "valid_loss: 0.40775 valid_acc: 0.79851\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 9/40\n",
            "train_loss: 0.28170 train_acc: 0.88910\n",
            "valid_loss: 0.39017 valid_acc: 0.80597\n",
            "Validation loss decreased (0.396883 --> 0.390169).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [10/40\n",
            "train_loss: 0.25129 train_acc: 0.89098\n",
            "valid_loss: 0.33815 valid_acc: 0.83582\n",
            "Validation loss decreased (0.390169 --> 0.338152).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [11/40\n",
            "train_loss: 0.21510 train_acc: 0.91541\n",
            "valid_loss: 0.36252 valid_acc: 0.82090\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [12/40\n",
            "train_loss: 0.18075 train_acc: 0.93045\n",
            "valid_loss: 0.35181 valid_acc: 0.83582\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [13/40\n",
            "train_loss: 0.17992 train_acc: 0.92481\n",
            "valid_loss: 0.31824 valid_acc: 0.83582\n",
            "Validation loss decreased (0.338152 --> 0.318242).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [14/40\n",
            "train_loss: 0.18375 train_acc: 0.93045\n",
            "valid_loss: 0.39936 valid_acc: 0.82836\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [15/40\n",
            "train_loss: 0.14407 train_acc: 0.93985\n",
            "valid_loss: 0.31217 valid_acc: 0.83582\n",
            "Validation loss decreased (0.318242 --> 0.312171).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [16/40\n",
            "train_loss: 0.12531 train_acc: 0.95113\n",
            "valid_loss: 0.33139 valid_acc: 0.83582\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [17/40\n",
            "train_loss: 0.13687 train_acc: 0.95865\n",
            "valid_loss: 0.27460 valid_acc: 0.85821\n",
            "Validation loss decreased (0.312171 --> 0.274597).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [18/40\n",
            "train_loss: 0.12805 train_acc: 0.94737\n",
            "valid_loss: 0.31784 valid_acc: 0.83582\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [19/40\n",
            "train_loss: 0.07650 train_acc: 0.97556\n",
            "valid_loss: 0.39266 valid_acc: 0.85821\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [20/40\n",
            "train_loss: 0.10646 train_acc: 0.96617\n",
            "valid_loss: 0.37153 valid_acc: 0.82090\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [21/40\n",
            "train_loss: 0.10301 train_acc: 0.97556\n",
            "valid_loss: 0.33187 valid_acc: 0.85821\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [22/40\n",
            "train_loss: 0.11194 train_acc: 0.97368\n",
            "valid_loss: 0.32782 valid_acc: 0.85075\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [23/40\n",
            "train_loss: 0.07611 train_acc: 0.97368\n",
            "valid_loss: 0.36381 valid_acc: 0.82090\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [24/40\n",
            "train_loss: 0.10735 train_acc: 0.96053\n",
            "valid_loss: 0.39361 valid_acc: 0.80597\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [25/40\n",
            "train_loss: 0.08180 train_acc: 0.98872\n",
            "valid_loss: 0.41993 valid_acc: 0.82090\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [26/40\n",
            "train_loss: 0.07154 train_acc: 0.97744\n",
            "valid_loss: 0.39580 valid_acc: 0.83582\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [27/40\n",
            "train_loss: 0.05176 train_acc: 0.98496\n",
            "valid_loss: 0.38996 valid_acc: 0.81343\n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [28/40\n",
            "train_loss: 0.06227 train_acc: 0.98120\n",
            "valid_loss: 0.42310 valid_acc: 0.81343\n",
            "EarlyStopping counter: 11 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [29/40\n",
            "train_loss: 0.11803 train_acc: 0.96992\n",
            "valid_loss: 0.36375 valid_acc: 0.82836\n",
            "EarlyStopping counter: 12 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [30/40\n",
            "train_loss: 0.05543 train_acc: 0.98308\n",
            "valid_loss: 0.40213 valid_acc: 0.79851\n",
            "EarlyStopping counter: 13 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [31/40\n",
            "train_loss: 0.10153 train_acc: 0.96805\n",
            "valid_loss: 0.44901 valid_acc: 0.82836\n",
            "EarlyStopping counter: 14 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [32/40\n",
            "train_loss: 0.04717 train_acc: 0.98872\n",
            "valid_loss: 0.45243 valid_acc: 0.83582\n",
            "EarlyStopping counter: 15 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [33/40\n",
            "train_loss: 0.04874 train_acc: 0.98684\n",
            "valid_loss: 0.40121 valid_acc: 0.82090\n",
            "EarlyStopping counter: 16 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [34/40\n",
            "train_loss: 0.06907 train_acc: 0.97932\n",
            "valid_loss: 0.36015 valid_acc: 0.82836\n",
            "EarlyStopping counter: 17 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [35/40\n",
            "train_loss: 0.03980 train_acc: 0.98872\n",
            "valid_loss: 0.49197 valid_acc: 0.75373\n",
            "EarlyStopping counter: 18 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [36/40\n",
            "train_loss: 0.05344 train_acc: 0.98496\n",
            "valid_loss: 0.42356 valid_acc: 0.82836\n",
            "EarlyStopping counter: 19 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [37/40\n",
            "train_loss: 0.03865 train_acc: 0.98684\n",
            "valid_loss: 0.38104 valid_acc: 0.83582\n",
            "EarlyStopping counter: 20 out of 20\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #save the model\n",
        "# PATH = model_folder_path+\"/moblenetv3_large_100.pth\"\n",
        "# torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "0mxURhuFF11M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = model_folder_path+\"/sample.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dK51F4PTZHi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML 飛ばして下さい\n",
        "###########################\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV2\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"grav\", \"cont\"]\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "    classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        ")\n",
        "\n",
        "# Save model\n",
        "mlmodel.save(model_folder_path+\"/sample_\"+model_name+\".mlmodel\")"
      ],
      "metadata": {
        "id": "cx_1FO6qZr0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "J2gmKzk9yPOW",
        "outputId": "ff189f7c-f437-4f9a-a679-d76da6c295b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "\n",
        "#Normalizationのreverse\n",
        "def invert_norm(tensor):\n",
        "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
        "                                                        std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
        "                                    transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
        "                                                        std = [ 1., 1., 1. ]),\n",
        "                                  ])\n",
        "    inv_tensor = invTrans(tensor)\n",
        "    return(inv_tensor)\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset,  row=0, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"grav\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = invert_norm(image) #normalizationを戻す\n",
        "            \n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_folder_path+\"/row{}-label{}-pred{}.png\".format(row,classes[test_dataset[j][1]], classes[c]))\n",
        "            row += 1\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "gradcam(model_ft, val_dataset, row=0, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "fold, id, number, path, label = [], [], [], [], []\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "for grav, cont in zip(val_dataset_grav, val_dataset_cont):\n",
        "    for j in grav:\n",
        "        fold.append(i)\n",
        "        id.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(1)\n",
        "        k+=1\n",
        "    for j in cont:\n",
        "        fold.append(i)\n",
        "        id.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(0)\n",
        "        k+=1\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# k=0\n",
        "# for i in val_dataset_grav:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(1)\n",
        "#     k+=1\n",
        "# k=0\n",
        "# for i in val_dataset_cont:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(0)\n",
        "#     k+=1\n",
        "print(len(fold))\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"fold\", \"img_id\", \"img_number\", \"path\",\"label\", \"pred\", \"prob\"])\n",
        "df_result[\"fold\"] = fold\n",
        "df_result[\"img_id\"] = id\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5697f870-639c-4968-f7db-ac26030f5b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fold  img_id img_number  \\\n",
              "0       0       0   2644.jpg   \n",
              "1       0       1   6599.jpg   \n",
              "2       0       2   6965.jpg   \n",
              "3       0       3   7077.jpg   \n",
              "4       0       4   2960.jpg   \n",
              "..    ...     ...        ...   \n",
              "661     4     661   6237.jpg   \n",
              "662     4     662   8019.jpg   \n",
              "663     4     663    147.JPG   \n",
              "664     4     664   4949.jpg   \n",
              "665     4     665    806.jpg   \n",
              "\n",
              "                                                  path  label pred prob  \n",
              "0    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "1    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "2    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "3    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "4    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "..                                                 ...    ...  ...  ...  \n",
              "661  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "662  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "663  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "664  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "665  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "\n",
              "[666 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09c7e334-21dd-4714-94ae-3f87936f0daa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2644.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6599.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6965.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7077.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2960.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>4</td>\n",
              "      <td>661</td>\n",
              "      <td>6237.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>4</td>\n",
              "      <td>662</td>\n",
              "      <td>8019.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>4</td>\n",
              "      <td>663</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>4</td>\n",
              "      <td>664</td>\n",
              "      <td>4949.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>4</td>\n",
              "      <td>665</td>\n",
              "      <td>806.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>666 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c7e334-21dd-4714-94ae-3f87936f0daa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09c7e334-21dd-4714-94ae-3f87936f0daa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09c7e334-21dd-4714-94ae-3f87936f0daa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) "
      ],
      "metadata": {
        "id": "s_XNgvXXImWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 3\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "\n",
        "#Define Data Augumentation\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # num_ftrs = model_ft.fc.in_features\n",
        "    # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    num_ftrs = model_ft.linear.in_features\n",
        "    model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    from ranger_adabelief import RangerAdaBelief\n",
        "    optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    #optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "    #save the model\n",
        "    PATH = model_folder_path+\"/fold_\"+str(fold)+\".pth\"\n",
        "    torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    \n",
        "    val_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0) #val_loader、batch-size、shuffleを直す\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    if fold == 0:\n",
        "        fold = 0\n",
        "    else:\n",
        "        for m in range(0, fold):\n",
        "            row += len(val_dataset_grav[m]+val_dataset_cont[m])\n",
        "    df_result.loc[row:row+len(y_pred)-1, \"pred\"] = y_pred\n",
        "    column = fold + 9\n",
        "    df_result.loc[row:row+len(y_pred)-1, \"prob\"] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    gradcam(model_ft, val_dataset, row, save=True) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "4Gw576P_uKYj",
        "outputId": "6e689575-812b-4bdb-aac0-320916f081e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fold  img_id img_number  \\\n",
              "0       0       0   2644.jpg   \n",
              "1       0       1   6599.jpg   \n",
              "2       0       2   6965.jpg   \n",
              "3       0       3   7077.jpg   \n",
              "4       0       4   2960.jpg   \n",
              "..    ...     ...        ...   \n",
              "661     4     661   6237.jpg   \n",
              "662     4     662   8019.jpg   \n",
              "663     4     663    147.JPG   \n",
              "664     4     664   4949.jpg   \n",
              "665     4     665    806.jpg   \n",
              "\n",
              "                                                  path  label  pred      prob  \n",
              "0    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.999973  \n",
              "1    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.919740  \n",
              "2    /content/drive/MyDrive/Deep_learning/666mai_da...      1   0.0  0.458516  \n",
              "3    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.988250  \n",
              "4    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.663085  \n",
              "..                                                 ...    ...   ...       ...  \n",
              "661  /content/drive/MyDrive/Deep_learning/666mai_da...      0   1.0  0.778016  \n",
              "662  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.007451  \n",
              "663  /content/drive/MyDrive/Deep_learning/666mai_da...      0   1.0  0.519158  \n",
              "664  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.007944  \n",
              "665  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.192361  \n",
              "\n",
              "[666 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2644.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6599.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.919740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6965.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7077.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2960.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>4</td>\n",
              "      <td>661</td>\n",
              "      <td>6237.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.778016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>4</td>\n",
              "      <td>662</td>\n",
              "      <td>8019.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>4</td>\n",
              "      <td>663</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.519158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>4</td>\n",
              "      <td>664</td>\n",
              "      <td>4949.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>4</td>\n",
              "      <td>665</td>\n",
              "      <td>806.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.192361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>666 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "Uh_aAup_hd5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#################################################\n",
        "threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "#################################################\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "\n",
        "X = df_result[\"prob\"]\n",
        "Y = df_result[\"label\"]\n",
        "\n",
        "Y_pred_proba = X\n",
        "Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "acc = accuracy_score(Y, Y_pred)\n",
        "print('Accuracy:',acc)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "#5-fold分のconfusion matrixを加算\n",
        "confusion_arr += confusion_matrix(Y, Y_pred)\n",
        "\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "#ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "accuracy.append(accuracy_score(Y, Y_pred))\n",
        "precision.append(precision_score(Y, Y_pred))\n",
        "recall.append(recall_score(Y, Y_pred))\n",
        "specificity.append(specificity_score(Y, Y_pred))\n",
        "f1score.append(f1_score(Y, Y_pred))\n",
        "area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#ヒートマップを作成\n",
        "arr_2d = np.round(confusion_arr/5).astype(int) #5foldの合計をfold数で割って平均を出す、整数に丸めて整数型にする\n",
        "df_matrix = pd.DataFrame(data=arr_2d, index=[\"Normal\", \"TED\"], columns=[\"Normal\", \"TED\"])\n",
        "print(df_matrix)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(df_matrix, annot=True,fmt=\"d\", cmap='Blues')\n",
        "plt.savefig(r\"C:\\Users\\ykita\\Downloads\\per_image_confusion_matrix.png\", dpi=700)\n",
        "plt.show()\n",
        "plt.close('all')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NmOJDYqaQEwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2b034deb-709c-47d0-aa0e-698266487d4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d9a413f40790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr,tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.savefig(r\"C:\\Users\\ykita\\Downloads\\ROC_5fold.png\", format=\"png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = [1]\n",
        "fig = Draw_roc_curve([Y], [Y_pred_proba], roc_label_list, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cb48jClLk24l",
        "outputId": "d4ec7982-65ea-4a8b-da92-be0d79ea697e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM/iZbKbEBNZt6TnnH/5w0j",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}