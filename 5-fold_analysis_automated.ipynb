{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_analysis_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "f9d13e17-0e36-4c86-a997-66dfb7b250b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 2 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "glav_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/grav\"\n",
        "cont_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/gravcont_250px/cont\"\n",
        "pretrained_model_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/RepVGG-A2.pth\"\n",
        "gradcam_img_path = \"\"\n",
        "result_csv_path = \"/content/drive/MyDrive/Deep_learning/666mai_dataset/result_RepVGGA2_SGD_20220627.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ODB-njjTzV",
        "outputId": "cb457220-ad97-4608-b6dc-f948725d614b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grav: 333, cont: 333\n"
          ]
        }
      ],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(glav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "0af19954-8f30-41e9-9647-73fe9f83e287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "266\n",
            "67\n",
            "266\n",
            "67\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(cont_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(cont_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(cont_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(grav_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(grav_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(grav_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "6f0cfd15-dfa7-4c93-f5d1-8cfb98ea01c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained repVGG model already exists\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "532\n",
            "134\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}')\n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "destination = pretrained_model_path\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# from ranger_adabelief import RangerAdaBelief\n",
        "# optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "J2gmKzk9yPOW",
        "outputId": "b4a30c52-0deb-4567-c01c-0f0fc1a62956"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"gla\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_img_path+\"/pt{}-img{}-label{}-pred{}.png\".format(pt,j,classes[test_dataset[j][1]], classes[c]))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "gradcam(model_ft, val_dataset, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9OyU2T71fC_",
        "outputId": "b3b2d0db-459f-4c5b-acff-4b4013d8b56e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.SimpleImageDataset object at 0x7fbebfe2f410>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "fold, number, path, label = [], [], [], []\n",
        "\n",
        "k=0\n",
        "for i in val_dataset_grav:\n",
        "    for j in i:\n",
        "        fold.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(1)\n",
        "    k+=1\n",
        "k=0\n",
        "for i in val_dataset_cont:\n",
        "    for j in i:\n",
        "        fold.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(0)\n",
        "    k+=1\n",
        "print(len(fold))\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"fold\", \"img_number\", \"path\",\"label\", \"pred\", \"prob\"])\n",
        "df_result[\"fold\"] = fold\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "df_result\n",
        "\n",
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) \n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 0\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "\n",
        "#Define Data Augumentation\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # num_ftrs = model_ft.fc.in_features\n",
        "    # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    num_ftrs = model_ft.linear.in_features\n",
        "    model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    #from ranger_adabelief import RangerAdaBelief\n",
        "    #optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    if fold == 0:\n",
        "        fold = 0\n",
        "    else:\n",
        "        for m in range(0, fold):\n",
        "            row += len(val_dataset_grav[m])\n",
        "    df_result.loc[row:row+len(y_pred), \"pred\"] = y_pred\n",
        "    column = fold + 9\n",
        "    df_result.loc[row:row+len(y_pred), \"prob\"] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    gradcam(model_ft, val_dataset, save=False) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.loc[row:row+10, \"prob\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN0qA7nQ_zJ2",
        "outputId": "4fbcd1bb-3727-4d92-c3c2-6993804cda81"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "267    NaN\n",
              "268    NaN\n",
              "269    NaN\n",
              "270    NaN\n",
              "271    NaN\n",
              "272    NaN\n",
              "273    NaN\n",
              "274    NaN\n",
              "275    NaN\n",
              "276    NaN\n",
              "277    NaN\n",
              "Name: prob, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZDC7A11f_24w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMH3AE5pj1aMWFu40lk6Cu5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}