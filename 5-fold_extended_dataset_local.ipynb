{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/5-fold_extended_dataset_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Wsoz46h1E-"
      },
      "source": [
        "#**GravCont_250 5-fold cross-validation**\n",
        "# -- using extended dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVzemJXhpnA",
        "outputId": "9ed19851-3841-4cb0-dee6-eb48f570fd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch_optimizer) (1.13.0+cu117)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.5.0->torch_optimizer) (4.0.1)\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "# #GDriveをマウント\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITI3BuQXiLVq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# YYYYMMDD\n",
        "t_delta = datetime.timedelta(hours=9)\n",
        "JST = datetime.timezone(t_delta, 'JST')\n",
        "now = datetime.datetime.now(JST)\n",
        "d = now.strftime('%Y%m%d') \n",
        "\n",
        "# Model\n",
        "model_name = \"EfficientNetb2\"\n",
        "\n",
        "parent_path = f\"H:/GO_extended_250px\"\n",
        "grav_path = f\"{parent_path}/grav\"\n",
        "cont_path = f\"{parent_path}/cont\"\n",
        "pretrained_model_path = f\"{parent_path}/RepVGG-A2.pth\"\n",
        "gradcam_folder_path = f\"{parent_path}/GradCam\"\n",
        "result_csv_path = f\"{parent_path}/result.csv\"\n",
        "model_folder_path = f\"{parent_path}/Models\"\n",
        "\n",
        "for path in [gradcam_folder_path, model_folder_path]:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path) \n",
        "    os.makedirs(path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Image processing to 250px**"
      ],
      "metadata": {
        "id": "ZYuEs1QVYd88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(in_path, out_path, processing_file):\n",
        "    #処理時間の計測\n",
        "    start = time.time()\n",
        "\n",
        "    l=0\n",
        "    for i in processing_file:      \n",
        "          img = Image.open(in_path + '/' + i)\n",
        "          img_new = expand2square(img, (0, 0, 0)).resize((250, 250))\n",
        "          img_new.save(out_path +'/'+ i)\n",
        "          print(out_path +'/'+ i)\n",
        "          \n",
        "          #切り取った画像を表示\n",
        "          #plt.imshow(np.asarray(img_new))\n",
        "          #plt.show()\n",
        "\n",
        "    print('Process done!!')\n",
        "    elapsed_time = time.time() - start\n",
        "    print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
        "\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width-height)//2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, (0, (height - width) // 2))\n",
        "        return result\n",
        "\n",
        "def showInfo(in_path):\n",
        "    #処理するDirectoryの設定\n",
        "    file = os.listdir(in_path)\n",
        "    print(len(file))\n",
        "\n",
        "    #ここにフォルダ番号を記載する (ex. [0:999])\n",
        "    processing_file = file[0:]\n",
        "    print(processing_file)\n",
        "    len(processing_file)\n",
        "    return processing_file"
      ],
      "metadata": {
        "id": "DBO8t4fvYdE-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#元画像フォルダ\n",
        "in_path = [f\"H:/GO_treatable/treatable\", f\"H:/Control_photo_1886mai\"]\n",
        "\n",
        "#保存先フォルダ\n",
        "out_path = [grav_path, cont_path]\n",
        "\n",
        "for in_path, out_path in zip(in_path,out_path):\n",
        "    if os.path.exists(out_path):\n",
        "        shutil.rmtree(out_path)\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "    processing_file = showInfo(in_path)\n",
        "    convert(in_path, out_path, processing_file)"
      ],
      "metadata": {
        "id": "8IQlhkg6Yu9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5-foldに分割**"
      ],
      "metadata": {
        "id": "XPnbeicQYvTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ODB-njjTzV"
      },
      "outputs": [],
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "grav_path_list = make_path_list(grav_path)\n",
        "cont_path_list = make_path_list(cont_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "grav_id = extract_ids(grav_path_list)\n",
        "cont_id = extract_ids(cont_path_list)\n",
        "\n",
        "print(\"grav: {}, cont: {}\".format(len(grav_id), len(cont_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ddvc4-rfsnY"
      },
      "source": [
        "#**5-Foldに分割**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvLpuwnkEzE",
        "outputId": "8017a839-e7d9-425b-ff9a-b4215f7d3673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1505\n",
            "377\n",
            "1508\n",
            "378\n"
          ]
        }
      ],
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "train_dataset_grav, val_dataset_grav, train_dataset_cont, val_dataset_cont =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(cont_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_cont[i].append(cont_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_cont[i].append(cont_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(grav_path_list):\n",
        "    for idx in train_idxs:\n",
        "        train_dataset_grav[i].append(grav_path_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_dataset_grav[i].append(grav_path_list[idx])\n",
        "    i+=1\n",
        "\n",
        "print(len(train_dataset_grav[0]))    \n",
        "print(len(val_dataset_grav[0]))\n",
        "print(len(train_dataset_cont[0]))    \n",
        "print(len(val_dataset_cont[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQhcDlAVhQ0t"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5q3bnqlpHlF",
        "outputId": "f9d58f66-4299-4e65-d402-52280f232037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Requirement already satisfied: ranger_adabelief in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ranger_adabelief) (1.13.0+cu117)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=0.4.0->ranger_adabelief) (4.0.1)\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "3013\n",
            "755\n"
          ]
        }
      ],
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            \n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL2ノルムの二乗を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l2_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l2_loss = l2_loss + torch.norm(w)**2\n",
        "            # loss = loss + lam * l2_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}')\n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "# def download_file_from_google_drive(id, destination):\n",
        "#     URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "#     session = requests.Session()\n",
        "\n",
        "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "#     token = get_confirm_token(response)\n",
        "\n",
        "#     if token:\n",
        "#         params = { 'id' : id, 'confirm' : token }\n",
        "#         response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "#     save_response_content(response, destination)    \n",
        "\n",
        "# def get_confirm_token(response):\n",
        "#     for key, value in response.cookies.items():\n",
        "#         if key.startswith('download_warning'):\n",
        "#             return value\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def save_response_content(response, destination):\n",
        "#     CHUNK_SIZE = 32768\n",
        "\n",
        "#     with open(destination, \"wb\") as f:\n",
        "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
        "#             if chunk: # filter out keep-alive new chunks\n",
        "#                 f.write(chunk)\n",
        "# file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     download_file_from_google_drive(file_id, destination)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "# import gdown\n",
        "# url = \"https://drive.google.com/uc?id=1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G\"\n",
        "# destination = pretrained_model_path\n",
        "\n",
        "# if os.path.exists(destination) is not True:\n",
        "#     gdown.download(url, destination, quiet=False)\n",
        "# else:\n",
        "#     print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "fold=0\n",
        "train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "timm.list_models(pretrained=True)"
      ],
      "metadata": {
        "id": "3c53-TILQs25",
        "outputId": "2d5a8693-b148-4756-8e0c-549a02122c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adv_inception_v3',\n",
              " 'bat_resnext26ts',\n",
              " 'beit_base_patch16_224',\n",
              " 'beit_base_patch16_224_in22k',\n",
              " 'beit_base_patch16_384',\n",
              " 'beit_large_patch16_224',\n",
              " 'beit_large_patch16_224_in22k',\n",
              " 'beit_large_patch16_384',\n",
              " 'beit_large_patch16_512',\n",
              " 'beitv2_base_patch16_224',\n",
              " 'beitv2_base_patch16_224_in22k',\n",
              " 'beitv2_large_patch16_224',\n",
              " 'beitv2_large_patch16_224_in22k',\n",
              " 'botnet26t_256',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_tiny',\n",
              " 'coatnet_0_rw_224',\n",
              " 'coatnet_1_rw_224',\n",
              " 'coatnet_bn_0_rw_224',\n",
              " 'coatnet_nano_rw_224',\n",
              " 'coatnet_rmlp_1_rw_224',\n",
              " 'coatnet_rmlp_2_rw_224',\n",
              " 'coatnet_rmlp_nano_rw_224',\n",
              " 'coatnext_nano_rw_224',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'convmixer_768_32',\n",
              " 'convmixer_1024_20_ks9_p14',\n",
              " 'convmixer_1536_20',\n",
              " 'convnext_atto',\n",
              " 'convnext_atto_ols',\n",
              " 'convnext_base',\n",
              " 'convnext_base_384_in22ft1k',\n",
              " 'convnext_base_in22ft1k',\n",
              " 'convnext_base_in22k',\n",
              " 'convnext_femto',\n",
              " 'convnext_femto_ols',\n",
              " 'convnext_large',\n",
              " 'convnext_large_384_in22ft1k',\n",
              " 'convnext_large_in22ft1k',\n",
              " 'convnext_large_in22k',\n",
              " 'convnext_nano',\n",
              " 'convnext_nano_ols',\n",
              " 'convnext_pico',\n",
              " 'convnext_pico_ols',\n",
              " 'convnext_small',\n",
              " 'convnext_small_384_in22ft1k',\n",
              " 'convnext_small_in22ft1k',\n",
              " 'convnext_small_in22k',\n",
              " 'convnext_tiny',\n",
              " 'convnext_tiny_384_in22ft1k',\n",
              " 'convnext_tiny_hnf',\n",
              " 'convnext_tiny_in22ft1k',\n",
              " 'convnext_tiny_in22k',\n",
              " 'convnext_xlarge_384_in22ft1k',\n",
              " 'convnext_xlarge_in22ft1k',\n",
              " 'convnext_xlarge_in22k',\n",
              " 'crossvit_9_240',\n",
              " 'crossvit_9_dagger_240',\n",
              " 'crossvit_15_240',\n",
              " 'crossvit_15_dagger_240',\n",
              " 'crossvit_15_dagger_408',\n",
              " 'crossvit_18_240',\n",
              " 'crossvit_18_dagger_240',\n",
              " 'crossvit_18_dagger_408',\n",
              " 'crossvit_base_240',\n",
              " 'crossvit_small_240',\n",
              " 'crossvit_tiny_240',\n",
              " 'cs3darknet_focus_l',\n",
              " 'cs3darknet_focus_m',\n",
              " 'cs3darknet_l',\n",
              " 'cs3darknet_m',\n",
              " 'cs3darknet_x',\n",
              " 'cs3edgenet_x',\n",
              " 'cs3se_edgenet_x',\n",
              " 'cs3sedarknet_l',\n",
              " 'cs3sedarknet_x',\n",
              " 'cspdarknet53',\n",
              " 'cspresnet50',\n",
              " 'cspresnext50',\n",
              " 'darknet53',\n",
              " 'darknetaa53',\n",
              " 'deit3_base_patch16_224',\n",
              " 'deit3_base_patch16_224_in21ft1k',\n",
              " 'deit3_base_patch16_384',\n",
              " 'deit3_base_patch16_384_in21ft1k',\n",
              " 'deit3_huge_patch14_224',\n",
              " 'deit3_huge_patch14_224_in21ft1k',\n",
              " 'deit3_large_patch16_224',\n",
              " 'deit3_large_patch16_224_in21ft1k',\n",
              " 'deit3_large_patch16_384',\n",
              " 'deit3_large_patch16_384_in21ft1k',\n",
              " 'deit3_medium_patch16_224',\n",
              " 'deit3_medium_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_224',\n",
              " 'deit3_small_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_384',\n",
              " 'deit3_small_patch16_384_in21ft1k',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_resnet33ts',\n",
              " 'eca_resnext26ts',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'edgenext_base',\n",
              " 'edgenext_small',\n",
              " 'edgenext_small_rw',\n",
              " 'edgenext_x_small',\n",
              " 'edgenext_xx_small',\n",
              " 'efficientformer_l1',\n",
              " 'efficientformer_l3',\n",
              " 'efficientformer_l7',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_rw_t',\n",
              " 'ens_adv_inception_resnet_v2',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'gc_efficientnetv2_rw_t',\n",
              " 'gcresnet33ts',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'gcresnext50ts',\n",
              " 'gcvit_base',\n",
              " 'gcvit_small',\n",
              " 'gcvit_tiny',\n",
              " 'gcvit_xtiny',\n",
              " 'gcvit_xxtiny',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_100',\n",
              " 'gluon_inception_v3',\n",
              " 'gluon_resnet18_v1b',\n",
              " 'gluon_resnet34_v1b',\n",
              " 'gluon_resnet50_v1b',\n",
              " 'gluon_resnet50_v1c',\n",
              " 'gluon_resnet50_v1d',\n",
              " 'gluon_resnet50_v1s',\n",
              " 'gluon_resnet101_v1b',\n",
              " 'gluon_resnet101_v1c',\n",
              " 'gluon_resnet101_v1d',\n",
              " 'gluon_resnet101_v1s',\n",
              " 'gluon_resnet152_v1b',\n",
              " 'gluon_resnet152_v1c',\n",
              " 'gluon_resnet152_v1d',\n",
              " 'gluon_resnet152_v1s',\n",
              " 'gluon_resnext50_32x4d',\n",
              " 'gluon_resnext101_32x4d',\n",
              " 'gluon_resnext101_64x4d',\n",
              " 'gluon_senet154',\n",
              " 'gluon_seresnext50_32x4d',\n",
              " 'gluon_seresnext101_32x4d',\n",
              " 'gluon_seresnext101_64x4d',\n",
              " 'gluon_xception65',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_s16_224',\n",
              " 'halo2botnet50ts_256',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'haloregnetz_b',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w64',\n",
              " 'ig_resnext101_32x8d',\n",
              " 'ig_resnext101_32x16d',\n",
              " 'ig_resnext101_32x32d',\n",
              " 'ig_resnext101_32x48d',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'jx_nest_base',\n",
              " 'jx_nest_small',\n",
              " 'jx_nest_tiny',\n",
              " 'lambda_resnet26rpt_256',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50ts',\n",
              " 'lamhalobotnet50ts_256',\n",
              " 'lcnet_050',\n",
              " 'lcnet_075',\n",
              " 'lcnet_100',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_384',\n",
              " 'maxvit_nano_rw_256',\n",
              " 'maxvit_rmlp_nano_rw_256',\n",
              " 'maxvit_rmlp_pico_rw_256',\n",
              " 'maxvit_rmlp_small_rw_224',\n",
              " 'maxvit_rmlp_tiny_rw_256',\n",
              " 'maxvit_tiny_rw_224',\n",
              " 'maxxvit_rmlp_nano_rw_256',\n",
              " 'maxxvit_rmlp_small_rw_256',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b16_224_in21k',\n",
              " 'mixer_b16_224_miil',\n",
              " 'mixer_b16_224_miil_in21k',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l16_224_in21k',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_small',\n",
              " 'mobilenetv2_050',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_100_miil',\n",
              " 'mobilenetv3_large_100_miil_in21k',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_050',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'mobilevit_s',\n",
              " 'mobilevit_xs',\n",
              " 'mobilevit_xxs',\n",
              " 'mobilevitv2_050',\n",
              " 'mobilevitv2_075',\n",
              " 'mobilevitv2_100',\n",
              " 'mobilevitv2_125',\n",
              " 'mobilevitv2_150',\n",
              " 'mobilevitv2_150_384_in22ft1k',\n",
              " 'mobilevitv2_150_in22ft1k',\n",
              " 'mobilevitv2_175',\n",
              " 'mobilevitv2_175_384_in22ft1k',\n",
              " 'mobilevitv2_175_in22ft1k',\n",
              " 'mobilevitv2_200',\n",
              " 'mobilevitv2_200_384_in22ft1k',\n",
              " 'mobilevitv2_200_in22ft1k',\n",
              " 'mvitv2_base',\n",
              " 'mvitv2_large',\n",
              " 'mvitv2_small',\n",
              " 'mvitv2_tiny',\n",
              " 'nasnetalarge',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_resnet50',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'poolformer_m36',\n",
              " 'poolformer_m48',\n",
              " 'poolformer_s12',\n",
              " 'poolformer_s24',\n",
              " 'poolformer_s36',\n",
              " 'pvt_v2_b0',\n",
              " 'pvt_v2_b1',\n",
              " 'pvt_v2_b2',\n",
              " 'pvt_v2_b2_li',\n",
              " 'pvt_v2_b3',\n",
              " 'pvt_v2_b4',\n",
              " 'pvt_v2_b5',\n",
              " 'regnetv_040',\n",
              " 'regnetv_064',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'regnetz_040',\n",
              " 'regnetz_040h',\n",
              " 'regnetz_b16',\n",
              " 'regnetz_c16',\n",
              " 'regnetz_c16_evos',\n",
              " 'regnetz_d8',\n",
              " 'regnetz_d8_evos',\n",
              " 'regnetz_d32',\n",
              " 'regnetz_e8',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_12_224_dino',\n",
              " 'resmlp_12_distilled_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_24_224_dino',\n",
              " 'resmlp_24_distilled_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_36_distilled_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resmlp_big_24_224_in22ft1k',\n",
              " 'resmlp_big_24_distilled_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet10t',\n",
              " 'resnet14t',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet32ts',\n",
              " 'resnet33ts',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50_gn',\n",
              " 'resnet50d',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101d',\n",
              " 'resnet152',\n",
              " 'resnet152d',\n",
              " 'resnet200d',\n",
              " 'resnetaa50',\n",
              " 'resnetblur50',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d_evos',\n",
              " 'resnetv2_50d_gn',\n",
              " 'resnetv2_50x1_bit_distilled',\n",
              " 'resnetv2_50x1_bitm',\n",
              " 'resnetv2_50x1_bitm_in21k',\n",
              " 'resnetv2_50x3_bitm',\n",
              " 'resnetv2_50x3_bitm_in21k',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101x1_bitm',\n",
              " 'resnetv2_101x1_bitm_in21k',\n",
              " 'resnetv2_101x3_bitm',\n",
              " 'resnetv2_101x3_bitm_in21k',\n",
              " 'resnetv2_152x2_bit_teacher',\n",
              " 'resnetv2_152x2_bit_teacher_384',\n",
              " 'resnetv2_152x2_bitm',\n",
              " 'resnetv2_152x2_bitm_in21k',\n",
              " 'resnetv2_152x4_bitm',\n",
              " 'resnetv2_152x4_bitm_in21k',\n",
              " 'resnext26ts',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'sebotnet33ts_256',\n",
              " 'sehalonet33ts',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'sequencer2d_l',\n",
              " 'sequencer2d_m',\n",
              " 'sequencer2d_s',\n",
              " 'seresnet33ts',\n",
              " 'seresnet50',\n",
              " 'seresnet152d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26ts',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'seresnext101d_32x8d',\n",
              " 'seresnextaa101d_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'ssl_resnet18',\n",
              " 'ssl_resnet50',\n",
              " 'ssl_resnext50_32x4d',\n",
              " 'ssl_resnext101_32x4d',\n",
              " 'ssl_resnext101_32x8d',\n",
              " 'ssl_resnext101_32x16d',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window7_224_in22k',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_base_patch4_window12_384_in22k',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window7_224_in22k',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_large_patch4_window12_384_in22k',\n",
              " 'swin_s3_base_224',\n",
              " 'swin_s3_small_224',\n",
              " 'swin_s3_tiny_224',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swinv2_base_window8_256',\n",
              " 'swinv2_base_window12_192_22k',\n",
              " 'swinv2_base_window12to16_192to256_22kft1k',\n",
              " 'swinv2_base_window12to24_192to384_22kft1k',\n",
              " 'swinv2_base_window16_256',\n",
              " 'swinv2_cr_small_224',\n",
              " 'swinv2_cr_small_ns_224',\n",
              " 'swinv2_cr_tiny_ns_224',\n",
              " 'swinv2_large_window12_192_22k',\n",
              " 'swinv2_large_window12to16_192to256_22kft1k',\n",
              " 'swinv2_large_window12to24_192to384_22kft1k',\n",
              " 'swinv2_small_window8_256',\n",
              " 'swinv2_small_window16_256',\n",
              " 'swinv2_tiny_window8_256',\n",
              " 'swinv2_tiny_window16_256',\n",
              " 'swsl_resnet18',\n",
              " 'swsl_resnet50',\n",
              " 'swsl_resnext50_32x4d',\n",
              " 'swsl_resnext101_32x4d',\n",
              " 'swsl_resnext101_32x8d',\n",
              " 'swsl_resnext101_32x16d',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b0_ap',\n",
              " 'tf_efficientnet_b0_ns',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b1_ap',\n",
              " 'tf_efficientnet_b1_ns',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b2_ap',\n",
              " 'tf_efficientnet_b2_ns',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b3_ap',\n",
              " 'tf_efficientnet_b3_ns',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b4_ap',\n",
              " 'tf_efficientnet_b4_ns',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b5_ap',\n",
              " 'tf_efficientnet_b5_ns',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b6_ap',\n",
              " 'tf_efficientnet_b6_ns',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b7_ap',\n",
              " 'tf_efficientnet_b7_ns',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_b8_ap',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2_ns',\n",
              " 'tf_efficientnet_l2_ns_475',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_l_in21ft1k',\n",
              " 'tf_efficientnetv2_l_in21k',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_m_in21ft1k',\n",
              " 'tf_efficientnetv2_m_in21k',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_s_in21ft1k',\n",
              " 'tf_efficientnetv2_s_in21k',\n",
              " 'tf_efficientnetv2_xl_in21ft1k',\n",
              " 'tf_efficientnetv2_xl_in21k',\n",
              " 'tf_inception_v3',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tinynet_a',\n",
              " 'tinynet_b',\n",
              " 'tinynet_c',\n",
              " 'tinynet_d',\n",
              " 'tinynet_e',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_l_448',\n",
              " 'tresnet_m',\n",
              " 'tresnet_m_448',\n",
              " 'tresnet_m_miil_in21k',\n",
              " 'tresnet_v2_l',\n",
              " 'tresnet_xl',\n",
              " 'tresnet_xl_448',\n",
              " 'tv_densenet121',\n",
              " 'tv_resnet34',\n",
              " 'tv_resnet50',\n",
              " 'tv_resnet101',\n",
              " 'tv_resnet152',\n",
              " 'tv_resnext50_32x4d',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'vit_base_patch8_224',\n",
              " 'vit_base_patch8_224_dino',\n",
              " 'vit_base_patch8_224_in21k',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_dino',\n",
              " 'vit_base_patch16_224_in21k',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_224_miil_in21k',\n",
              " 'vit_base_patch16_224_sam',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch16_rpn_224',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_224_clip_laion2b',\n",
              " 'vit_base_patch32_224_in21k',\n",
              " 'vit_base_patch32_224_sam',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_r50_s16_224_in21k',\n",
              " 'vit_base_r50_s16_384',\n",
              " 'vit_giant_patch14_224_clip_laion2b',\n",
              " 'vit_huge_patch14_224_clip_laion2b',\n",
              " 'vit_huge_patch14_224_in21k',\n",
              " 'vit_large_patch14_224_clip_laion2b',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_224_in21k',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_224_in21k',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_large_r50_s32_224',\n",
              " 'vit_large_r50_s32_224_in21k',\n",
              " 'vit_large_r50_s32_384',\n",
              " 'vit_relpos_base_patch16_224',\n",
              " 'vit_relpos_base_patch16_clsgap_224',\n",
              " 'vit_relpos_base_patch32_plus_rpn_256',\n",
              " 'vit_relpos_medium_patch16_224',\n",
              " 'vit_relpos_medium_patch16_cls_224',\n",
              " 'vit_relpos_medium_patch16_rpn_224',\n",
              " 'vit_relpos_small_patch16_224',\n",
              " 'vit_small_patch8_224_dino',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_patch16_224_dino',\n",
              " 'vit_small_patch16_224_in21k',\n",
              " 'vit_small_patch16_384',\n",
              " 'vit_small_patch32_224',\n",
              " 'vit_small_patch32_224_in21k',\n",
              " 'vit_small_patch32_384',\n",
              " 'vit_small_r26_s32_224',\n",
              " 'vit_small_r26_s32_224_in21k',\n",
              " 'vit_small_r26_s32_384',\n",
              " 'vit_srelpos_medium_patch16_224',\n",
              " 'vit_srelpos_small_patch16_224',\n",
              " 'vit_tiny_patch16_224',\n",
              " 'vit_tiny_patch16_224_in21k',\n",
              " 'vit_tiny_patch16_384',\n",
              " 'vit_tiny_r_s16_p8_224',\n",
              " 'vit_tiny_r_s16_p8_224_in21k',\n",
              " 'vit_tiny_r_s16_p8_384',\n",
              " 'volo_d1_224',\n",
              " 'volo_d1_384',\n",
              " 'volo_d2_224',\n",
              " 'volo_d2_384',\n",
              " 'volo_d3_224',\n",
              " 'volo_d3_448',\n",
              " 'volo_d4_224',\n",
              " 'volo_d4_448',\n",
              " 'volo_d5_224',\n",
              " 'volo_d5_448',\n",
              " 'volo_d5_512',\n",
              " 'wide_resnet50_2',\n",
              " 'wide_resnet101_2',\n",
              " 'xception',\n",
              " 'xception41',\n",
              " 'xception41p',\n",
              " 'xception65',\n",
              " 'xception65p',\n",
              " 'xception71',\n",
              " 'xcit_large_24_p8_224',\n",
              " 'xcit_large_24_p8_224_dist',\n",
              " 'xcit_large_24_p8_384_dist',\n",
              " 'xcit_large_24_p16_224',\n",
              " 'xcit_large_24_p16_224_dist',\n",
              " 'xcit_large_24_p16_384_dist',\n",
              " 'xcit_medium_24_p8_224',\n",
              " 'xcit_medium_24_p8_224_dist',\n",
              " 'xcit_medium_24_p8_384_dist',\n",
              " 'xcit_medium_24_p16_224',\n",
              " 'xcit_medium_24_p16_224_dist',\n",
              " 'xcit_medium_24_p16_384_dist',\n",
              " 'xcit_nano_12_p8_224',\n",
              " 'xcit_nano_12_p8_224_dist',\n",
              " 'xcit_nano_12_p8_384_dist',\n",
              " 'xcit_nano_12_p16_224',\n",
              " 'xcit_nano_12_p16_224_dist',\n",
              " 'xcit_nano_12_p16_384_dist',\n",
              " 'xcit_small_12_p8_224',\n",
              " 'xcit_small_12_p8_224_dist',\n",
              " 'xcit_small_12_p8_384_dist',\n",
              " 'xcit_small_12_p16_224',\n",
              " 'xcit_small_12_p16_224_dist',\n",
              " 'xcit_small_12_p16_384_dist',\n",
              " 'xcit_small_24_p8_224',\n",
              " 'xcit_small_24_p8_224_dist',\n",
              " 'xcit_small_24_p8_384_dist',\n",
              " 'xcit_small_24_p16_224',\n",
              " 'xcit_small_24_p16_224_dist',\n",
              " 'xcit_small_24_p16_384_dist',\n",
              " 'xcit_tiny_12_p8_224',\n",
              " 'xcit_tiny_12_p8_224_dist',\n",
              " 'xcit_tiny_12_p8_384_dist',\n",
              " 'xcit_tiny_12_p16_224',\n",
              " 'xcit_tiny_12_p16_224_dist',\n",
              " 'xcit_tiny_12_p16_384_dist',\n",
              " 'xcit_tiny_24_p8_224',\n",
              " 'xcit_tiny_24_p8_224_dist',\n",
              " 'xcit_tiny_24_p8_384_dist',\n",
              " 'xcit_tiny_24_p16_224',\n",
              " 'xcit_tiny_24_p16_224_dist',\n",
              " 'xcit_tiny_24_p16_384_dist']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft"
      ],
      "metadata": {
        "id": "tlFFweNSRxqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet timm\n",
        "import timm\n",
        "\n",
        "#model_ft = timm.create_model('efficientnet_b2', pretrained=True)\n",
        "model_ft = timm.create_model('efficientnetv2_rw_m', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Sequential(\n",
        "     nn.Dropout(0.5),\n",
        "     nn.Linear(num_ftrs, 2)\n",
        ")\n",
        "\n",
        "# model_ft = create_RepVGG_A2(deploy=False)\n",
        "# model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "# num_ftrs = model_ft.linear.in_features\n",
        "# model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# from ranger_adabelief import RangerAdaBelief\n",
        "# optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)\n",
        "\n",
        "#save the model\n",
        "PATH = model_folder_path+\"/efficientnet_b2.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "YXzP_K7Ataa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cabfebbd-2e97-40ac-b09c-4529194bcf9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnetv2_rw_m_agc-3d90cb1e.pth\" to C:\\Users\\ykita/.cache\\torch\\hub\\checkpoints\\efficientnetv2_rw_m_agc-3d90cb1e.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Epoch: [ 0/40\n",
            "train_loss: 0.65999 train_acc: 0.61268\n",
            "valid_loss: 0.63175 valid_acc: 0.72583\n",
            "Validation loss decreased (inf --> 0.631754).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 1/40\n",
            "train_loss: 0.53669 train_acc: 0.74809\n",
            "valid_loss: 0.50464 valid_acc: 0.77219\n",
            "Validation loss decreased (0.631754 --> 0.504637).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 2/40\n",
            "train_loss: 0.42028 train_acc: 0.80883\n",
            "valid_loss: 0.37051 valid_acc: 0.83046\n",
            "Validation loss decreased (0.504637 --> 0.370512).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 3/40\n",
            "train_loss: 0.34717 train_acc: 0.85032\n",
            "valid_loss: 0.34979 valid_acc: 0.85033\n",
            "Validation loss decreased (0.370512 --> 0.349795).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 4/40\n",
            "train_loss: 0.31645 train_acc: 0.86425\n",
            "valid_loss: 0.36086 valid_acc: 0.85430\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 5/40\n",
            "train_loss: 0.28584 train_acc: 0.88052\n",
            "valid_loss: 0.27652 valid_acc: 0.88742\n",
            "Validation loss decreased (0.349795 --> 0.276516).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 6/40\n",
            "train_loss: 0.26050 train_acc: 0.89247\n",
            "valid_loss: 0.25406 valid_acc: 0.88874\n",
            "Validation loss decreased (0.276516 --> 0.254061).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 7/40\n",
            "train_loss: 0.23365 train_acc: 0.90441\n",
            "valid_loss: 0.26043 valid_acc: 0.90464\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 8/40\n",
            "train_loss: 0.21477 train_acc: 0.91205\n",
            "valid_loss: 0.22841 valid_acc: 0.90728\n",
            "Validation loss decreased (0.254061 --> 0.228409).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 9/40\n",
            "train_loss: 0.19586 train_acc: 0.92366\n",
            "valid_loss: 0.24493 valid_acc: 0.90861\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [10/40\n",
            "train_loss: 0.19941 train_acc: 0.92366\n",
            "valid_loss: 0.22099 valid_acc: 0.92053\n",
            "Validation loss decreased (0.228409 --> 0.220992).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [11/40\n",
            "train_loss: 0.15351 train_acc: 0.94092\n",
            "valid_loss: 0.20977 valid_acc: 0.91788\n",
            "Validation loss decreased (0.220992 --> 0.209766).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [12/40\n",
            "train_loss: 0.14758 train_acc: 0.94457\n",
            "valid_loss: 0.20349 valid_acc: 0.91921\n",
            "Validation loss decreased (0.209766 --> 0.203486).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [13/40\n",
            "train_loss: 0.13707 train_acc: 0.94656\n",
            "valid_loss: 0.19397 valid_acc: 0.92583\n",
            "Validation loss decreased (0.203486 --> 0.193969).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [14/40\n",
            "train_loss: 0.12788 train_acc: 0.95022\n",
            "valid_loss: 0.18863 valid_acc: 0.93377\n",
            "Validation loss decreased (0.193969 --> 0.188633).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [15/40\n",
            "train_loss: 0.12029 train_acc: 0.95685\n",
            "valid_loss: 0.19841 valid_acc: 0.92053\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [16/40\n",
            "train_loss: 0.12236 train_acc: 0.95851\n",
            "valid_loss: 0.19068 valid_acc: 0.92450\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [17/40\n",
            "train_loss: 0.10223 train_acc: 0.96117\n",
            "valid_loss: 0.18999 valid_acc: 0.93245\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [18/40\n",
            "train_loss: 0.10887 train_acc: 0.95951\n",
            "valid_loss: 0.20043 valid_acc: 0.91258\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [19/40\n",
            "train_loss: 0.08052 train_acc: 0.97113\n",
            "valid_loss: 0.19943 valid_acc: 0.92715\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [20/40\n",
            "train_loss: 0.08047 train_acc: 0.97113\n",
            "valid_loss: 0.20348 valid_acc: 0.92318\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [21/40\n",
            "train_loss: 0.08411 train_acc: 0.96681\n",
            "valid_loss: 0.19379 valid_acc: 0.93377\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [22/40\n",
            "train_loss: 0.06439 train_acc: 0.98108\n",
            "valid_loss: 0.21246 valid_acc: 0.92715\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [23/40\n",
            "train_loss: 0.06925 train_acc: 0.97610\n",
            "valid_loss: 0.19076 valid_acc: 0.93245\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [24/40\n",
            "train_loss: 0.05039 train_acc: 0.98108\n",
            "valid_loss: 0.20690 valid_acc: 0.92185\n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [25/40\n",
            "train_loss: 0.06518 train_acc: 0.97610\n",
            "valid_loss: 0.20119 valid_acc: 0.92848\n",
            "EarlyStopping counter: 11 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [26/40\n",
            "train_loss: 0.04417 train_acc: 0.98506\n",
            "valid_loss: 0.22693 valid_acc: 0.92980\n",
            "EarlyStopping counter: 12 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [27/40\n",
            "train_loss: 0.04974 train_acc: 0.98307\n",
            "valid_loss: 0.23308 valid_acc: 0.92318\n",
            "EarlyStopping counter: 13 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [28/40\n",
            "train_loss: 0.05948 train_acc: 0.97876\n",
            "valid_loss: 0.18414 valid_acc: 0.93775\n",
            "Validation loss decreased (0.188633 --> 0.184137).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [29/40\n",
            "train_loss: 0.05050 train_acc: 0.98341\n",
            "valid_loss: 0.21969 valid_acc: 0.92848\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [30/40\n",
            "train_loss: 0.03112 train_acc: 0.99004\n",
            "valid_loss: 0.17569 valid_acc: 0.93510\n",
            "Validation loss decreased (0.184137 --> 0.175685).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [31/40\n",
            "train_loss: 0.03534 train_acc: 0.98772\n",
            "valid_loss: 0.20299 valid_acc: 0.93245\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [32/40\n",
            "train_loss: 0.03802 train_acc: 0.98639\n",
            "valid_loss: 0.20194 valid_acc: 0.93907\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [33/40\n",
            "train_loss: 0.02087 train_acc: 0.99336\n",
            "valid_loss: 0.24140 valid_acc: 0.93642\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [34/40\n",
            "train_loss: 0.02447 train_acc: 0.99237\n",
            "valid_loss: 0.20257 valid_acc: 0.94172\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [35/40\n",
            "train_loss: 0.03105 train_acc: 0.98971\n",
            "valid_loss: 0.19450 valid_acc: 0.93642\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [36/40\n",
            "train_loss: 0.02546 train_acc: 0.99137\n",
            "valid_loss: 0.19581 valid_acc: 0.92715\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [37/40\n",
            "train_loss: 0.02670 train_acc: 0.99104\n",
            "valid_loss: 0.20815 valid_acc: 0.93907\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [38/40\n",
            "train_loss: 0.02838 train_acc: 0.99038\n",
            "valid_loss: 0.25859 valid_acc: 0.93775\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [39/40\n",
            "train_loss: 0.02194 train_acc: 0.99104\n",
            "valid_loss: 0.19860 valid_acc: 0.93377\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #save the model\n",
        "# PATH = model_folder_path+\"/moblenetv3_large_100.pth\"\n",
        "# torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "0mxURhuFF11M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = model_folder_path+\"/sample.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dK51F4PTZHi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML 飛ばして下さい\n",
        "###########################\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV2\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"grav\", \"cont\"]\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "    classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        ")\n",
        "\n",
        "# Save model\n",
        "mlmodel.save(model_folder_path+\"/sample_\"+model_name+\".mlmodel\")"
      ],
      "metadata": {
        "id": "cx_1FO6qZr0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.xticks(np.arange(0, 20, 4) ) #start, end, 間隔\n",
        "plt.yticks(np.arange(0, 1.4, 0.2) )\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "J2gmKzk9yPOW",
        "outputId": "825b2802-5763-4840-c5df-de75361029c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GradCam**"
      ],
      "metadata": {
        "id": "ihK4e0-90FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "\n",
        "#Normalizationのreverse\n",
        "def invert_norm(tensor):\n",
        "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
        "                                                        std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
        "                                    transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
        "                                                        std = [ 1., 1., 1. ]),\n",
        "                                  ])\n",
        "    inv_tensor = invTrans(tensor)\n",
        "    return(inv_tensor)\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n",
        "def gradcam(model_ft, test_dataset,  row=0, save=False):\n",
        "    # Split model in two parts\n",
        "    features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "    #最後の2層\n",
        "\n",
        "    #評価モードにする    \n",
        "    model_ft = model_ft.eval()\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    classes = [\"cont\", \"grav\"]\n",
        "\n",
        "    #画像のパスを指定\n",
        "    #for j in range(3):\n",
        "    for j in range(len(test_dataset)):\n",
        "\n",
        "        #元画像\n",
        "\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "\n",
        "        img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "        #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "        pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "        #pとcを対にして入力\n",
        "        for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "            sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "            tmp = image.to('cpu').detach().numpy().copy()\n",
        "            img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "            #TensorをImageに変換\n",
        "            sal = Image.fromarray(sal)\n",
        "            sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "            print()\n",
        "            print('image: {}'.format(j))\n",
        "            #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "            #plt.title('')\n",
        "            print('label: '+classes[test_dataset[j][1]])\n",
        "            print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "            #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "            \n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            #グラフを1行2列に並べたうちの1番目\n",
        "            plt.subplots_adjust(wspace=0,hspace=0)\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "            #元の画像を並べて表示\n",
        "            image = test_dataset[j][0]\n",
        "            image = invert_norm(image) #normalizationを戻す\n",
        "            image = image.permute(1, 2, 0)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image)\n",
        "\n",
        "            if save == True:\n",
        "                plt.savefig(gradcam_folder_path+\"/row{}-label{}-pred{}.png\".format(row,classes[test_dataset[j][1]], classes[c]))\n",
        "            row += 1\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "gradcam(model_ft, val_dataset, row=0, save=False)"
      ],
      "metadata": {
        "id": "WcePIt3PyWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated_analysis**"
      ],
      "metadata": {
        "id": "sf8EN-q10MDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "fold, id, number, path, label = [], [], [], [], []\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "for grav, cont in zip(val_dataset_grav, val_dataset_cont):\n",
        "    for j in grav:\n",
        "        fold.append(i)\n",
        "        id.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(1)\n",
        "        k+=1\n",
        "    for j in cont:\n",
        "        fold.append(i)\n",
        "        id.append(k)\n",
        "        number.append(os.path.basename(j))\n",
        "        path.append(j)\n",
        "        label.append(0)\n",
        "        k+=1\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# k=0\n",
        "# for i in val_dataset_grav:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(1)\n",
        "#     k+=1\n",
        "# k=0\n",
        "# for i in val_dataset_cont:\n",
        "#     for j in i:\n",
        "#         fold.append(k)\n",
        "#         number.append(os.path.basename(j))\n",
        "#         path.append(j)\n",
        "#         label.append(0)\n",
        "#     k+=1\n",
        "print(len(fold))\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"fold\", \"img_id\", \"img_number\", \"path\",\"label\", \"pred\", \"prob\"])\n",
        "df_result[\"fold\"] = fold\n",
        "df_result[\"img_id\"] = id\n",
        "df_result[\"img_number\"] = number\n",
        "df_result[\"path\"] = path\n",
        "df_result[\"label\"] = label\n",
        "\n",
        "df_result"
      ],
      "metadata": {
        "id": "8UfoHXFk0J-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5697f870-639c-4968-f7db-ac26030f5b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fold  img_id img_number  \\\n",
              "0       0       0   2644.jpg   \n",
              "1       0       1   6599.jpg   \n",
              "2       0       2   6965.jpg   \n",
              "3       0       3   7077.jpg   \n",
              "4       0       4   2960.jpg   \n",
              "..    ...     ...        ...   \n",
              "661     4     661   6237.jpg   \n",
              "662     4     662   8019.jpg   \n",
              "663     4     663    147.JPG   \n",
              "664     4     664   4949.jpg   \n",
              "665     4     665    806.jpg   \n",
              "\n",
              "                                                  path  label pred prob  \n",
              "0    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "1    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "2    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "3    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "4    /content/drive/MyDrive/Deep_learning/666mai_da...      1  NaN  NaN  \n",
              "..                                                 ...    ...  ...  ...  \n",
              "661  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "662  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "663  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "664  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "665  /content/drive/MyDrive/Deep_learning/666mai_da...      0  NaN  NaN  \n",
              "\n",
              "[666 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09c7e334-21dd-4714-94ae-3f87936f0daa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2644.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6599.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6965.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7077.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2960.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>4</td>\n",
              "      <td>661</td>\n",
              "      <td>6237.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>4</td>\n",
              "      <td>662</td>\n",
              "      <td>8019.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>4</td>\n",
              "      <td>663</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>4</td>\n",
              "      <td>664</td>\n",
              "      <td>4949.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>4</td>\n",
              "      <td>665</td>\n",
              "      <td>806.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>666 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c7e334-21dd-4714-94ae-3f87936f0daa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09c7e334-21dd-4714-94ae-3f87936f0daa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09c7e334-21dd-4714-94ae-3f87936f0daa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#大事なデータを上書きしないよう注意！！#\n",
        "########################################\n",
        "\n",
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) "
      ],
      "metadata": {
        "id": "s_XNgvXXImWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "q67s2cGlztpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start automated analysis\n",
        "fold = 3\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "\n",
        "#Define Data Augumentation\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "for fold in range(fold, num_folds): #指定したfold数から開始\n",
        "    print(\"fold: {}\".format(fold))\n",
        "    train_list = train_dataset_grav[fold] + train_dataset_cont[fold]\n",
        "    train_list_label = list(itertools.repeat(1, len(train_dataset_grav[fold])))+list(itertools.repeat(0, len(train_dataset_cont[fold])))\n",
        "    val_list = val_dataset_grav[fold] + val_dataset_cont[fold]\n",
        "    val_list_label = list(itertools.repeat(1, len(val_dataset_grav[fold])))+list(itertools.repeat(0, len(val_dataset_cont[fold])))\n",
        "\n",
        "    #define dataset and dataloader\n",
        "    train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True, pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "\n",
        "    # show sample image\n",
        "    inputs, classes = next(iter(val_loader))\n",
        "    print(classes)\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    class_names = [\"cont\", \"grav\"]\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    # model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "    # num_ftrs = model_ft.fc.in_features\n",
        "    # model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load (pretrained_model_path))   \n",
        "    num_ftrs = model_ft.linear.in_features\n",
        "    model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    from ranger_adabelief import RangerAdaBelief\n",
        "    optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "    #optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min') \n",
        "\n",
        "\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=300)\n",
        "\n",
        "    #save the model\n",
        "    PATH = model_folder_path+\"/fold_\"+str(fold)+\".pth\"\n",
        "    torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 1.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "    #Prediction for validation set\n",
        "    \n",
        "    val_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0) #val_loader、batch-size、shuffleを直す\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    targets, probs, preds =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          #target = target.squeeze(1)     \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "          _, pred = torch.max(output, 1) \n",
        "        \n",
        "          prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "          prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "          print(prob)\n",
        "          print(pred) \n",
        "          \n",
        "          probs.append(prob) #予測確率\n",
        "          preds.append(int(pred))  #予測結果\n",
        "          targets.append(int(target)) #ラベル\n",
        "    y_label = np.array(targets)\n",
        "    y_pred = np.array(preds)\n",
        "    y_prob = np.array(probs)\n",
        "    print(\"label\")\n",
        "    print(y_label)\n",
        "    print(\"pred\")\n",
        "    print(y_pred)\n",
        "    print(\"prob\")\n",
        "    print(y_prob)\n",
        "\n",
        "    #write result to df\n",
        "    row = 0\n",
        "    if fold == 0:\n",
        "        fold = 0\n",
        "    else:\n",
        "        for m in range(0, fold):\n",
        "            row += len(val_dataset_grav[m]+val_dataset_cont[m])\n",
        "    df_result.loc[row:row+len(y_pred)-1, \"pred\"] = y_pred\n",
        "    column = fold + 9\n",
        "    df_result.loc[row:row+len(y_pred)-1, \"prob\"] = y_prob\n",
        "    df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "    \n",
        "    #GradCam\n",
        "    gradcam(model_ft, val_dataset, row, save=True) \n",
        "\n",
        "    #経過時間を表示\n",
        "    time_end = time.perf_counter()\n",
        "    time_elapsed = (time_end - time_start)\n",
        "    print(\"Elapsed time: \"+str(time_elapsed))"
      ],
      "metadata": {
        "id": "WCTAQQQ12tSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "4Gw576P_uKYj",
        "outputId": "6e689575-812b-4bdb-aac0-320916f081e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fold  img_id img_number  \\\n",
              "0       0       0   2644.jpg   \n",
              "1       0       1   6599.jpg   \n",
              "2       0       2   6965.jpg   \n",
              "3       0       3   7077.jpg   \n",
              "4       0       4   2960.jpg   \n",
              "..    ...     ...        ...   \n",
              "661     4     661   6237.jpg   \n",
              "662     4     662   8019.jpg   \n",
              "663     4     663    147.JPG   \n",
              "664     4     664   4949.jpg   \n",
              "665     4     665    806.jpg   \n",
              "\n",
              "                                                  path  label  pred      prob  \n",
              "0    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.999973  \n",
              "1    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.919740  \n",
              "2    /content/drive/MyDrive/Deep_learning/666mai_da...      1   0.0  0.458516  \n",
              "3    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.988250  \n",
              "4    /content/drive/MyDrive/Deep_learning/666mai_da...      1   1.0  0.663085  \n",
              "..                                                 ...    ...   ...       ...  \n",
              "661  /content/drive/MyDrive/Deep_learning/666mai_da...      0   1.0  0.778016  \n",
              "662  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.007451  \n",
              "663  /content/drive/MyDrive/Deep_learning/666mai_da...      0   1.0  0.519158  \n",
              "664  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.007944  \n",
              "665  /content/drive/MyDrive/Deep_learning/666mai_da...      0   0.0  0.192361  \n",
              "\n",
              "[666 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>img_id</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2644.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6599.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.919740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6965.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7077.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2960.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>4</td>\n",
              "      <td>661</td>\n",
              "      <td>6237.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.778016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>4</td>\n",
              "      <td>662</td>\n",
              "      <td>8019.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>4</td>\n",
              "      <td>663</td>\n",
              "      <td>147.JPG</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.519158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>4</td>\n",
              "      <td>664</td>\n",
              "      <td>4949.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>4</td>\n",
              "      <td>665</td>\n",
              "      <td>806.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Deep_learning/666mai_da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.192361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>666 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-252615c1-acdc-4fbf-9cec-3f86d2cc22a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "Uh_aAup_hd5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#################################################\n",
        "threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "#################################################\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "\n",
        "X = df_result[\"prob\"]\n",
        "Y = df_result[\"label\"]\n",
        "\n",
        "Y_pred_proba = X\n",
        "Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "acc = accuracy_score(Y, Y_pred)\n",
        "print('Accuracy:',acc)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "#5-fold分のconfusion matrixを加算\n",
        "confusion_arr += confusion_matrix(Y, Y_pred)\n",
        "\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "#ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "accuracy.append(accuracy_score(Y, Y_pred))\n",
        "precision.append(precision_score(Y, Y_pred))\n",
        "recall.append(recall_score(Y, Y_pred))\n",
        "specificity.append(specificity_score(Y, Y_pred))\n",
        "f1score.append(f1_score(Y, Y_pred))\n",
        "area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#ヒートマップを作成\n",
        "arr_2d = np.round(confusion_arr/5).astype(int) #5foldの合計をfold数で割って平均を出す、整数に丸めて整数型にする\n",
        "df_matrix = pd.DataFrame(data=arr_2d, index=[\"Normal\", \"TED\"], columns=[\"Normal\", \"TED\"])\n",
        "print(df_matrix)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(df_matrix, annot=True,fmt=\"d\", cmap='Blues')\n",
        "plt.savefig(r\"C:\\Users\\ykita\\Downloads\\per_image_confusion_matrix.png\", dpi=700)\n",
        "plt.show()\n",
        "plt.close('all')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NmOJDYqaQEwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2b034deb-709c-47d0-aa0e-698266487d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d9a413f40790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr,tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.savefig(r\"C:\\Users\\ykita\\Downloads\\ROC_5fold.png\", format=\"png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = [1]\n",
        "fig = Draw_roc_curve([Y], [Y_pred_proba], roc_label_list, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cb48jClLk24l",
        "outputId": "d4ec7982-65ea-4a8b-da92-be0d79ea697e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAGDCAYAAAA72Cm3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZd7G8e8vCSH0jiBdRUGUZmiKgAhIFQGVqiLsIlawrGUty7r4vquiguVdBEUEEVgBFQRl1xUsYCFBUMACKtKihE6AEJI87x8zZIcQkglkcmaS+3Ndc5nTfzOJ3PM85znnmHMOERERiTxRXhcgIiIip0chLiIiEqEU4iIiIhFKIS4iIhKhFOIiIiIRSiEuIiISoRTiItmY2Xoz6+R1HV4zs8lm9mghH3O6mY0vzGOGipkNNbN/nea2+huUoJiuE5dwZmabgbOADCAF+AC4wzmX4mVdRY2ZDQf+4Jxr73Ed04FtzrlHPK5jHHCec25YIRxrOmHwniUyqSUukaCPc64s0BxoATzkcT35ZmYxxfHYXtJnLsWBQlwihnPuN2ApvjAHwMzamtlKM9tnZmsDuyDNrLKZvWZmO8xsr5m9E7Cst5mt8W+30syaBizbbGZdzOxsMztiZpUDlrUws11mVsI/PcLMvvPvf6mZ1QtY15nZ7Wa2EdiY03sys6v9Xaf7zGy5mTXOVsdDZrbBv//XzCwuH+/hATP7BjhkZjFm9qCZ/WRmB/377OdftzEwGWhnZilmts8/P6tr28w6mdk2M7vXzHaaWZKZ3RxwvCpmtsjMDpjZKjMbb2afnep3aWbtA35vW/09AcdVMrPF/jq/NLNzA7ab5F//gJklmtnlAcvGmdk8M3vDzA4Aw82stZl97j9Okpm9aGaxAds0MbN/m9keM/vdzP5sZt2BPwMD/Z/HWv+6FczsVf9+tvvfY7R/2XAzW2Fmz5nZbmCcf95n/uXmX7bTX/u3ZnaRmY0ChgL3+4+1KOD318X/c7S/ruO/u0Qzq3Oqz1aKGeecXnqF7QvYDHTx/1wb+BaY5J+uBewGeuL7QtrVP13Nv3wxMBeoBJQAOvrntwB2Am2AaOAm/3FK5nDMj4A/BtTzNDDZ/3NfYBPQGIgBHgFWBqzrgH8DlYFSOby384FD/rpLAPf79xcbUMc6oI5/HyuA8fl4D2v825byz7sOONv/WQ30H7umf9lw4LNs9U0POF4nIB143F9rT+AwUMm/fI7/VRq4ENiafX8B+60HHAQG+/dVBWgecMzdQGv/ZzoLmBOw7TD/+jHAvcBvQJx/2TjgGHCN/z2WAi4B2vrXrw98B4z1r18OSPLvJ84/3SZgX29kq/tt4GWgDFAd+Aq4JeDzSwfu9B+rVOBnClwFJAIVAcP3N1Mz++d8ir/7P+H7u7/Av20zoIrX/2/qFR4vzwvQS6/cXv5/zFL8/+g74D9ARf+yB4CZ2dZfii/QagKZx0Mm2zr/AP6Wbd4P/DfkA/8B/QPwkf9n84dTB//0+8DIgH1E4Qu2ev5pB3TO5b09Cvwz2/bbgU4BdYwOWN4T+Ckf72FEHp/tGqCv/+eswAlYnhUu+EL8CBATsHwnvoCMxheeFwQsG599fwHLHgLePsWy6cAr2d7z97m8h71AM//P44BP8njPY48fG9+XiK9Psd44AkIc37iMowR8GfNvvyzg89uSbR9ZnynQGfjR/3lFnepzzvZ3f/xv8Ifjvye99Mr+Une6RIJrnHPl8AVJI6Cqf3494Dp/V+k+fzdwe3wBXgfY45zbm8P+6gH3ZtuuDr5Wanbz8XUz1wQ64Pti8GnAfiYF7GMPvqCvFbD91lze19nAr8cnnHOZ/vVPtf2vATUG8x5OOLaZ3RjQ/b4PuIj/fpbB2O2cSw+YPgyUBarha30GHi+3910H+CmX5b/lcAwAzOw+852+2O9/DxU48T1kf8/nm9l7Zvabv4v9fwLWz6uOQPXw9RokBXx+L+Nrked47EDOuY+AF4GXgJ1mNsXMygd57PzUKcWMQlwihnPuY3ytlgn+WVvxtcQrBrzKOOf+7l9W2cwq5rCrrcAT2bYr7ZybncMx9wL/wtf9PARf164L2M8t2fZTyjm3MnAXubylHfjCAfCdN8X3D/b2gHUCz33W9W8T7HvIOrb5ztVPBe7A1xVbEV9XvQVRZ16S8XUl1z5F3dltBc7NZXmO/Oe/7weux9fDUhHYz3/fA5z8Pv4BfA80dM6Vx3eu+/j6W4FzTnG47PvZiq8lXjXg8y7vnGuSyzYn7tC5551zl+A73XA+vm7yPLfjND8vKR4U4hJpJgJdzawZ8AbQx8yu8g/+ifMPwKrtnEvC1939f2ZWycxKmFkH/z6mAqPNrI1/wFEZM+tlZuVOccw3gRuBa/0/HzcZeMjMmkDWwKfr8vFe/gn0MrMrzTdQ7l58QRH4JeB2M6ttvsF1D+M7x38676EMvrBI9td6M76W+HG/A7UDB30FyzmXASzAN5irtJk1wvd5ncosoIuZXW++AXdVzKx5LusfVw7fl4VkIMbMHgPyas2WAw4AKf66bg1Y9h5Q08zGmllJMytnZm38y34H6ptZlP89JuH7MveMmZU3sygzO9fMOgZRN2bWyv+7KoFvLEIqvl6d48c61ZcJgFeAv5lZQ//vuqmZVQnmuFL0KcQlojjnkoEZwGPOua34Bpf9Gd8/7FvxtW6O/13fgO9c7ff4zt+O9e8jAfgjvu7NvfgGkw3P5bALgYbAb865tQG1vA08Cczxd9WuA3rk4738gG+g1gvALqAPvsvp0gJWexNfePyMr0t1/Om8B+fcBuAZ4HN8oXExvoFyx30ErAd+M7Ndwb6HAHfg69r+DZgJzMb3hSSnWrbgO9d9L75TEGvwDdbKy1J89wn4Ed+phVRy77YHuA9fD8pBfF98jn8Jwjl3EN+gwj7+ujcCV/gXv+X/724zW+3/+UYgFtiA7zOfh+/UTTDK+4+/11/7bnyDJAFeBS70d9O/k8O2z+L7wvcvfF9IXsU3cE5EN3sRCVfmu9HNH5xzH3pdS36Z2ZNADefcTV7XIlKUqSUuImfMzBr5u3nNzFoDI/FdkiUiIaS7ColIQSiHrwv9bHzd9c8A73pakUgxoO50ERGRCKXudBERkQilEBcREYlQEXdOvGrVqq5+/fpelyEiIlIoEhMTdznnquW0LOJCvH79+iQkJHhdhoiISKEws19PtUzd6SIiIhFKIS4iIhKhFOIiIiIRSiEuIiISoRTiIiIiEUohLiIiEqEU4iIiIhFKIS4iIhKhFOIiIiIRKmQhbmbTzGynma07xXIzs+fNbJOZfWNmLUNVi4iISFEUypb4dKB7Lst7AA39r1HAP0JYi4iISJETshB3zn0C7Mlllb7ADOfzBVDRzGqGqh4REZGQ6NULzE58FRIvH4BSC9gaML3NPy8p+4pmNgpfa526desWSnEiIpKLXr1gyRKvqyj2ImJgm3NuinMu3jkXX61ajk9jExGRQDm1DgvypQA/wWcVLsIYR0z0X3l58qpCO66XLfHtQJ2A6dr+eSIiEgyvW8M9e8Lixd4dP0z07DmL99/fRL16FZg9ewDt2tXJe6MC4mVLfCFwo3+Ueltgv3PupK50EZGwF+pW7+m2hnv2BOdC91KAAzB5cm9GjGjOmjWjCzXAIbSXmM0GPgcuMLNtZjbSzEab2Wj/KkuAn4FNwFTgtlDVIiISUl63hhWyherrr5O4/fbFZGY6AOrWrcCrr/alYsW4Qq8lZN3pzrnBeSx3wO2hOr6ISEjl1JXtnDe1SKFwzvH8819y//0fkpaWQcuWNRk50ttbnHh5TlxEJDLlFOA9e3pTixSKXbsOc/PN7/Leez8CcOut8QwZcrHHVSnERSQSeT2g6zgN7CoWli/fzNChC9ix4yAVK8bx6qtX079/Y6/LAhTiIlLYwiWAz5QCvFj48MOf6dZtJs7BZZfV4c03B1C3bgWvy8qiEBeRglHY4awQlULQsWM9Lr20Dp07N+CxxzoSExNet1dRiIvI6TmT0FYASxh7993vufTSOlSrVoYSJaJZvnx42IX3ceFZlYiEl5yug84pwIO9LlkBLmHoyJFj3HbbYq65Zi433/wuzn+1QbgGOKglLiI5CbaVrRa1FBHr1+9k0KD5rFu3k9jYaLp1O9frkoKiEBcp7hTYUow553jlldWMGfMBR46kc/75VZgzZwAtWkTGQzUV4iLFWW4BrtCWIi4z0zF06ALmzFkHwPDhzXnhhR6ULRvrcWXBU4iLFAd5tbYV2FIMRUUZdeqUp2zZWCZP7sXQoU29LinfzEXYbQLj4+NdQkKC12WIhIeCuKxLAS7FSGamY8uW/dSvXxGAtLQMtm8/QIMGlTyu7NTMLNE5F5/TsvAdcicip3Z8tHh+AvxUI8cV4FJMJCUdpFu3mbRvP43duw8DEBsbHdYBnheFuEg4yuvRloHhrcu6RPL0/vsbadZsMv/5zy+kpWXw0097vS6pQOicuEg40mhxkQKRlpbBQw99yLPPfgFAly7nMGPGNdSsWc7jygqGQlyksJzO+esIG7MiEk42bdrD4MHzSUjYQXS0MX58Z+6//zKioszr0gqMQlwkvwrrHuF6tKXIGdm4cTcJCTuoX78is2cPoG3b2l6XVOAU4iLBKKjgVhe4SEhlZGQSHe0b7tWjR0PeeKMfvXqdT8WKcR5XFhoa2CZyXG6DybIHeLCDyTS4TKTQrF6dxMUX/4PPPtuSNW/o0KZFNsBBIS7iE0xLOzC4FcYiYcM5x8SJX9Cu3at8990u/v73z7wuqdCoO10kMMDV3S0SUZKTD3Hzze+yePFGAG67LZ4JE7p5XFXhUYhL8RBsS1sBLhIxli37haFDF5CUlELFinFMm3Y1/fo19rqsQqUQl6LhTAeeKcBFIsqhQ2kMHDiP5OTDXHZZHd58cwB161bwuqxCpxCXyJXf4FZQixQZZcrEMm1aX776ajuPPdaRmJjiOcRLIS6R51ThrZAWKdIWLPiObdsOcNddbQDo3ft8evc+3+OqvKUQl/CnZ16LFGtHjhzjnnuWMnlyItHRxpVXNqBJk+pelxUWFOISHtQ1LiI5WL9+JwMHzmP9+mRiY6OZMKErF15YzeuywoZCXMKDRo6LSADnHFOmJDJ27FJSU9O54IIqzJlzLc2b1/C6tLCiEBdvZW+B64EfIgKMH/8Jjz22HIDhw5vzwgs9KFs21tuiwlDxHM4n3sjptqbZn4stIoIvuOvVq8CsWf157bW+CvBTUEtcQifY89zqKhcp9jIzHbNnf8vgwRcTFWXUqVOBjRvvpESJaK9LC2tqiUvonOoyMD0UREQC7NhxkG7dZjJs2NtMmLAya74CPG9qiUvByK3VrfPcInIKS5Zs5Kab3mHXrsNUr16Gpk3P8rqkiKIQl/w5nUvBRESyOXo0nYce+g/PPfcFAF26nMPMmf2oUaOsx5VFFoW4BC+vANe5bREJwu+/p9Cz55usXp1ETEwU48dfwZ/+dBlRUeZ1aRFHIS45013SRCREqlQpTVxcDPXrV2T27AG0bVvb65IilkJccqYAF5EClJKSxtGj6VSpUpqYmCjeeus6ypQpQYUKcV6XFtEU4pI7DUoTkTO0enUSgwbN47zzKvPee0OIijLOPruc12UVCbrETEREQsI5x8SJX9C27Sts3LiHbdsOsHv3Ya/LKlLUEhcRkQKXnHyI4cPfZcmSjQDcfnsrJkzoRlycYqcg6dMUEZEC9dFHvzBs2AKSklKoVCmOV1+9mn79GntdVpGk7nQ50fH7m4uInKZ///snkpJSaN++LmvWjFaAh5Ba4nIiPZBERE5DRkYm0dG+duHjj19BvXoV+cMfWhITo7ZiKOnTlZzpnuYiEqR58zbQtOlkdu3yDVorUSKa0aPjFeCFQJ+w+KgbXUTy6ciRY4we/R7XXfcWGzYkM3VqotclFTvqThcfdaOLSD6sW7eTQYPmsX59MrGx0UyY0JU77mjtdVnFjkJcfK3w43RzFxHJhXOOKVMSGTt2Kamp6VxwQRXmzLmW5s1reF1asaQQLw6CffKYWuAikoevv/6N0aN942VGjGjO88/3oEyZWI+rKr4U4sVBsAGugWwikoeWLWsyblxHzj+/CoMHX+x1OcWeQrw4UVe5iORTRkYmf//7Z7RvX5eOHesD8Je/dPK0JvkvjU4vqo6PNteIcxE5TTt2HKRr15k88sgybrjhbVJT070uSbIJaYibWXcz+8HMNpnZgzksr2tmy8zsazP7xsx0UvZMHQ/v7F3oOt8tIvmwePGPNGs2mWXLNlO9ehmmTu2j+56HoZD9RswsGngJ6ApsA1aZ2ULn3IaA1R4B/umc+4eZXQgsAeqHqqZiIfulYjrPLSL5cPRoOg8++CETJ34JQNeu5zBjRj9q1CjrcWWSk1B+rWoNbHLO/QxgZnOAvkBgiDugvP/nCsCOENZTdOU0+lznv0XkNFxzzVw++GATMTFRPPFEZ+6771KionRaLlyFMsRrAVsDprcBbbKtMw74l5ndCZQBuoSwnqJLXeciUkDuvLM1P/64mzff7E+bNrW9Lkfy4PXAtsHAdOdcbaAnMNPMTqrJzEaZWYKZJSQnJxd6kRHDOd3zXETy5eDBoyxc+EPWdM+eDfnuu9sV4BEilCG+HagTMF3bPy/QSOCfAM65z4E4oGr2HTnnpjjn4p1z8dWqVQtRuSIixUti4g5atpxC//5zWbFiS9b82NhoD6uS/AhliK8CGppZAzOLBQYBC7OtswW4EsDMGuMLcTW18yPwlqkiIkFwzvHcc5/Trt2rbNq0hyZNqlO5cimvy5LTELJz4s65dDO7A1gKRAPTnHPrzexxIME5txC4F5hqZnfjG+Q23DmNyMpRXrdO1XlwEQlCcvIhhg9/lyVLNgJw++2tmDChmy4fi1Ah/a0555bgu2wscN5jAT9vAC4LZQ0RL5j7nutSMhEJwldfbeeaa+aQlJRCpUpxTJvWl2uuaeR1WXIG9NUrXOUU3gprETkDZ59djqNHM7j88rrMmtWfOnUqeF2SnCGFeDjKHuAKbxE5Tdu3H6BGjbJER0dRu3Z5PvvsZho2rEJMjNcXJ0lB0G8xHB0P8J49dcmYiJy2efM20KTJ//HUUyuy5jVuXE0BXoSoJR5uAkebK7xF5DQcPnyMu+/+gClTVgOQmJiEcw7TA5GKHIV4OAnsRtdocxE5DevW7WTQoHmsX59MyZLRPPNMN267rZUCvIhSiHvpVCPPdQ5cRPLJOceUKYmMHbuU1NR0LrigCnPnXkuzZjW8Lk1CSCHuFQW4iBSgzEzHrFnfkpqazogRzXn++R6UKRPrdVkSYgpxrwR2myu0ReQ0ZWY6oqKM6OgoZs3qz8qVWxk48CKvy5JCoiGKhalXLzDzvY5TgIvIacjIyOSJJz6hT5/ZZGb6bnRZp04FBXgxo5Z4Ycit61xEJJ927DjIsGELWLZsMwCffPIrnTrV97Qm8YZCvDDoxi0iUkAWL/6R4cPfZdeuw1SvXoaZM/spwIsxhXhh0rNdROQ0HT2azoMPfsjEiV8C0K3bucyYcQ1nnVXW48rESzonLiISAaZMSWTixC+JiYniqae68P77QxXgopa4iEgkGD06ni++2M6YMW1o3bqW1+VImFBLXEQkDB08eJS77nqfnTsPAVCiRDSzZvVXgMsJ1BIXEQkziYk7GDRoPps27WHHjoPMm3e91yVJmFJLXEQkTGRmOp599nPatXuVTZv20LTpWYwf39nrsiSMqSUuIhIGdu48xPDh7/D++5sAuOOOVjz9dDfi4vTPtJya/jpERDx24MBRWrR4mR07DlK5cimmTbuavn0beV2WRAB1p4fS8dusiojkonz5ktxwQ1M6dKjH2rWjFeASNLXEQyn7ndpERPw2b97Hzp2Hskab/+1vV2Q9yEQkWPprCYXsLXDndKtVEcny1lvrad58Mv36zWXXrsOA7xIyBbjkl/5iCtLx8FYLXERycPjwMUaNWsT1189j//6jtGp1NlFROuUmp0/d6QVJDzoRkVP49tvfGTRoPhs2JFOyZDTPPNON225rhWncjJwBhXgo6EEnIhJgxoy13HLLe6SmptOoUVXmzBlAs2Y1vC5LigCFuIhIiFWvXobU1HRGjmzBpEndKVMm1uuSpIhQiIuIhMCOHQc5++xyAHTvfh5ff30LzZur9S0FSwPbztTxwWw6ryUiQEZGJuPHf0KDBpP49NNfs+YrwCUUFOJnKnAwG2g0ukgxtn37Abp0mcmjjy4jLS2DL7/c7nVJUsSpO72gaDCbSLH23ns/Mnz4O+zefYSzzirDzJn96Nr1XK/LkiJOIS4icgaOHk3ngQc+ZNKkLwHo1u1cZsy4hrPOKutxZVIcqDtdROQM7NlzhFmzviUmJoqnnurC++8PVYBLoVFLXEQkn5z/9JmZUbNmOWbPHkD58iWz7oMuUlgU4iIi+XDw4FFuvXUxjRtX5eGHOwDQpcs5HlclxZVCXEQkSAkJOxg0aB4//bSX8uVLcuutrahcuZTXZUkxpnPiIiJ5yMx0PPPMSi699FV++mkvzZqdxZdf/kEBLp5TS1xEJBc7dx7ippve4YMPNgFw552teeqprsTF6Z9P8Z7+CkVEcnHnne/zwQebqFy5FNOmXU3fvo28Lkkki0JcRCQXzzzTjbS0DF54oQe1a5f3uhyRE+icuIhIgF9+2cu99y4lM9N3GVnt2uV5++2BCnAJS2qJi4j4/fOf6/njHxdx4MBR6tatwJgxbb0uSSRXQYe4mZV2zh0OZTEiIl44fPgYY8d+wNSpqwG45ppG3HBDM4+rEslbnt3pZnapmW0AvvdPNzOz/wt5ZeFMjx8VKTK+/fZ34uOnMHXqakqWjOall3qyYMH1unxMIkIwLfHngKuAhQDOubVm1iGkVYU7PX5UpEj46qvtdOjwGkePZtC4cVXmzLmWpk3P8roskaAF1Z3unNtqJ7Y6M0JTThjr1evk8NbjR0UiWsuWNWnVqhaNGlVh4sTulCkT63VJIvkSTIhvNbNLAWdmJYAxwHehLSsMqfUtUiSsWLGF886rzFlnlSUmJop//WsYpUqV8LoskdMSzCVmo4HbgVrAdqA5cFsoiwprzvleixd7XYmI5ENGRiZ/+9vHdOgwnZtueifrEjIFuESyYFriFzjnhgbOMLPLgBWhKUlEpGBt336AYcPeZvnyzQA0b16DzExHVJQGp0pkCybEXwBaBjFPRCTsLFr0Azff/C67dx/hrLPKMHNmP7p2PdfrskQKxClD3MzaAZcC1czsnoBF5YHoUBcmInImnHPce++/eO65LwC46qpzef31azjrrLIeVyZScHJriccCZf3rlAuYfwC4NpRFiYicKTOjVKkYYmKi+Pvfr+Tuu9up+1yKHHN5XCZlZvWcc7+e1s7NugOT8LXcX3HO/T2Hda4HxgEOWOucG5LbPuPj411CQsLplHNmjl9ip8vKRMKWc47ffz9EjRq+1nZ6eiYbNiTr2m+JaGaW6JyLz2lZMOfED5vZ00ATIO74TOdc5zwOGg28BHQFtgGrzGyhc25DwDoNgYeAy5xze82sehD1iIic5MCBo9x662KWLfuFtWtHU61aGWJiohTgUqQFc4nZLHy3XG0A/BXYDKwKYrvWwCbn3M/OuTRgDtA32zp/BF5yzu0FcM7tDLLuwtWrl9cViEguVq3aTsuWL/Pmm9+yf/9R1qz5zeuSRApFMCFexTn3KnDMOfexc24EkGsr3K8WsDVgept/XqDzgfPNbIWZfeHvfj+JmY0yswQzS0hOTg7i0AXs+I1edIMXkbCSmemYMGEll146jZ9+2kvz5jVYvXqURp9LsRFMd/ox/3+TzKwXsAOoXIDHbwh0AmoDn5jZxc65fYErOeemAFPAd068gI6df7rBi0jY+P33FG666R2WLv0JgLvuas2TT3YlLk5PWJbiI5i/9vFmVgG4F9/14eWBsUFstx2oEzBd2z8v0DbgS+fcMeAXM/sRX6gH011fONSVLhKWvv12J0uX/kSVKqV47bW+9OlzgdcliRS6PEPcOfee/8f9wBWQdce2vKwCGppZA3zhPQjIPvL8HWAw8JqZVcXXvf5zcKUXEnWli4QN5xzHH8bUpcs5vPJKH6666jxq1y7vcWUi3jjlOXEzizazwWZ2n5ld5J/X28xWAi/mtWPnXDpwB7AU3wNT/umcW29mj5vZ1f7VlgK7/c8rXwb8yTm3+wzfU2ioK13EU7/8spf27V/LunUqwMiRLRXgUqyd8jpxM5uOrzv8K6ANvnPh8cCDzrl3CqvA7Ar9OnFdHy7iublz1zFq1HscOHCUdu1qs2LFiKwWuUhRd7rXiccDTZ1zmWYWB/wGnBu2LWURKXIOHUpj7NgPeOWVrwG45ppGvPrq1QpwEb/cQjzNOZcJ4JxLNbOfFeAiUli++eZ3Bg6cx/ff76JkyWieffYqbr01XgEuEiC3EG9kZt/4fzbgXP+0Ac451zTk1YlIsZSWlkHv3m+ydesBGjeuyty513Lxxbrzmkh2uYV440KrQkQkQGxsNC+/3Ju33/6eiRO7U7p0Ca9LEglLpwzx033oiYjI6fj0019Zu/Z37rijNQA9ejSkR4+GHlclEt50ayMR8VRGRiZPPPEpf/3rxwC0aVOLVq2y36FZRHKiEBcRz2zbdoBhwxbw8ce/YgYPPtie5s1reF2WSMQIKsTNrBRQ1zn3Q4jrEZFiYuHCH7j55nfZs+cINWqUZebMfnTpco7XZYlElDyfYmZmfYA1wAf+6eZmtjDUhYUF3TddJCT+8Y9V9O07hz17jtCjx3msXTtaAS5yGoJ5FOk4fM8G3wfgnFuD79niRZ/umy4SEldffQE1a5ZlwoSuvPfeEKpXL+N1SSIRKahHkTrn9me7wULxugep7psuckaccyxevJEePc4jOjqKWrXKs2nTXbp0TOQMBdMSX29mQ4BoM2toZi8AK0Ncl4gUEQcOHGXo0AX06TObv//9s6z5CnCRMxdMiN8JNAGOAm/ieyRpMM8TF5FibtWq7bRo8TKzZ6+jTJkS1KlTweuSRIqUYLrTGznnHgYeDnUxIlI0ZGY6nnlmJVZL0pEAACAASURBVH/+80ekp2fSokUNZs8ewAUXVPW6NJEiJZgQf8bMagDzgLnOuXUhrklEItj+/akMHDiPpUt/AmDMmDY8+WQXSpbUbSlEClqe3enOuSuAK4Bk4GUz+9bMHgl5ZV7q1eu/zxEXkXwpWzaWI0fSqVKlFIsWDWbixO4KcJEQMeeCH2huZhcD9wMDnXOxIasqF/Hx8S4hISG0BwkM8J49NTpdJA/HjmWQkpJGpUqlANi+/QAAtWqV97IskSLBzBKdc/E5Lcvz67GZNQYGAgOA3cBc4N4CrTBc5eMLjkhx9csvexk8eD7lypVk6dJhREWZwlukkATTxzUNX3Bf5ZzbEeJ6vKe7tIkEbe7cdYwa9R4HDhylTp3ybNt2gLp1NQJdpLDkGeLOuXaFUUjY0F3aRPJ06FAaY8Z8wKuvfg1A//6NeeWVPlnd6SJSOE4Z4mb2T+fc9Wb2LSfeoc0A55xrGvLqvKTz4CI5Wrv2NwYNms/33++iZMloJk7szi23XIJpMKhIocutJT7G/9/ehVGIiESGBQu+4/vvd3HhhdWYM2cAF198ltcliRRbpwxx51yS/8fbnHMPBC4zsyeBB07eSkSKIudcVkv70Uc7UqZMLHfc0Vq3ThXxWDC3Xe2aw7weBV2IiISnTz/9lTZtXuH331MAiImJ4v77L1OAi4SBU4a4md3qPx9+gZl9E/D6Bfim8EoUES9kZGTy178up1On11m1agcTJui5RyLhJrdz4m8C7wP/CzwYMP+gc25PSKvyii4vEwFg27YDDB26gE8++RUzeOih9vz1r528LktEssktxJ1zbrOZ3Z59gZlVLpJBrsvLRHj33e8ZMWIhe/YcoUaNsrzxRj+uvPIcr8sSkRzk1RLvDSTiu8Qs8PoRBxSd/6t79fpvgIMuL5Ni68cfd9Ov31ycgx49zmP69GuoXr2M12WJyCnkNjq9t/+/DQqvHI8EBrha4VKMnX9+FR59tAMVKsQxdmxboqJ07bdIOAvm3umXAWucc4fMbBjQEpjonNsS8uoKm+6VLsWMc47p09dQv35FrrjC9339r3+9wuOqRCRYwVxi9g/gsJk1w/fgk5+AmSGtSkRC7sCBowwduoARIxYydOgCDhw46nVJIpJPwYR4uvM9r7Qv8KJz7iWgXGjLEpFQ+uqr7bRo8TKzZ6+jTJkS/P3vXShfvqTXZYlIPgXzFLODZvYQcANwuZlFAbrLg0gEysx0TJiwkocf/oj09ExatKjBnDnXcv75VbwuTUROQzAt8YHAUWCEc+43oDbwdEirKiy9eoEe2iDFyPDh7/DAAx+Snp7JmDFt+PzzkQpwkQiWZ4j7g3sWUMHMegOpzrkZIa+sMGhUuhQzw4Y1pVq10ixaNJiJE7tTsmQwnXEiEq6CGZ1+Pb6W93J814q/YGZ/cs7NC3FthUej0qWIOnYsg+XLN9O167kAdOt2Lj//PIayZWM9rkxECkIwX8MfBlo553YCmFk14EOg6IS4SBH08897GTx4PgkJO/jooxvp2LE+gAJcpAgJJsSjjge4326CO5cuIh6ZM2cdt9zyHgcOHKVu3QrExkZ7XZKIhEAwIf6BmS0FZvunBwJLcllfRDxy6FAad931PtOmrQGgf//GvPJKHypVKuVxZSISCnmGuHPuT2bWH2jvnzXFOfd2aMsSkfz6/vtd9Os3l++/30VcXAwTJ17FqFGXYLoCQ6TIOmWIm1lDYAJwLvAtcJ9zbnthFSYi+VOhQkl27z7MhRdWY+7ca7nooupelyQiIZZbS3waMAP4BOgDvAD0L4yiRCQ4e/ceoXz5kkRHR1GzZjn+/e8baNiwCqVL635MIsVBbgPUyjnnpjrnfnDOTQDqF1JNIhKETz75laZNJ/PEE59mzWvWrIYCXKQYyS3E48yshZm1NLOWQKls0yLigfT0TMaNW84VV7zOtm0H+Pe/fyY9PdPrskTEA7l1pycBzwZM/xYw7YDOoSpKRHK2det+hg5dwKefbsEM/vzn9owb14mYGF31KVIcnTLEnXN6qLBIGHn33e8ZMWIhe/YcoWbNssyc2Y8rrzzH67JExEO6cbJIBHDOMWnSl+zZc4SePRsyfXpfqlUr43VZIuIxhbhIGHPOYWaYGTNn9mPBgu+4/fbWREXp2m8R0e1TRcKSc45p076mb985ZGT4Bq3VqlWeO+9sowAXkSx5hrj5DDOzx/zTdc2sdehLEyme9u9PZciQBYwcuZBFi35k0aIfvS5JRMJUMC3x/wPaAYP90weBl4LZuZl1N7MfzGyTmT2Yy3oDzMyZWXww+xUpqr76ajstWrzMnDnrKFOmBK+/fg3XXNPI67JEJEwFc068jXOupZl9DeCc22tmeT7L0Myi8YV9V2AbsMrMFjrnNmRbrxwwBvgy39WLFBGZmY4JE1by8MMfkZ6eSYsWNZgz51rOP7+K16WJSBgLpiV+zB/IDrKeJx7MnSVaA5uccz8759KAOUDfHNb7G/AkkBpcySJFz8yZa3nggQ9JT89k7Ng2fP75SAW4iOQpmBB/HngbqG5mTwCfAf8TxHa1gK0B09v887L47/xWxzm3OLcdmdkoM0sws4Tk5OQgDi0SWYYObUr//o15773BPPdcd0qW1IUjIpK3YB5FOsvMEoErAQOucc59d6YHNrMofHeAGx5EDVOAKQDx8fHuTI8t4rW0tAz+538+ZfToeGrUKEtMTBTz51/vdVkiEmHyDHEzqwscBhYFznPObclj0+1AnYDp2v55x5UDLgKW+593XANYaGZXO+cSgitfJPL8/PNeBg2ax6pVO/jqq+0sWTLU65JEJEIF02e3GN/5cAPigAbAD0CTPLZbBTQ0swb4wnsQMOT4QufcfqDq8WkzW47vmeUKcCmyZs/+lltueY+DB9OoW7cCDz98udcliUgEC6Y7/eLAaf957NuC2C7dzO4AlgLRwDTn3HozexxIcM4tPM2aRSLOoUNp3Hnn+7z22hoABgxozNSpfahUqZTHlYlIJMv36Bnn3GozaxPkukuAJdnmPXaKdTvltxaRSJCamk7r1q+wYUMycXExTJx4FaNGXYL/NJKIyGkL5pz4PQGTUUBLYEfIKhIpYuLiYujfvxFmMGfOtVx0UXWvSxKRIsKcy32wt5n9JWAyHdgMzHfOeXJdd3x8vEtIKKDT5sdbQnl8BiL5tXv3YTZv3scll5wNQHp6JmlpGZQuXcLjykQk0phZonMuxzua5toS99/kpZxz7r6QVCZSBH388WaGDl1ARoZj7drRVK9ehpiYKGJi9LwhESlYp/xXxcxinHMZwGWFWI9IxEpPz2TcuOV07jyD7dsPcs45lUhLy/C6LBEpwnJriX+F7/z3GjNbCLwFHDq+0Dm3IMS1iUSMrVv3M3ToAj79dAtm8PDDlzNuXCe1vkUkpIIZnR4H7AY689/rxR2gEBcBlizZyLBhC9i7N5WaNcvyxhv96dy5gddliUgxkFuIV/ePTF/Hf8P7OI0EE/GLjY1m375UevZsyPTpfalWrYzXJYlIMZFbiEcDZTkxvI9TiEuxtmfPESpX9t2opUuXc/jkk5u57LI6uvZbRApVbiGe5Jx7vNAqEYkAzjmmTfuasWOXsnDhIK64wtdt3r59XY8rE5HiKLdRN2pSiATYvz+VwYPn84c/LCIlJY0lSzZ6XZKIFHO5tcSvLLQqRMLcl19uY/Dg+fzyyz7Klo3lH//oxbBhTb0uS0SKuVOGuHNuT2EWIhKOMjMdTz+9gkceWUZ6eiYtW9ZkzpwBNGxYxevSRERy7U4XKfb27DnCs89+QXp6Jnff3ZaVK0cowEUkbOT7KWYixUnVqqWZNas/aWkZ9OzZ0OtyREROoBAXCZCWlsHDD/+HcuVK8thjHQHfJWQiIuFIIS7i99NPexg8eD6rVu0gNjaakSNbUKtWea/LEhE5JZ0TFwHefPNbWrR4mVWrdlCvXgWWLbtJAS4iYU8tcSnWUlLSuPPO95k+fQ0A1157IVOn9qFixTiPKxMRyZtCXIq1u+/+gOnT1xAXF8OkSd354x9b6tapIhIxFOJSrP31r1fw0097ef75Hlx0UXWvyxERyRedE5diZffuw/zlL8vIyMgE4Oyzy/HRRzcpwEUkIqklLsXGxx9vZujQBWzffpBSpUrw4IPtvS5JROSMqCUuRV56eiZ/+csyOneewfbtB7n00joMHnyR12WJiJwxtcSlSNu6dT9Dhizgs8+2YAYPP3w548Z1IiZG319FJPIpxKXI+u67ZC67bBp796ZSs2ZZ3nijP507N/C6LBGRAqMQlyLr/POr0KxZDUqXLsH06X2pVq2M1yWJiBQohbgUKd99l0zFinHUrFmO6Ogo3n13EOXKxerabxEpknRiUIoE5xyvvLKaSy6Zwg03vE1mpgOgfPmSCnARKbLUEpeIt39/Krfc8h5z564HoFat8hw9mk6pUiU8rkxEJLQU4hLRvvhiG4MHz2fz5n2ULRvLP/7Ri2HDmnpdlohIoVCIS8R6+ukV/PnPH5GenknLljWZM2cADRtW8bosEZFCo3PiErEOHTpGenom99zTlpUrRyjARaTYUUtcIsq+falZjwl95JEOXHllAy6/vJ7HVYmIeEMtcYkIaWkZ3Hffv2jc+CV+/z0FgJiYKAW4iBRrCnEJe5s27eGyy6bxzDOfk5x8iI8//tXrkkREwoK60yWszZr1DaNHLyYlJY169Sowe/YA2rWr43VZIiJhQSEuYSklJY077ljC66+vBeC66y5kypQ+WefDRUREIS5havXqJGbMWEupUjFMmtSdP/yhpe68JiKSjUJcwlKHDvV46aWedOxYnwsvrOZ1OSIiYUkD2yQs7Np1mL595/Dhhz9nzbv11lYKcBGRXKglLp5bvnwzQ4cuYMeOg2zatIdvv72VqCh1nYuI5EUtcfFMenomjz22jM6dX2fHjoNcdlkdliwZogAXEQmSWuLiiS1b9jNkyHxWrNiKGTz6aAcee6wjMTH6XikiEiyFuBS6zExH9+5v8N13uzj77HLMmtWfTp3qe12WiEjEUbNHCl1UlDFpUneuvvoC1q4drQAXETlNCnEpFBs2JDN5ckLWdNeu5/Luu4OoWrW0h1WJiEQ2dadLSDnneOWV1YwZ8wGpqek0aVJNDy0RESkgCnEJmX37Uhk1ahFvvbUBgJtuakaLFjU9rkpEpOhQiEtIfP75VoYMWcDmzfsoWzaWyZN7MXRoU6/LEhEpUhTiUuD++c/1DBkyn4wMR3z82cyePYDzzqvsdVkiIkVOSAe2mVl3M/vBzDaZ2YM5LL/HzDaY2Tdm9h8z08nSIuDyy+tStWpp7r23HStWjFCAi4iESMha4mYWDbwEdAW2AavMbKFzbkPAal8D8c65w2Z2K/AUMDBUNUnofPbZFtq1q010dBQ1a5bju+9up1KlUl6XJSJSpIWyJd4a2OSc+9k5lwbMAfoGruCcW+acO+yf/AKoHcJ6JATS0jK4996lXH75a4wf/0nWfAW4iEjohfKceC1ga8D0NqBNLuuPBN4PYT1SwDZt2sOgQfNITEwiOtooVaqE1yWJiBQrYTGwzcyGAfFAx1MsHwWMAqhbt24hVian8sYb33DrrYtJSUmjXr0KzJ49gHbt6nhdlohIsRLK7vTtQOC/6rX9805gZl2Ah4GrnXNHc9qRc26Kcy7eORdfrZqeL+2lI0eOMXz4O9xww9ukpKRx/fVNWLNmtAJcRMQDoWyJrwIamlkDfOE9CBgSuIKZtQBeBro753aGsBYpILGx0WzZsp9SpWJ4/vkejBzZAjM9OlRExAshC3HnXLqZ3QEsBaKBac659Wb2OJDgnFsIPA2UBd7yB8EW59zVoapJTo9zjoMH0yhfviTR0VG88UZ/9u1L5cIL1SsiIuIlc855XUO+xMfHu4SEhLxXDMbxFmSEfQaFadeuw9x887ukpKTx4Yc3EB2tZ+aIiBQmM0t0zsXntCwsBrZJeFq27BeGDXubHTsOUrFiHD/+uJvGjdX6FhEJF2pWyUnS0zN59NGPuPLKGezYcZD27euydu1oBbiISJhRS1xOsGXLfoYMmc+KFVsxg8ce68Cjj3YkJkbf90REwo1CXE4wa9Y3rFixlbPPLsesWf3p1Km+1yWJiMgpKMTlBPfffxmHDx9jzJi2VK1a2utyREQkF+ojLeY2bEjmyitnkJR0EIDo6Cj+9rfOCnARkQigEC+mnHNMmZJIfPwUPvroFx57bJnXJYmISD6pO70Y2rcvlVGjFvHWW76nwg4f3pznnuvucVUiIpJfCvFi5vPPtzJ48Hx+/XU/5crFMnlyb4YMudjrskRE5DQoxIuR7dsP0KnT66SlZRAffzZz5gzg3HMre12WiIicJoV4MVKrVnkeeqg9hw6l8cQTVxIbG+11SSIicgYU4kXc++9vJDY2miuvPAeAv/ylo546JiJSRGh0ehGVlpbBvfcupWfPNxkyZAHJyYcAFOAiIkWIWuJF0MaNuxk8eD6JiUnExERxzz1tqVJF132LiBQ1CvEi5o03vuHWWxeTkpJG/foVmT17AG3b1va6LBERCQGFeBHypz/9iwkTPgfg+uub8PLLvalYMc7jqkREJFR0TrwI6dGjIWXLxjJ1ah/mzBmgABcRKeLUEo9gzjk+/3wbl15aB4DOnRuwefMYnf8WESkm1BKPUMnJh+jTZzbt20/jP//5OWu+AlxEpPhQSzwCLVv2C0OHLiApKYVKleJITU33uiQREfGAQjyCpKdnMm7ccv7nfz7FOWjfvi6zZvWnbt0KXpcmIiIeUIhHiG3bDjBw4DxWrtxKVJTx6KOX8+ijHYmJ0RkREZHiSiEeIUqUiOKnn/ZQq1Y5Zs3qT8eO9b0uSUREPKYQD2NHjhyjRIloYmKiOOussixaNJgGDSpRtaoGr4mIiEanh63163fSuvUrPP74x1nzWrWqpQAXEZEsCvEw45xjypREWrWayrp1O5k3b4NGn4uISI4U4mFk375Urr9+Hrfc8h5HjqQzfHhzvvrqj8TF6ayHiIicTOkQJlau3MqQIfP59df9lCsXy+TJvRky5GKvyxIRkTCmEA8T48d/wq+/7ic+/mzmzBnAuedW9rokEREJcwrxMDFtWl/+7/9W8cgjHYiNjfa6HBERiQA6J+6RJUs2ct11b5GRkQlAjRplefzxKxTgIiISNIV4ITt6NJ177llKr15vMm/eBt544xuvSxIRkQil7vRCtHHjbgYNms/q1UnExEQxfvwV3HBDM6/LEhGRCKUQLyQzZ67lttuWkJKSRv36FZk9ewBt29b2uiwREYlgCvFC8O6733Pjje8AMHBgE15+uTcVKsR5XJWIiEQ6hXgh6N37fHr1aki/fo0YMaIFZuZ1SSIiUgQoxEPAOcdLL62if//GnH12OaKjo1i0aLDCW0RECpRGpxew5ORD9O49mzvvfJ8bbngb5xyAAlxERAqcWuIF6KOPfmHYsAUkJaVQqVIcd97ZWuEtIiIhoxAvAOnpmfzlL8v43//9DOfg8svrMmtWf+rUqeB1aSIiUoQpxM9QenomnTu/zqefbiEqynjssQ488kgHYmJ0pkJEREJLIX6GYmKiuPLKBvz8815mzepPx471vS5JRESKCTs+8CpSxMfHu4SEhILZ2fHz1fn8DA4fPsbGjbtp1qwGABkZmezff5TKlUsVTF0iIiJ+ZpbonIvPaZn6fPNp3bqdtG49lW7d3uC331IAiI6OUoCLiEihU4gHyTnHyy8n0KrVVNavT6ZSpTj27j3idVkiIlKM6Zx4EPbuPcIf/7iI+fO/A2DEiOY8/3wPypSJ9bgyEREpzhTiefjii20MHDiPLVv2U65cLC+/3JvBgy/2uiwROU3Hjh1j27ZtpKamel2KyAni4uKoXbs2JUqUCHobhXgeUlPT2bp1P61anc3s2QM499zKXpckImdg27ZtlCtXjvr16+tmTBI2nHPs3r2bbdu20aBBg6C3U4jn4NChtKyu8k6d6vPBB8Po1Kk+sbHRHlcmImcqNTVVAS5hx8yoUqUKycnJ+dpOA9uyWbz4R84553n+/e+fsuZ163auAlykCFGASzg6nb9Lhbjf0aPp3H33B/TuPZudOw8xY8Y3XpckIiKSq5CGuJl1N7MfzGyTmT2Yw/KSZjbXv/xLM6sfynpO5ccfd3PppdOYOPFLYmKiePLJLrz++jVelCIixcCIESOoXr06F1100SnXmT59OtWqVaN58+Y0atSI55577oTlU6ZMoVGjRjRq1IjWrVvz2WefZS07duwYDz74IA0bNqRly5a0a9eO999/P2Tv53SNHTuWTz75xOsyTikxMZGLL76Y8847j7vuuoucbo62d+9e+vXrR9OmTWndujXr1q0DYOvWrVxxxRVceOGFNGnShEmTJmVtc9999/HRRx8VTJHOuZC8gGjgJ+AcIBZYC1yYbZ3bgMn+nwcBc/Pa7yWXXOIKjO9eba5MmSccjHMNGkx0X3yxteD2LyJhZ8OGDV6X4D7++GOXmJjomjRpcsp1XnvtNXf77bc755zbtWuXq1KlituyZYtzzrlFixa5li1buuTkZOecc4mJia5OnTouKSnJOefcAw884G688UaXmprqnHPut99+c3Pnzi3Q95Cenn5G2+/atcu1adMmX9scO3bsjI6ZX61atXKff/65y8zMdN27d3dLliw5aZ377rvPjRs3zjnn3Hfffec6d+7snHNux44dLjEx0Tnn3IEDB1zDhg3d+vXrnXPObd682XXt2jXHY+b09wkkuFNkYihb4q2BTc65n51zacAcoG+2dfoCr/t/ngdcaR6crDp06BiDBl3E11/fQps2tQv78CLiFbPQvPLQoUMHKlcO/kqXKlWqcN5555GUlATAk08+ydNPP03VqlUBaNmyJTfddBMvvfQShw8fZurUqbzwwguULFkSgLPOOovrr7/+pP2uWrWKSy+9lGbNmtG6dWsOHjzI9OnTueOOO7LW6d27N8uXLwegbNmy3HvvvTRr1oz//d//5brrrstab/ny5fTu3RuAf/3rX7Rr146WLVty3XXXkZKSctKx58+fT/fu3bOmH3/8cVq1asVFF13EqFGjslq9nTp1YuzYscTHxzNp0iQSExPp2LEjl1xyCVdddVXWZzJ16lRatWpFs2bNGDBgAIcPHw76881JUlISBw4coG3btpgZN954I++8885J623YsIHOnTsD0KhRIzZv3szvv/9OzZo1admyJQDlypWjcePGbN++HYB69eqxe/dufvvttzOqEULbnV4L2Bowvc0/L8d1nHPpwH6gSvYdmdkoM0sws4T8jtwLxquvXs2bb/anQoW4At+3iEiwJk+ezOTJk0+av2XLFlJTU2natCkA69ev55JLLjlhnfj4eNavX8+mTZuoW7cu5cuXz/VYaWlpDBw4kEmTJrF27Vo+/PBDSpXK/fbRhw4dok2bNqxdu5YHH3yQL7/8kkOHDgEwd+5cBg0axK5duxg/fjwffvghq1evJj4+nmefffakfa1YseKE93DHHXewatUq1q1bx5EjR3jvvfdOqDUhIYG77rqLO++8k3nz5pGYmMiIESN4+OGHAejfvz+rVq1i7dq1NG7cmFdfffWkYy5btozmzZuf9Lr00ktPWnf79u3Urv3fRl3t2rWzQjhQs2bNWLBgAQBfffUVv/76K9u2bTthnc2bN/P111/Tpk2brHktW7ZkxYoVOX/Q+RARl5g556YAU8D3AJQC3DEAIwpshyISUcLsAVCjR48+YXru3Ll88sknfP/997z44ovExRVcQ+OHH36gZs2atGrVCiDP0AeIjo5mwIABAMTExNC9e3cWLVrEtddey+LFi3nqqaf4+OOP2bBhA5dddhngC+B27dqdtK+kpCSqVauWNb1s2TKeeuopDh8+zJ49e2jSpAl9+vQBYODAgVk1r1u3jq5duwKQkZFBzZo1AVi3bh2PPPII+/btIyUlhauuuuqkY15xxRWsWbMm6M8oGA8++CBjxoyhefPmXHzxxbRo0YLo6P9ezZSSksKAAQOYOHHiCZ9x9erV2bFjxxkfP5Qhvh2oEzBd2z8vp3W2mVkMUAHYHcKaREQixsCBA3nxxRdJSEigW7duXH311dSoUYMLL7yQxMTErG5c8A3CatKkCeeddx5btmzhwIEDQQVzdjExMWRmZmZNB97ZLi4u7oSAGjRoEC+++CKVK1cmPj6ecuXK4Zyja9euzJ49O9fjlCpVKmvfqamp3HbbbSQkJFCnTh3GjRt3wnHLlCkD+MZwNWnShM8///yk/Q0fPpx33nmHZs2aMX369KxTAIGWLVvG3XfffdL80qVLs3LlyhPm1apV64QW9bZt26hVK3tnsu/Lz2uvvZZVX4MGDTjnnHMA3wDDAQMGMHToUPr373/CdqmpqXn2fAQjlN3pq4CGZtbAzGLxDVxbmG2dhcBN/p+vBT5yLsy+GouIeCw+Pp4bbrgha4Tz/fffzwMPPMDu3b42z5o1a5g+fTq33XYbpUuXZuTIkYwZM4a0tDQAkpOTeeutt07Y5wUXXEBSUhKrVq0C4ODBg6Snp1O/fn3WrFlDZmYmW7du5auvvjplXR07dmT16tVMnTqVQYMGAdC2bVtWrFjBpk2bAF8X/I8//njSto0bN85a53hgV61alZSUFObNm5fj8S644AKSk5OzQvzYsWOsX78+q/6aNWty7NgxZs2aleP2x1vi2V/ZAxygZs2alC9fni+++ALnHDNmzKBv3+zDumDfvn1Zn/Mrr7xChw4dKF++PM45Ro4cSePGjbnnnntO2u7HH3/M9eqEYIUsxP3nuO8AlgLfAf90zq03s8fN7Gr/aq8CVcxsE3APcNJlaCIiRc3gwYNp1+7/27v7IKvqOo7j70/Iuj4lTVJj4gOpiDsrkG4i4uOgokCYo6mUYyYyjSVOSQ5OOdW4aJnhyjeiJQAACgtJREFUjM7kmJKugSnJpEMK4XM4KCoBIoo4pEZkpZEZPpCi3/44v12vy2X3rne99569n9fMHe7D75zz3S9393t/v3Pu7zeKtWvXMmjQoI7zt9s6Jw4wffp0br75ZjZt2sTEiRM599xzOfzwwxk6dChTpkxhzpw5HUPLM2bMYODAgTQ1NdHc3MyECRO26pU3NDQwd+5cpk6dyvDhwzn++OPZvHkzo0ePZvDgwTQ1NXHhhRd2XJxVTL9+/ZgwYQILFy7suKht4MCBtLW1MWnSJIYNG8aoUaN47rnnttp2/PjxHb3lAQMGMGXKFJqbmxk7dmzHEH9nDQ0NzJs3j+nTpzN8+HBGjBjRUYBbW1sZOXIko0ePZujQoV1kv3TXXXcd5513Hvvttx/77rsvJ510EvDh/6c1a9bQ3NzMAQccwMKFCzs+aC1ZsoTZs2fz4IMPdpx7X7BgAZB9+Fi3bh0tLUWXCO8R5a3j29LSEsuWLat2GGaWU2vWrOHAAw+sdhgGHHHEEdx9990MGDCg2qFU1J133sny5ctpbW3d6rVi709Jf4qIohXfM7aZmVlVzJw5k/Xr11c7jIrbsmUL06ZN65V95eLqdDMz63sKv3JVTwq/X18u98TNrO7k7TSi1YeP8r50ETezutLY2MjGjRtdyK2mRFpPvKdzAXg43czqyqBBg9iwYUOP1202+7g1NjZ+aJa4UriIm1ld6d+/P4MHD652GGa9wsPpZmZmOeUibmZmllMu4mZmZjmVuxnbJL0K/KUXd7kb8K9e3F+9ch7L5xyWzzksn3NYvt7O4d4RMbDYC7kr4r1N0rJtTWdnpXMey+ccls85LJ9zWL5K5tDD6WZmZjnlIm5mZpZTLuJwQ7UD6COcx/I5h+VzDsvnHJavYjms+3PiZmZmeeWeuJmZWU7VTRGXdKKktZLWSbqkyOvbS5qbXn9c0j6Vj7K2lZDDiyQ9K2mVpAck7V2NOGtZdzksaHeqpJDkq4SLKCWPkk5P78dnJP2m0jHWuhJ+n/eS9JCkFel3elw14qxVkm6S9Iqk1dt4XZKuTfldJengjyWQiOjzN6Af8Gfg80AD8BTQ1KnNt4Dr0/0zgbnVjruWbiXm8Fhgx3T/fOew5zlM7XYBFgNLgZZqx11rtxLfi/sDK4BPpcefqXbctXQrMYc3AOen+03AS9WOu5ZuwFHAwcDqbbw+DlgICDgMePzjiKNeeuKHAusi4oWIeAe4HTi5U5uTgVvS/XnAGEmqYIy1rtscRsRDEfFWergU6NlyPH1fKe9DgFbgSmBzJYPLkVLyOAX4RUS8BhARr1Q4xlpXSg4D+GS6vyvwcgXjq3kRsRj4dxdNTgZ+HZmlwABJu/d2HPVSxPcA/lrweEN6rmibiNgCvA58uiLR5UMpOSw0mexTqH2g2xymIbc9I+KeSgaWM6W8F4cAQyQtkbRU0okViy4fSsnhj4GzJG0AFgBTKxNan9HTv5kfiZcitV4n6SygBTi62rHkiaRPAFcD51Q5lL5gO7Ih9WPIRoQWSzooIv5T1ajyZRLQFhEzJY0CZktqjoj3qx2YfaBeeuJ/A/YseDwoPVe0jaTtyIaPNlYkunwoJYdIOg74ATAxIv5Xodjyorsc7gI0Aw9LeonsPNp8X9y2lVLeixuA+RHxbkS8CDxPVtQtU0oOJwO/BYiIx4BGsjnBrTQl/c0sV70U8SeB/SUNltRAduHa/E5t5gNfT/dPAx6MdHWCASXkUNIXgF+SFXCfg9xalzmMiNcjYreI2Cci9iG7rmBiRCyrTrg1q5Tf57vIeuFI2o1seP2FSgZZ40rJ4XpgDICkA8mK+KsVjTLf5gNnp6vUDwNej4i/9/ZB6mI4PSK2SLoAWER2VeZNEfGMpMuAZRExH/gV2XDROrKLFc6sXsS1p8QcXgXsDNyRrglcHxETqxZ0jSkxh9aNEvO4CDhB0rPAe8DFEeGRtaTEHE4DbpT0XbKL3M5xx+YDkm4j+6C4W7pu4EdAf4CIuJ7sOoJxwDrgLeAbH0sc/j8xMzPLp3oZTjczM+tzXMTNzMxyykXczMwsp1zEzczMcspF3MzMLKdcxM2qQNJ7klYW3Pbpou0bvXC8NkkvpmMtTzNw9XQfsyQ1pfvf7/Tao+XGmPbTnpfVkn4vaUA37Ud4dS2rZ/6KmVkVSHojInbu7bZd7KMNuDsi5kk6Afh5RAwrY39lx9TdfiXdAjwfEZd30f4cspXeLujtWMzywD1xsxogaee0BvtySU9L2mp1M0m7S1pc0FM9Mj1/gqTH0rZ3SOquuC4G9kvbXpT2tVrSd9JzO0m6R9JT6fkz0vMPS2qR9FNghxTHrem1N9K/t0saXxBzm6TTJPWTdJWkJ9Payt8sIS2PkRaMkHRo+hlXSHpU0gFpprHLgDNSLGek2G+S9ERqW2yVOLM+oy5mbDOrQTtIWpnuvwh8BTglIv6bpgldKml+pxmyvgosiojLJfUDdkxtLwWOi4g3JU0HLiIrbtvyJeBpSYeQzSI1kmzN48cl/ZFsjemXI2I8gKRdCzeOiEskXRARI4rsey5wOnBPKrJjyNaWn0w27eQXJW0PLJF0b5rXfCvp5xtDNpMiwHPAkWmmseOAKyLiVEk/pKAnLukKsimTz01D8U9Iuj8i3uwiH2a55SJuVh1vFxZBSf2BKyQdBbxP1gP9LPCPgm2eBG5Kbe+KiJWSjgaayIoiQANZD7aYqyRdSjb/9WSyInlne4GT9DvgSOAPwExJV5INwT/Sg59rIXBNKtQnAosj4u00hD9M0mmp3a5kC5J0LuLtH272ANYA9xW0v0XS/mRTgPbfxvFPACZK+l563AjslfZl1ue4iJvVhq8BA4FDIuJdZauYNRY2iIjFqciPB9okXQ28BtwXEZNKOMbFETGv/YGkMcUaRcTzytY1HwfMkPRARHTVsy/cdrOkh4GxwBnA7e2HA6ZGxKJudvF2RIyQtCPZvN7fBq4FWoGHIuKUdBHgw9vYXsCpEbG2lHjN8s7nxM1qw67AK6mAHwvs3bmBpL2Bf0bEjcAs4GCylc5GS2o/x72TpCElHvMR4MuSdpS0E3AK8IikzwFvRcQcskVtDi6y7btpRKCYuWTD9O29esgK8vnt20gako5ZVES8BVwITNMHSwO3L+N4TkHTTWRLuLZbBExVGpZQtrKeWZ/lIm5WG24FWiQ9DZxNdg64s2OApyStIOvlXhMRr5IVtdskrSIbSh9aygEjYjnQBjwBPA7MiogVwEFk55JXkq3MNKPI5jcAq9ovbOvkXuBo4P6IeCc9Nwt4FlguaTXZkrVdjgSmWFYBk4CfAT9JP3vhdg8BTe0XtpH12Pun2J5Jj836LH/FzMzMLKfcEzczM8spF3EzM7OcchE3MzPLKRdxMzOznHIRNzMzyykXcTMzs5xyETczM8spF3EzM7Oc+j/rP6C/uzp5+gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMuEI4vMNYGvaHju+8qgjO2",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}