{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled72.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Olympia_Hertel_ensemble_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJiUlScYrIgg"
      },
      "source": [
        "#**Olympia_Hertel_estimation_RepVGG-A2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import modules"
      ],
      "metadata": {
        "id": "EZvxdGnfLm8o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1FDbAxrAsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d10e28-9867-4490-cfb1-f90c281df28f"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install --q torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import statistics\n",
        "import math\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "import shutil\n",
        "import codecs\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "!pip install --q pingouin\n",
        "import pingouin as pg\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "# #google driveをcolabolatoryにマウント\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 15 10:19:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 526.67       Driver Version: 526.67       CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Quadro RTX 5000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   45C    P0    33W /  N/A |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Random Seed:  1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XD7y5oqsMwg"
      },
      "source": [
        "## **Set Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Er_Gm6sRDv"
      },
      "source": [
        "path = r'C:\\Users\\ykita\\OneDrive\\デスクトップ\\Hertel_dataset'\n",
        "os.chdir(path)\n",
        "\n",
        "# grav or cont, age, and sex\n",
        "#NUM_CLASSES = 3\n",
        "\n",
        "# contains train, val\n",
        "#DATASET_PATH = r\"./dataset_500px\"\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "DATASET_PATH_0 = f\"./dataset_250px_uni_{AREA[0]}\"\n",
        "DATASET_PATH_1 = f\"./dataset_250px_uni_{AREA[1]}\"\n",
        "DATASET_PATH_2 = f\"./dataset_250px_uni_{AREA[2]}\"\n",
        "PARENT_PATHS = [DATASET_PATH_0, DATASET_PATH_1, DATASET_PATH_2]\n",
        "#TRAIN_FOLDER_NAME = \"train\"\n",
        "#VAL_FOLDER_NAME = \"val\"\n",
        "#EFFICIENT_NET_NAME = \"RepVGG-A2-train\"\n",
        "MODEL_PATH = \"./RepVGG-A2-train.pth\"\n",
        "CSV_PATH = \"./Hertel_unilateral.csv\"\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "#SEX_DICT_PATH = \"gender_json\"\n",
        "#AGE_DICT_PATH = \"age_json\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "#CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# transforms param　　左右分けているのでflipはしない\n",
        "PX = 224\n",
        "TRAIN_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "ROTATION_DEGREES = 3\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "\n",
        "VAL_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "# train_data_transforms = transforms.Compose([\n",
        "#                 transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "#                 #transforms.RandomRotation(ROTATION_DEGREES),\n",
        "#                 transforms.RandomHorizontalFlip(),\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\n",
        "# val_data_transforms = transforms.Compose([\n",
        "#                 transforms.Resize(PX),\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])]) \n",
        "\n",
        "# https://buildersbox.corp-sansan.com/entry/2020/11/05/110000\n",
        "train_data_transforms = nn.Sequential(\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                #transforms.RandomRotation(ROTATION_DEGREES),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])\n",
        "                ).to(device)\n",
        "val_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])\n",
        "                ).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-Foldに分割**"
      ],
      "metadata": {
        "id": "aLBpMuFwhz1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    #id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    id_list = [os.path.basename(name).split(\".\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "def extract_patient_number(path_list):\n",
        "    patient_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(patient_list)\n",
        "\n",
        "\n",
        "path_list = make_path_list(PARENT_PATHS[1])\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "id = extract_ids(path_list)\n",
        "patient = extract_patient_number(id)\n",
        "\n",
        "print(\"id_num: {}\".format(len(id)))\n",
        "print(\"patient_num: {}\".format(len(patient)))\n",
        "\n",
        "print(len(path_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZXXWIO9k9Cq",
        "outputId": "76f378f1-6251-49ad-e78a-ae7c0003f2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_num: 1959\n",
            "patient_num: 1959\n",
            "1959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_list_0 = extract_ids(make_path_list(DATASET_PATH_0))\n",
        "id_list_1 = extract_ids(make_path_list(DATASET_PATH_1))\n",
        "id_list_2 = extract_ids(make_path_list(DATASET_PATH_2))\n",
        "common_id = set(id_list_0) & set(id_list_1) & set(id_list_2)\n",
        "common_patient = list([id.split(\"_\")[0] for id in common_id])\n",
        "\n",
        "path_list_0 = [f\"{DATASET_PATH_0}/{id}.JPG\" for id in common_id]    \n",
        "path_list_1 = [f\"{DATASET_PATH_1}/{id}.JPG\" for id in common_id]    \n",
        "path_list_2 = [f\"{DATASET_PATH_2}/{id}.JPG\" for id in common_id]    \n",
        "path_list_list = [path_list_0, path_list_1, path_list_2]\n",
        "\n",
        "print(f\"common_ids: {len(common_id)}\")\n",
        "print(f\"common_patients: {len(common_patient)}\")\n",
        "print(f\"{path_list_0[20]}\")\n",
        "print(f\"{path_list_1[20]}\")\n",
        "print(f\"{path_list_2[20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9H3EZ2B3Dl",
        "outputId": "a1cd740f-f20d-40e5-f864-dfe1d06739f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_ids: 1959\n",
            "common_patients: 1959\n",
            "./dataset_250px_uni_half/802_L.JPG\n",
            "./dataset_250px_uni_periocular/802_L.JPG\n",
            "./dataset_250px_uni_eye/802_L.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Group Shuffle Split ＋　Group K-foldを用いてデータセット分け(idxを抜き出し)\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "#fold数だけ空のリストを作成\n",
        "num_folds = 5\n",
        "train_set, val_set =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "train_idx, val_idx =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "test_idx = []\n",
        "test_set, remain_set = [], []\n",
        "\n",
        "#remain:test = 1:9で分割\n",
        "X = np.ones(len(common_id))\n",
        "y = np.ones(len(common_id))\n",
        "groups = common_patient\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=0.9, random_state=random_seed)\n",
        "for remain_idxs, test_idxs in gss.split(X, y, groups):\n",
        "    pass\n",
        "\n",
        "test_idx = [idx for idx in test_idxs]\n",
        "# test_set = [path_list[idxs] for idxs in test_idxs]\n",
        "\n",
        "remain_patients = [patient[idxs] for idxs in remain_idxs]\n",
        "# remain_set = [path_list[idxs] for idxs in remain_idxs]\n",
        "\n",
        "X = np.ones(len(remain_idxs))\n",
        "y = np.ones(len(remain_idxs))\n",
        "gkf = GroupKFold(n_splits=num_folds)\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(X, y, groups=remain_patients):\n",
        "    for idx in train_idxs:\n",
        "        # train_set[i].append(remain_set[idx])\n",
        "        train_idx[i].append(idx)\n",
        "    for idx in val_idxs:\n",
        "        # val_set[i].append(remain_set[idx])\n",
        "        val_idx[i].append(idx)\n",
        "    i+=1\n",
        "\n",
        "print(\"train_dataset: {}\".format(len(train_idx[0])))\n",
        "print(\"val_dataset: {}\".format(len(val_idx[0])))\n",
        "print(\"test_dataset: {}\".format(len(test_idx)))\n",
        "# print(\"\")\n",
        "# print(\"extracted_id (example): {}\".format(extract_ids(test_set)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzjZhrg3lrdU",
        "outputId": "abac6c8a-1f94-46d1-f6fa-a8a1c5392369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset: 1410\n",
            "val_dataset: 353\n",
            "test_dataset: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GURyJLkrtsx"
      },
      "source": [
        "## **Create Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Create_Datasets(Dataset):\n",
        "     \n",
        "    def __init__(self, image_path_list_list, idxs, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.path_list_list = path_list_list\n",
        "        self.idxs = idxs\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        df = self.df\n",
        "\n",
        "        k=0\n",
        "        for idx in idxs:\n",
        "            path_0, path_1, path_2 = path_list_list[0][idx], path_list_list[1][idx], path_list_list[2][idx]\n",
        "            base_name = os.path.splitext(os.path.basename(path_0))[0] #フォルダより画像番号を抜き出す\n",
        "            hertel = df[df['number']==str(base_name)].iloc[0,1] #CSV上で一致した番号の画像についてHertel値を抜き出す\n",
        "            self.item_paths.append([path_0, path_1, path_2, hertel]) #[path, hertel]の組み合わせをリストに追加する\n",
        "            item_paths = self.item_paths\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "     \n",
        "    def __getitem__(self, index):\n",
        "        # [tensor[path0, path1, path2], hertel_value]\n",
        "        def tensor_img(image_path):\n",
        "            pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "            tensor_image = transforms.functional.to_tensor(pilr_image)\n",
        "            tensor_image = self.transform(tensor_image)\n",
        "            # tensor_image = self.transform(pilr_image).float()\n",
        "            # tensor_image = self.transform(read_image(path=image_path))\n",
        "            return tensor_image\n",
        "        tensor_image_0 = tensor_img(self.item_paths[index][0]) \n",
        "        tensor_image_1 = tensor_img(self.item_paths[index][1])      \n",
        "        tensor_image_2 = tensor_img(self.item_paths[index][2])      \n",
        "        tensor_image = torch.stack([tensor_image_0, tensor_image_1, tensor_image_2])\n",
        "        #tensor_image = tensor_image_0\n",
        "        hertel = self.item_paths[index][3]\n",
        "        target= torch.tensor([hertel]).float()\n",
        "        return  tensor_image, target\n",
        "\n",
        "train_dataset = Create_Datasets(path_list_list, train_idx[0], CSV_PATH, train_data_transforms)\n",
        "val_dataset = Create_Datasets(path_list_list, val_idx[0], CSV_PATH, val_data_transforms)\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "print('train_dataset_size: ' +str(len(train_dataset)))\n",
        "print('val_dataset_size: ' +str(len(val_dataset)))\n",
        "print('test_dataset_size: ' +str(len(test_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXqKg2jfswY3",
        "outputId": "27a83f29-d66a-4dc9-f6c5-241e2e35b2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_size: 1410\n",
            "val_dataset_size: 353\n",
            "test_dataset_size: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMch8ogOX1X6"
      },
      "source": [
        "## **Test with early-stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IIK64KHX1nA"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#1つずつ解析するバージョン\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device, area_num, alpha=0):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # define scaler for fastening\n",
        "        scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,area_num])  #16,3,3,224,224 --> 16,3,224,224 (バッチサイズの次の次元でスライスすることによりtensorを取り出す)\n",
        "            # calculate the loss\n",
        "            with torch.cuda.amp.autocast(): \n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "                ################\n",
        "                ##l2_normalization##\n",
        "                ################\n",
        "                l2 = torch.tensor(0., requires_grad=True)\n",
        "                for w in model.parameters():\n",
        "                    l2 = l2 + torch.norm(w)**2\n",
        "                loss = loss + alpha*l2\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer) \n",
        "            scaler.update() \n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,area_num])\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "\n",
        "        \n",
        "        #Scheduler step for SGD\n",
        "        #scheduler.step() #val_lossが下がらなければ減衰\n",
        "        \n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXAxIikRdQEu"
      },
      "source": [
        "## **define RepVGG-A2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZk-1LhdQTK"
      },
      "source": [
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc = nn.Linear(in_features=1408, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYO37TYHeFwG"
      },
      "source": [
        "## **ConvNetの調整**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6p9djzEeF7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdad065-5e08-4e74-9e60-d6cbeb0260c8"
      },
      "source": [
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "# !pip install ranger_adabelief\n",
        "# from ranger_adabelief import RangerAdaBelief\n",
        "# optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft =  optim.AdaBound(\n",
        "#     model_ft.parameters(),\n",
        "#     lr= 1e-3,\n",
        "#     betas= (0.9, 0.999),\n",
        "#     final_lr = 0.1,\n",
        "#     gamma=1e-3,\n",
        "#     eps= 1e-8,\n",
        "#     weight_decay=5e-4,\n",
        "#     amsbound=False,\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**モデルのトレーニング**"
      ],
      "metadata": {
        "id": "bGofj_nxPfx1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lPDAqyEEx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ed2c10e-e4a2-4784-fbc5-1639854d4b94"
      },
      "source": [
        "\"\"\"\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "データセットからそれぞれの画像を読みこんでトレーニング\n",
        "\"\"\"\n",
        "train_dataset = Create_Datasets(path_list_list, train_idx[0], CSV_PATH, train_data_transforms)\n",
        "val_dataset = Create_Datasets(path_list_list, val_idx[0], CSV_PATH, val_data_transforms)\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "print('train_dataset_size: ' +str(len(train_dataset)))\n",
        "print('val_dataset_size: ' +str(len(val_dataset)))\n",
        "print('test_dataset_size: ' +str(len(test_dataset)))\n",
        "\n",
        "\n",
        "for area_num in [0]:\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "    model_ft = model_ft.to(device)\n",
        "    loss_func = nn.MSELoss()\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device, area_num=area_num)\n",
        "\n",
        "    #save the model\n",
        "    PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_test_RepVGGA2.pth\"\n",
        "    torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_size: 1410\n",
            "val_dataset_size: 353\n",
            "test_dataset_size: 196\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Epoch: [  1/100] \n",
            "train_loss: 23.68999 \n",
            "valid_loss: 12.41374 \n",
            "Validation loss decreased (inf --> 12.413740).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 4.13531 \n",
            "valid_loss: 3.94686 \n",
            "Validation loss decreased (12.413740 --> 3.946857).  Saving model ...\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 3.54612 \n",
            "valid_loss: 6.82275 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 3.25421 \n",
            "valid_loss: 9.64995 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 3.01224 \n",
            "valid_loss: 4.63676 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [  6/100] \n",
            "train_loss: 2.78526 \n",
            "valid_loss: 6.79342 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [  7/100] \n",
            "train_loss: 2.55843 \n",
            "valid_loss: 3.40311 \n",
            "Validation loss decreased (3.946857 --> 3.403112).  Saving model ...\n",
            "\n",
            "Epoch: [  8/100] \n",
            "train_loss: 2.53047 \n",
            "valid_loss: 3.16447 \n",
            "Validation loss decreased (3.403112 --> 3.164472).  Saving model ...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [174]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     26\u001b[0m optimizer_ft \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model_ft\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.0002\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m model, train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marea_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#save the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models_Hertel_estimation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAREA[area_num]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test_RepVGGA2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, area_num, alpha)\u001b[0m\n\u001b[0;32m    116\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# prep model for evaluation\u001b[39;00m\n\u001b[0;32m    118\u001b[0m running_corrects, val_acc\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_tensor, target \u001b[38;5;129;01min\u001b[39;00m val_loader:  \n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#target = target.squeeze(1)         \u001b[39;00m\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(target), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    124\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36mCreate_Datasets.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# tensor_image = self.transform(pilr_image).float()\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# tensor_image = self.transform(read_image(path=image_path))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor_image\n\u001b[1;32m---> 32\u001b[0m tensor_image_0 \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     33\u001b[0m tensor_image_1 \u001b[38;5;241m=\u001b[39m tensor_img(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_paths[index][\u001b[38;5;241m1\u001b[39m])      \n\u001b[0;32m     34\u001b[0m tensor_image_2 \u001b[38;5;241m=\u001b[39m tensor_img(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_paths[index][\u001b[38;5;241m2\u001b[39m])      \n",
            "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36mCreate_Datasets.__getitem__.<locals>.tensor_img\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_img\u001b[39m(image_path):\n\u001b[1;32m---> 26\u001b[0m     pilr_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     tensor_image \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mto_tensor(pilr_image)\n\u001b[0;32m     28\u001b[0m     tensor_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(tensor_image)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\Image.py:889\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\ImageFile.py:235\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\JpegImagePlugin.py:402\u001b[0m, in \u001b[0;36mJpegImageFile.load_read\u001b[1;34m(self, read_bytes)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, read_bytes):\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    internal: read more image data\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    so libjpeg can finish decoding\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ended\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Premature EOF.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;66;03m# Pretend file is finished adding EOI marker\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_test_RepVGGA2.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "hp5LBdAGNJGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#backup models\n",
        "for area_num in [0,1,2]:\n",
        "    orig_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    dst_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2_backup.pth\"\n",
        "    shutil.copy(orig_path, dst_path)"
      ],
      "metadata": {
        "id": "NXLBk6vDZqqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEkl9xMiIno_"
      },
      "source": [
        "#Draw learning curve\n",
        "\"\"\"\n",
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss', color=\"#377eb8\")\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss', color=\"#ff7f00\")\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 10.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "BAdFoY4h22gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "#Training\n",
        "\n",
        "for fold in [0,1,2,3,4]:\n",
        "    # Define dataset and dataloader\n",
        "    train_dataset = Create_Datasets(path_list_list, train_idx[fold], CSV_PATH, train_data_transforms)\n",
        "    val_dataset = Create_Datasets(path_list_list, val_idx[fold], CSV_PATH, val_data_transforms)\n",
        "    test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    #train models\n",
        "    AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "    for area_num in [0,1,2]:\n",
        "        print(f\"area: {AREA[area_num], fold: {fold}}\")\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "        model_ft = mod_RepVGG()\n",
        "        model_ft = model_ft.to(device)\n",
        "        loss_func = nn.MSELoss()\n",
        "        optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "        model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device, area_num=area_num)\n",
        "\n",
        "        #save the model\n",
        "        PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "        torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "        PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_backup_RepVGGA2.pth\"\n",
        "        torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "metadata": {
        "id": "EDC5obyi26YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference on single model\n",
        "\n",
        "model_path = f\"./models_Hertel_estimation/half_test_RepVGGA2.pth\"\n",
        "\n",
        "#model_path = f\"./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\"\n",
        "#model_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False) \n",
        "model_ft = mod_RepVGG()\n",
        "model_ft = model_ft.to(device)\n",
        "model_ft.load_state_dict(torch.load(model_path))\n",
        "model_ft.eval() # prep model for evaluation\n",
        "print(f\"model_path: {model_path}\")\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs = []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "          outputs.append(output[0].item())      \n",
        "df[f'{area}_fold{str(fold)}'] = outputs\n",
        "print(f\"targets: {targets}\")\n",
        "print(f\"outputs: {[my_round(i) for i in outputs]}\")"
      ],
      "metadata": {
        "id": "S_AUuV--W4NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load backup\n",
        "\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "\n",
        "for area_num in [0,1,2]:\n",
        "  for fold in [0,1,2,3,4]:\n",
        "      backup_PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_backup_RepVGGA2.pth\"\n",
        "      main_PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "      shutil.copy(backup_PATH, main_PATH)"
      ],
      "metadata": {
        "id": "VEbHbassgvrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "# カラムがないindexだけ設定されている\n",
        "# DataFrameを作成\n",
        "df = pd.DataFrame(index=[], columns=[])\n",
        "\n",
        "#Define dataset\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "#Interference\n",
        "with torch.inference_mode():\n",
        "    targets = []\n",
        "    for image_tensor, target in test_loader:  \n",
        "            target = target.view(len(target), 1)         \n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device) \n",
        "            targets.append(target[0].item())\n",
        "    df['targets'] = targets\n",
        "\n",
        "FOLD = [0,1,2,3,4]\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "for area_num in [0,1,2]:\n",
        "    for fold in FOLD:\n",
        "        model_path = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False) \n",
        "        model_ft = mod_RepVGG()\n",
        "        model_ft = model_ft.to(device)\n",
        "        model_ft.load_state_dict(torch.load(model_path))\n",
        "        model_ft.eval() # prep model for evaluation\n",
        "        print(f\"model_path: {model_path}\")\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = []\n",
        "            for image_tensor, target in test_loader:  \n",
        "                  target = target.view(len(target), 1)         \n",
        "                  image_tensor = image_tensor.to(device)\n",
        "                  target = target.to(device)\n",
        "                  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                  output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "                  outputs.append(output[0].item())      \n",
        "        df[f'{AREA[area_num]}_fold{str(fold)}'] = outputs\n",
        "        print(f\"targets: {targets}\")\n",
        "        print(f\"outputs: {my_round(i) for i in outputs}\")\n",
        "\n",
        "df.to_csv( f\"./models_Hertel_estimation/5-fold-crossvalidation/result.csv\", header=True, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_mo_HU99r-",
        "outputId": "9b4ff1c4-2ccf-4f50-a28c-80ad41ab7431"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E0B0>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E890>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E430>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E890>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E430>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E430>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E0B0>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E430>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E0B0>\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: <generator object <genexpr> at 0x0000024CE687E970>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "df"
      ],
      "metadata": {
        "id": "8WbUvsaK3hKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#すべての平均\n",
        "df[\"average_all\"]=df.iloc[:,1:15].mean(axis='columns')\n",
        "\n",
        "#各fold毎の（3部位）平均\n",
        "for fold in [0,1,2,3,4]:\n",
        "    pred_loc = df.loc[:, [f\"half_fold{fold}\",f\"periocular_fold{fold}\" , f\"eye_fold{fold}\"]]\n",
        "    average = pred_loc.mean(axis='columns')\n",
        "    df[f\"average_fold{fold}\"] = average"
      ],
      "metadata": {
        "id": "5tyn53sGG8sV"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#各部位における推定のうち、最も5-foldのばらつき（標準偏差）が少ないものの平均をとる\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "pred_stable = []\n",
        "for row in range(len(df)):\n",
        "    pred_all = [df.iloc[row, 1:6], df.iloc[row, 6:11], df.iloc[row, 11:16]] #[half, periocular, eye]\n",
        "    stdev = [statistics.stdev(pred_all[0]), statistics.stdev(pred_all[1]), statistics.stdev(pred_all[2])]\n",
        "    pred = statistics.mean(pred_all[np.argmax(stdev)])\n",
        "    pred_stable.append(pred)\n",
        "df['stable_ave'] = pred_stable"
      ],
      "metadata": {
        "id": "mn8kJy2KfLjn"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis\n",
        "df_analysis = pd.DataFrame(index=[\"AveError\", \"StdError\", \"AveAbsError\", \"StdAbsError\", \"Corrected_AveAbsError\", \"Corrected_StdAbsError\", \"Corr_coef\", \"<=1mm_rate\", \"<=2mm_rate\", \">2mm_rate\", \">18mm_sensitivity\", \">18mm_specificity\", \">18mm_positive_predictive\", \">18mm_negative_predictive\"], columns=df.columns[1:])\n",
        "targets = df['targets']\n",
        "\n",
        "for column in df.columns[1:]:\n",
        "    outputs = df[column]\n",
        "    df_analysis.loc[df_analysis.index[0],column] = statistics.mean(outputs-targets) #AveError\n",
        "    df_analysis.loc[df_analysis.index[1],column] = statistics.stdev(outputs-targets) #StdError\n",
        "    df_analysis.loc[df_analysis.index[2],column] = statistics.mean(abs(outputs-targets)) #AveAbsError\n",
        "    df_analysis.loc[df_analysis.index[3],column] = statistics.stdev(abs(outputs-targets)) #StdAbsError\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_error = (np.array(outputs)-np.array(targets)-np.array(statistics.mean(outputs-targets))).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "    df_analysis.loc[df_analysis.index[4],column] = statistics.mean(corrected_AbsError) #Corrected_AveAbsError\n",
        "    df_analysis.loc[df_analysis.index[5],column] = statistics.stdev(corrected_AbsError) #Corrected_StdAbsError\n",
        "    df_analysis.loc[df_analysis.index[6],column] = np.corrcoef(outputs, targets)[0,1] #Corr_coef\n",
        "    total = len(df)\n",
        "    within1 = sum((i <= 1 and i >= -1 for i in outputs-targets))\n",
        "    within2 = sum((i <= 2 and i >= -2 for i in outputs-targets))\n",
        "    over2 = sum((i > 2 or i < -2 for i in outputs-targets))\n",
        "\n",
        "    df_analysis.loc[df_analysis.index[7],column] = my_round(within1/total*100) #<=1mm_rate\n",
        "    df_analysis.loc[df_analysis.index[8],column] = my_round(within2/total*100) #<=2mm_rate\n",
        "    df_analysis.loc[df_analysis.index[9],column] = my_round(over2/total*100) #>2mm_rate\n",
        "\n",
        "    TP, FP, TN, FN = 0,0,0,0\n",
        "    for i in range(len(df)):\n",
        "      if df[\"targets\"][i]>=18 and df[column][i]>= 17.5:\n",
        "          TP += 1\n",
        "      if df[\"targets\"][i]<18 and df[column][i]>= 18.5:\n",
        "          FP += 1\n",
        "      if df[\"targets\"][i]>=18 and df[column][i]< 17.5:\n",
        "          FN += 1 \n",
        "      if df[\"targets\"][i]<18 and df[column][i]< 17.5:\n",
        "          TN += 1    \n",
        "\n",
        "    df_analysis.loc[df_analysis.index[10],column] = TP/(TP+FN) #Sensitivity\n",
        "    df_analysis.loc[df_analysis.index[11],column] = TN/(FP+TN) #Specificity\n",
        "    df_analysis.loc[df_analysis.index[12],column] = TP/(TP+FP) #Positive predictive value\n",
        "    df_analysis.loc[df_analysis.index[13],column] = TN/(TN+FN) #Negative predictive value\n",
        "\n",
        "\n",
        "df_analysis.to_csv( f\"./models_Hertel_estimation/5-fold-crossvalidation/analysis.csv\", header=True, index=False)"
      ],
      "metadata": {
        "id": "8QgA6XT_hMCY"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u86wisiyQyHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_analysis"
      ],
      "metadata": {
        "id": "p-JhpT5G1UOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw scatterplot\n",
        "\n",
        "targets = df[\"targets\"]\n",
        "outputs = df[\"average_all\"]\n",
        "\n",
        "#Draw Graphs（もともとの散布図\n",
        "df_plot = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df_plot)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df_plot['target']-df_plot['estimate'], bins=15, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "\n",
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V1G9vgI2Djy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBy1BeytJGel"
      },
      "source": [
        "#**Evaluation using testset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "area_num\n",
        "0: half \n",
        "1: periocular\n",
        "2: eye\n",
        "\"\"\"\n",
        "area_num = 0\n",
        "\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "#PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "#PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\"\n",
        "\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "r3FmwmZ8P9ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "#evaluation using validation dataset\n",
        "\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "\n",
        "model_ft.eval() # prep model for evaluation\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          print(f\"estimate: {my_round(output[0].item())} mm, target: {target[0].item()} mm\")\n",
        "\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "print('')\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n"
      ],
      "metadata": {
        "id": "9uZfA263UUhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lamJcFxkjkxA",
        "outputId": "36158ec7-2a62-4470-c2f0-05eceb76bd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "#Draw Graphs（もともとの散布図\n",
        "df = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.0, 24.0)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['target']-df['estimate'], bins=15, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示"
      ],
      "metadata": {
        "id": "IumsUK1p29SL",
        "outputId": "849cb508-71d5-4073-c58a-1b28c6f14aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "IfRogutV3Y4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(df)\n",
        "within1 = sum((i <= 1 and i >= -1 for i in df['estimate']-df['target']))\n",
        "within2 = sum((i <= 2 and i >= -2 for i in df['estimate']-df['target']))\n",
        "over2 = sum((i > 2 or i < -2 for i in df['estimate']-df['target']))\n",
        "\n",
        "print(f'-1<Error<1: {within1}, ({my_round(within1/total*100)}%)')\n",
        "print(f'-2<Error<2: {within1}, ({my_round(within2/total*100)}%)')\n",
        "print(f'Error over 2: {within1}, ({my_round(over2/total*100)}%)')\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]>= 18:\n",
        "        FN += 1\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]< 18:\n",
        "        FP += 1 \n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,0]>=16 and df.iloc[i,1]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,0]<16 and df.iloc[i,1]>= 18:\n",
        "        minogashi += 1\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]<= 16:\n",
        "        kajyou += 1 \n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n",
        "\n"
      ],
      "metadata": {
        "id": "QDNfYarsk3eI",
        "outputId": "3a01747d-1cce-4f87-9ffe-60bea1f67908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1<Error<1: 136, (69.39%)\n",
            "-2<Error<2: 136, (91.84%)\n",
            "Error over 2: 136, (8.16%)\n",
            "\n",
            "Hertel 18mm以上の検出精度\n",
            "TP: 68\n",
            "FP: 5\n",
            "FN: 11\n",
            "TN: 112\n",
            "Sensitivity: 0.8607594936708861\n",
            "Specificity: 0.9572649572649573\n",
            "Positive predictive value: 0.9315068493150684\n",
            "Negative predictive value: 0.9105691056910569\n",
            "\n",
            "推測18mm以上だが実は16mm未満(過剰): 1例\n",
            "推測16mm未満だが実は18mm以上（見逃がし）: 0例\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSxjXrglZc4k"
      },
      "source": [
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**平均値、線形近似による補正**"
      ],
      "metadata": {
        "id": "ctOezTjprVyF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R6aSRMkWEZO",
        "outputId": "92602d57-c35f-4e7f-bed2-1d6f617ace49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#線形近似式算出\n",
        "from sklearn import linear_model\n",
        "\n",
        "estimate = df.loc[:,'estimate']\n",
        "target = df.loc[:,'target']\n",
        "clf = linear_model.LinearRegression()\n",
        "\n",
        "# 説明変数xに \"x1\"のデータを使用\n",
        "x = np.array([estimate]).T\n",
        "\n",
        "# 目的変数yに \"x2\"のデータを使用\n",
        "y = target.values\n",
        "\n",
        "# 予測モデルを作成（単回帰）\n",
        "clf.fit(x, y)\n",
        "\n",
        "# パラメータ（回帰係数、切片）を抽出\n",
        "[a] = clf.coef_\n",
        "b = clf.intercept_\n",
        "\n",
        "# パラメータの表示\n",
        "print(\"回帰係数:\", a)\n",
        "print(\"切片:\", b)\n",
        "print(\"決定係数:\", clf.score(x, y))\n",
        "\n",
        "#平均値により補正した値\n",
        "df['Corrected_estimate_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,2] = corrected_output[i]\n",
        "\n",
        "#回帰直線により補正した値\n",
        "df['Corrected_estimate_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,3] = df.iloc[i,0]*a+b\n",
        "\n",
        "#残差\n",
        "df['Residual_error_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,4] = df.iloc[i,2]-df.iloc[i,1]\n",
        "\n",
        "#残差\n",
        "df['Residual_error_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,5] = df.iloc[i,3]-df.iloc[i,1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "回帰係数: 0.9243867958397015\n",
            "切片: 1.2198555301736356\n",
            "決定係数: 0.8391249673052268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlWXLynoKxy"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiUi44-jGIZ"
      },
      "source": [
        "#平均近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_1'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_1', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_1']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_1'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_1'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "\n",
        "print('')\n",
        "print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df['Residual_error_2']))))\n",
        "print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df['Residual_error_2']))))\n",
        "print('Error<=-2: ' +  str(sum((i <= -2 for i in df['Residual_error_2']))))\n",
        "print('Error>=2: ' +  str(sum((i >= 2 for i in df['Residual_error_2']))))\n",
        "\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]>= 18:\n",
        "        FP += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]< 18:\n",
        "        FN += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=16 and df.iloc[i,2]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,1]<16 and df.iloc[i,2]>= 18:\n",
        "        kajyou += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]<= 16:\n",
        "        minogashi += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x96i5oZDM0dm"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (平均値により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_1']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBFhobtCbv6t"
      },
      "source": [
        "#線形近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_2'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_2', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_2']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_2'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_2'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "print('')\n",
        "print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df['Residual_error_2']))))\n",
        "print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df['Residual_error_2']))))\n",
        "print('Error<=-2: ' +  str(sum((i <= -2 for i in df['Residual_error_2']))))\n",
        "print('Error>=2: ' +  str(sum((i >= 2 for i in df['Residual_error_2']))))\n",
        "\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]>= 18:\n",
        "        FP += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]< 18:\n",
        "        FN += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=16 and df.iloc[i,3]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,1]<16 and df.iloc[i,3]>= 18:\n",
        "        kajyou += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]<= 16:\n",
        "        minogashi += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPJMCKTFqFnQ"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (線形近似により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_2']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ensemble learning (Stacking)**"
      ],
      "metadata": {
        "id": "qf7jBK7E3ns_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define training"
      ],
      "metadata": {
        "id": "0hfU2ZFPKwwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load backup models\n",
        "for area_num in [0,1,2]:\n",
        "    orig_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2_backup.pth\"\n",
        "    dst_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    shutil.copy(orig_path, dst_path)\n",
        "    print(f\"loading: {os.path.basename(dst_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgP6XtWzak6R",
        "outputId": "c3835c57-ba50-414f-8782-7ee5d8bad0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: half_RepVGGA2.pth\n",
            "loading: periocular_RepVGGA2.pth\n",
            "loading: eye_RepVGGA2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#1つずつ解析するバージョン\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha=0):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    # define scaler (for fastening)\n",
        "    scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2])  #16,3,3,224,224 --> 16,3,224,224 (バッチサイズの次の次元でスライスすることによりtensorを取り出す)\n",
        "            \n",
        "            with torch.cuda.amp.autocast(): \n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "                ################\n",
        "                ##l2_normalization##\n",
        "                ################\n",
        "                l2 = torch.tensor(0., requires_grad=True)\n",
        "                for w in model.parameters():\n",
        "                    l2 = l2 + torch.norm(w)**2\n",
        "                loss = loss + alpha*l2\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer) \n",
        "            scaler.update() \n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2])\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            #print(f\"val_output: {output}\")\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "\n",
        "        \n",
        "        #Scheduler step for SGD\n",
        "        #scheduler.step() #val_lossが下がらなければ減衰\n",
        "        \n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "metadata": {
        "id": "DZny1BiR3dsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select model"
      ],
      "metadata": {
        "id": "jjrVJYPyLJCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output(half, periocular, eye, 各1層)を連結してトレーニング"
      ],
      "metadata": {
        "id": "-Bvoufo1yr04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        self.model_0 = model_ft_half\n",
        "        self.model_1 = model_ft_periocular\n",
        "        self.model_2 = model_ft_eye\n",
        "        self.fc = nn.Linear(in_features=3, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x1 = self.model_1(x1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSvjVD8U3n8T",
        "outputId": "d6fe3b14-6f09-40ba-b68a-30a7882da5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fc layer（各1408層）を直接連結してトレーニング（dropoutを追加）"
      ],
      "metadata": {
        "id": "wm0ywdRwy7VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        model_0 = model_ft_half\n",
        "        model_1 = model_ft_periocular\n",
        "        model_2 = model_ft_eye\n",
        "        self.model_0 = nn.Sequential(*list(model_0.children())[:-1])\n",
        "        self.model_1 = nn.Sequential(*list(model_1.children())[:-1])\n",
        "        self.model_2 = nn.Sequential(*list(model_2.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc = nn.Linear(in_features=1408*3, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x0 = torch.flatten(x0, 1)\n",
        "        x1 = self.model_1(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FJSZRKuQzKvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### さらに全結合層を追加"
      ],
      "metadata": {
        "id": "XnSzr6k3jJms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        model_0 = model_ft_half\n",
        "        model_1 = model_ft_periocular\n",
        "        model_2 = model_ft_eye\n",
        "        self.model_0 = nn.Sequential(*list(model_0.children())[:-1])\n",
        "        self.model_1 = nn.Sequential(*list(model_1.children())[:-1])\n",
        "        self.model_2 = nn.Sequential(*list(model_2.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc1 = nn.Linear(in_features=1408*3, out_features=20)\n",
        "        self.fc2 = nn.Linear(in_features=20, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x0 = torch.flatten(x0, 1)\n",
        "        x1 = self.model_1(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.fc1(x) \n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4m8_K8siyes",
        "outputId": "37043144-c2d4-4948-972b-12b4c8e29f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train ensemble model"
      ],
      "metadata": {
        "id": "Q4cFAvKSMHIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    del model_ft_ensemble\n",
        "    print(\"renewing modell_ft_ensemble...\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "model_ft_ensemble = Ensemble_three()\n",
        "model_ft_ensemble.to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "#optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "def read_path(area_num):\n",
        "    #ネットワークの読み込み\n",
        "    PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    print(\"...\")\n",
        "    print(f\"loading: {os.path.basename(PATH)}\")\n",
        "    return PATH\n",
        "\n",
        "model_ft_half = model_ft.load_state_dict(torch.load(read_path(0)))\n",
        "model_ft_periocular = model_ft.load_state_dict(torch.load(read_path(1)))\n",
        "model_ft_eye = model_ft.load_state_dict(torch.load(read_path(2)))\n",
        "\n",
        "# パラメータを固定\n",
        "\n",
        "# Fix model parameters\n",
        "for param in model_ft_ensemble.parameters():\n",
        "    param.requres_grad = False\n",
        "\n",
        "try:\n",
        "    # Let fc parameters rewritable\n",
        "    for param in model_ft_ensemble.fc1.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model_ft_ensemble.fc2.parameters():\n",
        "        param.requires_grad = True\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Let fc parameters rewritable\n",
        "    for param in model_ft_ensemble.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCiRr7ss_G3i",
        "outputId": "962fff88-b173-49a3-c061-b9ee18b76718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "renewing modell_ft_ensemble...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "...\n",
            "loading: half_RepVGGA2.pth\n",
            "...\n",
            "loading: periocular_RepVGGA2.pth\n",
            "...\n",
            "loading: eye_RepVGGA2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model, train_loss, valid_loss = train_model(model_ft_ensemble, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "aI1dpdwc2VSp",
        "outputId": "926ecf99-9768-4cc7-aa36-90888a346228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d5b8fcfdbf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_ensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-6a0303635654>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mrunning_corrects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;31m# convert batch-size labels to batch-size x 1 tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#target = target.squeeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-aec368febf3c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtensor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtensor_image_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtensor_image_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtensor_image_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-aec368febf3c>\u001b[0m in \u001b[0;36mtensor_img\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# [tensor[path0, path1, path2], hertel_value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mpilr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtensor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "PATH = f\"./models_Hertel_estimation/fc_ensemble.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "backup_path = f\"./models_Hertel_estimation/fc_ensemble_backup.pth\"\n",
        "shutil.copy(PATH, backup_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "suqWif1v2VU_",
        "outputId": "43ff8145-ab18-4a4c-a163-78b2e2071d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./models_Hertel_estimation/fc_ensemble_backup.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = f\"./models_Hertel_estimation/fc_ensemble.pth\"\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQwmK8WDnfOh",
        "outputId": "ae2ed462-7aea-4386-865a-8bcf73e3d1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 全ての層を書き換え可能にしてfine tuningする\n",
        "\n",
        "# Let all model parameters rewritable\n",
        "for param in model_ft_ensemble.parameters():\n",
        "    param.requres_grad = True\n",
        "\n",
        "# Train model\n",
        "model, train_loss, valid_loss = train_model(model_ft_ensemble, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "sNvccMAV0gT6",
        "outputId": "687f339f-d734-477c-832d-a34443c24a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [  1/100] \n",
            "train_loss: 156.08770 \n",
            "valid_loss: 55.77340 \n",
            "Validation loss decreased (inf --> 55.773396).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 3.82457 \n",
            "valid_loss: 54.45423 \n",
            "Validation loss decreased (55.773396 --> 54.454226).  Saving model ...\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 1.51321 \n",
            "valid_loss: 49.26537 \n",
            "Validation loss decreased (54.454226 --> 49.265373).  Saving model ...\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 1.45142 \n",
            "valid_loss: 85.19647 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 1.22514 \n",
            "valid_loss: 88.91958 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-3b9011eb2d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_ensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-144-6a0303635654>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# perform a single optimization step (parameter update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# record training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ranger_adabelief/ranger_adabelief.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mp_data_fp32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_data_fp32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# integrated look ahead...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3634sCn0gpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation using validation dataset\n",
        "\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "\n",
        "model_ft_ensemble.eval() # prep model for evaluation\n",
        "\n",
        "outputs,targets,errors =[], [], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      target = target.view(len(target), 1)         \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft_ensemble(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2]) #dim0はbach_size、dim1がarea_num\n",
        "\n",
        "      outputs.append(output[0].item())      \n",
        "      targets.append(target[0].item())\n",
        "      print(f\"estimate: {my_round(output[0].item())} mm, target: {target[0].item()} mm\")\n",
        "\n",
        "      errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "print('')\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYzQCiD02VXJ",
        "outputId": "008c8112-bfae-4e1e-cf1a-8e197b79bc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimate: 13.93 mm, target: 16.0 mm\n",
            "estimate: 10.97 mm, target: 12.0 mm\n",
            "estimate: 14.95 mm, target: 16.0 mm\n",
            "estimate: 14.16 mm, target: 16.0 mm\n",
            "estimate: 13.76 mm, target: 15.0 mm\n",
            "estimate: 17.25 mm, target: 19.0 mm\n",
            "estimate: 16.1 mm, target: 19.0 mm\n",
            "estimate: 11.14 mm, target: 12.0 mm\n",
            "estimate: 19.53 mm, target: 20.0 mm\n",
            "estimate: 15.94 mm, target: 19.0 mm\n",
            "estimate: 12.18 mm, target: 14.0 mm\n",
            "estimate: 19.04 mm, target: 20.0 mm\n",
            "estimate: 24.27 mm, target: 25.0 mm\n",
            "estimate: 12.08 mm, target: 13.0 mm\n",
            "estimate: 8.55 mm, target: 9.0 mm\n",
            "estimate: 18.41 mm, target: 21.0 mm\n",
            "estimate: 19.33 mm, target: 23.0 mm\n",
            "estimate: 16.5 mm, target: 20.0 mm\n",
            "estimate: 17.09 mm, target: 19.0 mm\n",
            "estimate: 16.17 mm, target: 20.0 mm\n",
            "estimate: 14.19 mm, target: 16.0 mm\n",
            "estimate: 17.25 mm, target: 21.0 mm\n",
            "estimate: 15.87 mm, target: 18.0 mm\n",
            "estimate: 19.1 mm, target: 21.0 mm\n",
            "estimate: 21.71 mm, target: 24.0 mm\n",
            "estimate: 13.35 mm, target: 14.0 mm\n",
            "estimate: 17.33 mm, target: 20.0 mm\n",
            "estimate: 15.82 mm, target: 17.0 mm\n",
            "estimate: 15.41 mm, target: 16.0 mm\n",
            "estimate: 13.79 mm, target: 16.0 mm\n",
            "estimate: 17.01 mm, target: 19.0 mm\n",
            "estimate: 13.32 mm, target: 15.0 mm\n",
            "estimate: 12.81 mm, target: 15.0 mm\n",
            "estimate: 12.59 mm, target: 13.0 mm\n",
            "estimate: 13.91 mm, target: 18.0 mm\n",
            "estimate: 13.53 mm, target: 14.0 mm\n",
            "estimate: 17.63 mm, target: 19.0 mm\n",
            "estimate: 13.22 mm, target: 16.0 mm\n",
            "estimate: 14.56 mm, target: 16.0 mm\n",
            "estimate: 20.9 mm, target: 23.0 mm\n",
            "estimate: 14.36 mm, target: 16.0 mm\n",
            "estimate: 15.98 mm, target: 19.0 mm\n",
            "estimate: 16.82 mm, target: 18.0 mm\n",
            "estimate: 12.6 mm, target: 14.0 mm\n",
            "estimate: 15.5 mm, target: 17.0 mm\n",
            "estimate: 16.34 mm, target: 15.0 mm\n",
            "estimate: 15.04 mm, target: 17.0 mm\n",
            "estimate: 14.96 mm, target: 17.0 mm\n",
            "estimate: 17.02 mm, target: 19.0 mm\n",
            "estimate: 16.26 mm, target: 18.0 mm\n",
            "estimate: 16.23 mm, target: 18.0 mm\n",
            "estimate: 11.85 mm, target: 13.0 mm\n",
            "estimate: 14.37 mm, target: 15.0 mm\n",
            "estimate: 11.32 mm, target: 12.0 mm\n",
            "estimate: 16.57 mm, target: 18.0 mm\n",
            "estimate: 13.66 mm, target: 16.0 mm\n",
            "estimate: 12.67 mm, target: 15.0 mm\n",
            "estimate: 14.34 mm, target: 15.0 mm\n",
            "estimate: 17.38 mm, target: 21.0 mm\n",
            "estimate: 14.18 mm, target: 15.0 mm\n",
            "estimate: 14.21 mm, target: 16.0 mm\n",
            "estimate: 17.12 mm, target: 18.0 mm\n",
            "estimate: 13.31 mm, target: 15.0 mm\n",
            "estimate: 18.99 mm, target: 21.0 mm\n",
            "estimate: 12.31 mm, target: 14.0 mm\n",
            "estimate: 16.05 mm, target: 18.0 mm\n",
            "estimate: 13.6 mm, target: 15.0 mm\n",
            "estimate: 18.26 mm, target: 19.0 mm\n",
            "estimate: 12.91 mm, target: 13.0 mm\n",
            "estimate: 16.71 mm, target: 17.0 mm\n",
            "estimate: 17.58 mm, target: 20.0 mm\n",
            "estimate: 11.87 mm, target: 13.0 mm\n",
            "estimate: 15.77 mm, target: 17.0 mm\n",
            "estimate: 14.45 mm, target: 16.0 mm\n",
            "estimate: 18.1 mm, target: 19.0 mm\n",
            "estimate: 19.01 mm, target: 21.0 mm\n",
            "estimate: 20.7 mm, target: 22.0 mm\n",
            "estimate: 16.74 mm, target: 18.0 mm\n",
            "estimate: 20.66 mm, target: 24.0 mm\n",
            "estimate: 14.64 mm, target: 16.0 mm\n",
            "estimate: 13.45 mm, target: 15.0 mm\n",
            "estimate: 11.8 mm, target: 12.0 mm\n",
            "estimate: 14.13 mm, target: 16.0 mm\n",
            "estimate: 18.62 mm, target: 20.5 mm\n",
            "estimate: 18.3 mm, target: 20.0 mm\n",
            "estimate: 13.69 mm, target: 15.0 mm\n",
            "estimate: 18.5 mm, target: 20.0 mm\n",
            "estimate: 14.13 mm, target: 14.0 mm\n",
            "estimate: 18.52 mm, target: 20.0 mm\n",
            "estimate: 13.96 mm, target: 17.0 mm\n",
            "estimate: 13.72 mm, target: 15.0 mm\n",
            "estimate: 15.07 mm, target: 18.0 mm\n",
            "estimate: 15.78 mm, target: 17.0 mm\n",
            "estimate: 13.48 mm, target: 16.0 mm\n",
            "estimate: 16.22 mm, target: 13.0 mm\n",
            "estimate: 14.15 mm, target: 16.0 mm\n",
            "estimate: 14.23 mm, target: 15.0 mm\n",
            "estimate: 15.26 mm, target: 18.0 mm\n",
            "estimate: 19.61 mm, target: 20.0 mm\n",
            "estimate: 15.78 mm, target: 18.0 mm\n",
            "estimate: 14.82 mm, target: 16.0 mm\n",
            "estimate: 17.4 mm, target: 19.0 mm\n",
            "estimate: 14.03 mm, target: 15.0 mm\n",
            "estimate: 19.36 mm, target: 21.0 mm\n",
            "estimate: 17.0 mm, target: 20.0 mm\n",
            "estimate: 17.45 mm, target: 20.0 mm\n",
            "estimate: 17.02 mm, target: 19.0 mm\n",
            "estimate: 17.1 mm, target: 20.0 mm\n",
            "estimate: 17.37 mm, target: 19.0 mm\n",
            "estimate: 18.98 mm, target: 21.0 mm\n",
            "estimate: 13.77 mm, target: 15.0 mm\n",
            "estimate: 15.83 mm, target: 17.0 mm\n",
            "estimate: 15.53 mm, target: 20.0 mm\n",
            "estimate: 13.25 mm, target: 15.0 mm\n",
            "estimate: 18.04 mm, target: 20.0 mm\n",
            "estimate: 15.78 mm, target: 17.0 mm\n",
            "estimate: 16.41 mm, target: 19.0 mm\n",
            "estimate: 14.94 mm, target: 20.0 mm\n",
            "estimate: 15.46 mm, target: 17.0 mm\n",
            "estimate: 17.32 mm, target: 19.0 mm\n",
            "estimate: 15.5 mm, target: 17.0 mm\n",
            "estimate: 15.62 mm, target: 21.0 mm\n",
            "estimate: 15.35 mm, target: 17.0 mm\n",
            "estimate: 18.28 mm, target: 21.0 mm\n",
            "estimate: 14.1 mm, target: 15.0 mm\n",
            "estimate: 11.5 mm, target: 12.0 mm\n",
            "estimate: 16.04 mm, target: 17.0 mm\n",
            "estimate: 14.74 mm, target: 17.0 mm\n",
            "estimate: 17.48 mm, target: 19.0 mm\n",
            "estimate: 15.33 mm, target: 17.0 mm\n",
            "estimate: 12.54 mm, target: 14.0 mm\n",
            "estimate: 15.8 mm, target: 17.0 mm\n",
            "estimate: 15.38 mm, target: 17.0 mm\n",
            "estimate: 14.67 mm, target: 15.0 mm\n",
            "estimate: 13.62 mm, target: 14.0 mm\n",
            "estimate: 16.57 mm, target: 18.0 mm\n",
            "estimate: 9.27 mm, target: 9.0 mm\n",
            "estimate: 16.91 mm, target: 18.0 mm\n",
            "estimate: 11.57 mm, target: 12.0 mm\n",
            "estimate: 12.77 mm, target: 14.0 mm\n",
            "estimate: 15.93 mm, target: 17.0 mm\n",
            "estimate: 13.79 mm, target: 15.0 mm\n",
            "estimate: 10.37 mm, target: 11.0 mm\n",
            "estimate: 17.84 mm, target: 20.0 mm\n",
            "estimate: 18.99 mm, target: 18.0 mm\n",
            "estimate: 12.52 mm, target: 14.0 mm\n",
            "estimate: 17.55 mm, target: 19.0 mm\n",
            "estimate: 15.55 mm, target: 17.0 mm\n",
            "estimate: 17.94 mm, target: 19.0 mm\n",
            "estimate: 14.94 mm, target: 17.0 mm\n",
            "estimate: 15.33 mm, target: 15.0 mm\n",
            "estimate: 15.66 mm, target: 17.0 mm\n",
            "estimate: 15.96 mm, target: 16.0 mm\n",
            "estimate: 11.73 mm, target: 12.0 mm\n",
            "estimate: 17.28 mm, target: 18.0 mm\n",
            "estimate: 21.1 mm, target: 23.0 mm\n",
            "estimate: 13.4 mm, target: 15.0 mm\n",
            "estimate: 10.18 mm, target: 12.0 mm\n",
            "estimate: 16.71 mm, target: 19.0 mm\n",
            "estimate: 13.57 mm, target: 14.0 mm\n",
            "estimate: 13.16 mm, target: 15.0 mm\n",
            "estimate: 11.56 mm, target: 15.0 mm\n",
            "estimate: 12.72 mm, target: 15.0 mm\n",
            "estimate: 10.27 mm, target: 11.0 mm\n",
            "estimate: 10.06 mm, target: 10.0 mm\n",
            "estimate: 12.11 mm, target: 13.0 mm\n",
            "estimate: 11.36 mm, target: 12.0 mm\n",
            "estimate: 15.22 mm, target: 17.0 mm\n",
            "estimate: 15.44 mm, target: 17.0 mm\n",
            "estimate: 15.46 mm, target: 17.0 mm\n",
            "estimate: 16.01 mm, target: 20.0 mm\n",
            "estimate: 15.3 mm, target: 17.0 mm\n",
            "estimate: 16.39 mm, target: 17.0 mm\n",
            "estimate: 12.52 mm, target: 14.0 mm\n",
            "estimate: 15.84 mm, target: 18.0 mm\n",
            "estimate: 12.57 mm, target: 14.0 mm\n",
            "estimate: 12.83 mm, target: 16.0 mm\n",
            "estimate: 13.62 mm, target: 15.0 mm\n",
            "estimate: 17.45 mm, target: 20.0 mm\n",
            "estimate: 14.81 mm, target: 16.0 mm\n",
            "estimate: 14.18 mm, target: 16.0 mm\n",
            "estimate: 19.02 mm, target: 20.0 mm\n",
            "estimate: 15.39 mm, target: 17.0 mm\n",
            "estimate: 15.1 mm, target: 18.0 mm\n",
            "estimate: 14.73 mm, target: 18.0 mm\n",
            "estimate: 20.03 mm, target: 18.0 mm\n",
            "estimate: 17.78 mm, target: 19.0 mm\n",
            "estimate: 12.68 mm, target: 12.0 mm\n",
            "estimate: 14.38 mm, target: 14.0 mm\n",
            "estimate: 13.59 mm, target: 13.0 mm\n",
            "estimate: 14.43 mm, target: 17.0 mm\n",
            "estimate: 14.96 mm, target: 17.0 mm\n",
            "estimate: 12.54 mm, target: 15.0 mm\n",
            "estimate: 12.96 mm, target: 13.0 mm\n",
            "estimate: 15.68 mm, target: 10.0 mm\n",
            "estimate: 16.33 mm, target: 18.0 mm\n",
            "AveError: -1.522510372862524\n",
            "StdError: 1.2268599775878566\n",
            "AveAbsError: 1.6827616983530473\n",
            "StdAbsError: 0.9944356232046988\n",
            "\n",
            "Corrected_AveAbsError: 0.8255372273827631\n",
            "Corrected_StdAbsError: 0.9056372115513152\n",
            "Round_Corrected_AveAbsError: 0.8254081632653061\n",
            "Round_Corrected_StdAbsError: 0.9057810550723012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw Graphs（もともとの散布図\n",
        "df_ensemble = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df_ensemble)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Li8BDOr12VZa",
        "outputId": "53b26515-c71a-462f-b7c9-7ca1e79e7694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.0, 24.0)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df_ensemble['target']-df_ensemble['estimate'], bins=15, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "DA4wwJtT2Vbj",
        "outputId": "55389ae8-9eea-49d5-e45a-84265ee8e42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(df_ensemble)\n",
        "within1 = sum((i <= 1 and i >= -1 for i in df_ensemble['estimate']-df_ensemble['target']))\n",
        "within2 = sum((i <= 2 and i >= -2 for i in df_ensemble['estimate']-df_ensemble['target']))\n",
        "over2 = sum((i > 2 or i < -2 for i in df['estimate']-df['target']))\n",
        "\n",
        "print(f'-1<Error<1: {within1}, ({my_round(within1/total*100)}%)')\n",
        "print(f'-2<Error<2: {within1}, ({my_round(within2/total*100)}%)')\n",
        "print(f'Error over 2: {within1}, ({my_round(over2/total*100)}%)')\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df_ensemble)):\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]>= 18:\n",
        "        TP += 1\n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]>= 18:\n",
        "        FN += 1\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]< 18:\n",
        "        FP += 1 \n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df_ensemble)):\n",
        "    if df_ensemble.iloc[i,0]>=16 and df_ensemble.iloc[i,1]> 18:\n",
        "        okpositive += 1\n",
        "    if df_ensemble.iloc[i,0]<16 and df_ensemble.iloc[i,1]>= 18:\n",
        "        minogashi += 1\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]<= 16:\n",
        "        kajyou += 1 \n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5JBKBJ2Vdp",
        "outputId": "138f3ffd-c30c-4fe5-af74-cc4d0d786bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1<Error<1: 48, (24.49%)\n",
            "-2<Error<2: 48, (71.43%)\n",
            "Error over 2: 48, (15.31%)\n",
            "\n",
            "Hertel 18mm以上の検出精度\n",
            "TP: 27\n",
            "FP: 0\n",
            "FN: 52\n",
            "TN: 117\n",
            "Sensitivity: 0.34177215189873417\n",
            "Specificity: 1.0\n",
            "Positive predictive value: 1.0\n",
            "Negative predictive value: 0.6923076923076923\n",
            "\n",
            "推測18mm以上だが実は16mm未満(過剰): 0例\n",
            "推測16mm未満だが実は18mm以上（見逃がし）: 13例\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "3bdeNzKQ2Vfz",
        "outputId": "60708a03-8ea1-4b18-bf2a-623edf358495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsMX4OLR2Vh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZ6K3ah3_G7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3uDlMtU3oFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated 5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "h1pCIJY5NeiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['target', 'fold0', 'fold1', 'fold2', 'fold3', 'fold4', 'fold0_corrected', 'fold1_corrected', 'fold2_corrected', 'fold3_corrected', 'fold4_corrected',]\n",
        "df_result = pd.DataFrame(index=[], columns=cols)\n",
        "\n",
        "cols = ['AveError', 'AveStdError', 'AveAbsError', 'StdAbsError', 'Corrected_AveAbsError', 'Corrected_StdAbsError', 'Round_Corrected_AveAbsError', 'Round_Corrected_StdAbsError']\n",
        "indices = ['fold0', 'fold1', 'fold2', 'fold3', 'fold4']\n",
        "df_summary = pd.DataFrame(index=indices, columns=cols)"
      ],
      "metadata": {
        "id": "akk3glokkBIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_start = 0 #スタートするfold\n",
        "dst_result_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_result.csv\"\n",
        "dst_summary_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_summary.csv\"\n",
        "\n",
        "#四捨五入のモジュール\n",
        "def my_round(x, d=0):\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "for fold in range(fold_start,5,1):    \n",
        "    ###############\n",
        "    ##Define model ##\n",
        "    ###############\n",
        "\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), lr=1e-5)\n",
        "    alpha = 1e-6 #l2_normalization\n",
        "\n",
        "    #################\n",
        "    ## select dataset ##\n",
        "    ################\n",
        "    train_dataset = Create_Datasets(train_set[fold], CSV_PATH, train_data_transforms)\n",
        "    val_dataset = Create_Datasets(val_set[fold], CSV_PATH, val_data_transforms)\n",
        "    test_dataset = Create_Datasets(test_set, CSV_PATH, val_data_transforms) \n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "    #################\n",
        "    ## train model ##\n",
        "    #################\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE,optimizer_ft, PATIENCE, EPOCH, device, alpha)\n",
        "\n",
        "    ####################\n",
        "    ## Draw learning curve ##\n",
        "    ####################\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss', color=\"#377eb8\")\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss', color=\"#ff7f00\")\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 10.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot(Hertel)_fold'+str(fold)+'.png', bbox_inches='tight', dpi=350)\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ## eval using validation dataset ##\n",
        "    ###########################\n",
        "\n",
        "    #evaluation using validation dataset (1枚ずつevalする)\n",
        "    val_dataset = Create_Datasets(val_set[fold], CSV_PATH, val_data_transforms)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 1)\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "\n",
        "    print('fold '+str(fold))\n",
        "    print('')\n",
        "    print('--evaluation using val dataset--')\n",
        "    print('AveError: '+str(statistics.mean(errors)))\n",
        "    print('StdError: '+str(statistics.stdev(errors)))\n",
        "    print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "    print('')\n",
        "\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "    corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "    round_output = [my_round(i) for i in outputs]\n",
        "    round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "    print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "    print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "    print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n",
        "    print('')\n",
        "    ###########################\n",
        "    ## eval using test dataset ##\n",
        "    ###########################\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "\n",
        "    \n",
        "    print('--evaluation using test dataset--')\n",
        "    print('AveError: '+str(statistics.mean(errors)))\n",
        "    print('StdError: '+str(statistics.stdev(errors)))\n",
        "    print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "    print('')\n",
        "\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "    corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "    round_output = [my_round(i) for i in outputs]\n",
        "    round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "    print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "    print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "    print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n",
        "    print('')\n",
        "    print('')\n",
        "\n",
        "    #結果をdataframeに書き込む\n",
        "    df_result['target'] = targets\n",
        "    df_result['fold'+str(fold)] = outputs\n",
        "    df_result['fold'+str(fold)+'_corrected'] = corrected_output\n",
        "    df_summary.iloc[fold, 0] = statistics.mean(errors)\n",
        "    df_summary.iloc[fold, 1] = statistics.stdev(errors)\n",
        "    df_summary.iloc[fold, 2] = statistics.mean(AbsError)\n",
        "    df_summary.iloc[fold, 3] = statistics.stdev(AbsError)\n",
        "    df_summary.iloc[fold, 4] = statistics.mean(corrected_AbsError)\n",
        "    df_summary.iloc[fold, 5] = statistics.stdev(corrected_AbsError)\n",
        "    df_summary.iloc[fold, 6] = statistics.mean(round_corrected_AbsError)\n",
        "    df_summary.iloc[fold, 7] = statistics.stdev(round_corrected_AbsError)\n",
        "\n",
        "    df_result.to_csv(dst_result_path,index=False)\n",
        "    df_summary.to_csv(dst_summary_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "5O9JFMDTjHRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_result_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_result_1.csv\"\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(dst_result_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "    df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "df_result"
      ],
      "metadata": {
        "id": "6qPNRLAhs9nY",
        "outputId": "6a9800bd-0e41-46b0-fcba-121b5eea96ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     target      fold0      fold1      fold2      fold3      fold4  \\\n",
              "0      16.0  18.274897  18.086258  16.982693  16.731331  18.360825   \n",
              "1      16.0  18.240702  16.648167  17.850836  19.017797  18.382151   \n",
              "2      16.0  18.401655  16.097504  17.015856  16.246473  16.902615   \n",
              "3      16.0  16.841370  16.170847  17.116571  17.318340  19.125807   \n",
              "4      21.0  19.725548  21.173748  20.488394  20.001635  20.520454   \n",
              "..      ...        ...        ...        ...        ...        ...   \n",
              "199    17.0  14.232739  13.812715  14.326204  13.889405  14.692945   \n",
              "200    19.0  21.097057  21.475121  20.992577  21.097054  20.442337   \n",
              "201    19.0  20.500013  18.138063  18.657246  19.152702  19.862629   \n",
              "202    15.0  17.755945  17.409885  16.379116  16.741234  16.965052   \n",
              "203    15.0  15.876468  17.173515  15.093376  14.462296  16.130594   \n",
              "\n",
              "     fold0_corrected  fold1_corrected  fold2_corrected  fold3_corrected  \\\n",
              "0          17.683797        18.048479        17.346565        16.704272   \n",
              "1          17.649602        16.610387        18.214708        18.990738   \n",
              "2          17.810555        16.059725        17.379728        16.219414   \n",
              "3          16.250270        16.133068        17.480444        17.291281   \n",
              "4          19.134448        21.135969        20.852266        19.974575   \n",
              "..               ...              ...              ...              ...   \n",
              "199        13.641640        13.774935        14.690077        13.862346   \n",
              "200        20.505957        21.437341        21.356449        21.069994   \n",
              "201        19.908913        18.100284        19.021118        19.125643   \n",
              "202        17.164845        17.372106        16.742989        16.714175   \n",
              "203        15.285368        17.135736        15.457249        14.435236   \n",
              "\n",
              "     fold4_corrected  \n",
              "0          18.388139  \n",
              "1          18.409465  \n",
              "2          16.929929  \n",
              "3          19.153122  \n",
              "4          20.547769  \n",
              "..               ...  \n",
              "199        14.720260  \n",
              "200        20.469652  \n",
              "201        19.889944  \n",
              "202        16.992366  \n",
              "203        16.157909  \n",
              "\n",
              "[204 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71713c29-0ea2-4991-beeb-69d28c5d665f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>fold0</th>\n",
              "      <th>fold1</th>\n",
              "      <th>fold2</th>\n",
              "      <th>fold3</th>\n",
              "      <th>fold4</th>\n",
              "      <th>fold0_corrected</th>\n",
              "      <th>fold1_corrected</th>\n",
              "      <th>fold2_corrected</th>\n",
              "      <th>fold3_corrected</th>\n",
              "      <th>fold4_corrected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.274897</td>\n",
              "      <td>18.086258</td>\n",
              "      <td>16.982693</td>\n",
              "      <td>16.731331</td>\n",
              "      <td>18.360825</td>\n",
              "      <td>17.683797</td>\n",
              "      <td>18.048479</td>\n",
              "      <td>17.346565</td>\n",
              "      <td>16.704272</td>\n",
              "      <td>18.388139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.240702</td>\n",
              "      <td>16.648167</td>\n",
              "      <td>17.850836</td>\n",
              "      <td>19.017797</td>\n",
              "      <td>18.382151</td>\n",
              "      <td>17.649602</td>\n",
              "      <td>16.610387</td>\n",
              "      <td>18.214708</td>\n",
              "      <td>18.990738</td>\n",
              "      <td>18.409465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.401655</td>\n",
              "      <td>16.097504</td>\n",
              "      <td>17.015856</td>\n",
              "      <td>16.246473</td>\n",
              "      <td>16.902615</td>\n",
              "      <td>17.810555</td>\n",
              "      <td>16.059725</td>\n",
              "      <td>17.379728</td>\n",
              "      <td>16.219414</td>\n",
              "      <td>16.929929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>16.841370</td>\n",
              "      <td>16.170847</td>\n",
              "      <td>17.116571</td>\n",
              "      <td>17.318340</td>\n",
              "      <td>19.125807</td>\n",
              "      <td>16.250270</td>\n",
              "      <td>16.133068</td>\n",
              "      <td>17.480444</td>\n",
              "      <td>17.291281</td>\n",
              "      <td>19.153122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>19.725548</td>\n",
              "      <td>21.173748</td>\n",
              "      <td>20.488394</td>\n",
              "      <td>20.001635</td>\n",
              "      <td>20.520454</td>\n",
              "      <td>19.134448</td>\n",
              "      <td>21.135969</td>\n",
              "      <td>20.852266</td>\n",
              "      <td>19.974575</td>\n",
              "      <td>20.547769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>17.0</td>\n",
              "      <td>14.232739</td>\n",
              "      <td>13.812715</td>\n",
              "      <td>14.326204</td>\n",
              "      <td>13.889405</td>\n",
              "      <td>14.692945</td>\n",
              "      <td>13.641640</td>\n",
              "      <td>13.774935</td>\n",
              "      <td>14.690077</td>\n",
              "      <td>13.862346</td>\n",
              "      <td>14.720260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>19.0</td>\n",
              "      <td>21.097057</td>\n",
              "      <td>21.475121</td>\n",
              "      <td>20.992577</td>\n",
              "      <td>21.097054</td>\n",
              "      <td>20.442337</td>\n",
              "      <td>20.505957</td>\n",
              "      <td>21.437341</td>\n",
              "      <td>21.356449</td>\n",
              "      <td>21.069994</td>\n",
              "      <td>20.469652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>19.0</td>\n",
              "      <td>20.500013</td>\n",
              "      <td>18.138063</td>\n",
              "      <td>18.657246</td>\n",
              "      <td>19.152702</td>\n",
              "      <td>19.862629</td>\n",
              "      <td>19.908913</td>\n",
              "      <td>18.100284</td>\n",
              "      <td>19.021118</td>\n",
              "      <td>19.125643</td>\n",
              "      <td>19.889944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>15.0</td>\n",
              "      <td>17.755945</td>\n",
              "      <td>17.409885</td>\n",
              "      <td>16.379116</td>\n",
              "      <td>16.741234</td>\n",
              "      <td>16.965052</td>\n",
              "      <td>17.164845</td>\n",
              "      <td>17.372106</td>\n",
              "      <td>16.742989</td>\n",
              "      <td>16.714175</td>\n",
              "      <td>16.992366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>15.0</td>\n",
              "      <td>15.876468</td>\n",
              "      <td>17.173515</td>\n",
              "      <td>15.093376</td>\n",
              "      <td>14.462296</td>\n",
              "      <td>16.130594</td>\n",
              "      <td>15.285368</td>\n",
              "      <td>17.135736</td>\n",
              "      <td>15.457249</td>\n",
              "      <td>14.435236</td>\n",
              "      <td>16.157909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71713c29-0ea2-4991-beeb-69d28c5d665f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71713c29-0ea2-4991-beeb-69d28c5d665f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71713c29-0ea2-4991-beeb-69d28c5d665f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5-foldのICC(2,1)とp-valueを算出\n",
        "target = df_result[\"target\"]\n",
        "fold0 = df_result[\"fold0_corrected\"]\n",
        "fold1 = df_result[\"fold1_corrected\"]\n",
        "fold2 = df_result[\"fold2_corrected\"]\n",
        "fold3 = df_result[\"fold3_corrected\"]\n",
        "fold4 = df_result[\"fold4_corrected\"]\n",
        "\n",
        "ICC_list, pval_list , ave_list, std_list, ttest_list= [], [], [], [], []\n",
        "for fold in [fold0,fold1,fold2,fold3,fold4]:\n",
        "    ratings = np.concatenate([target,fold])\n",
        "    raters = ['target'] * len(target) + ['pred'] *len(fold)\n",
        "    targets = [i for i in range(len(target))]+[i for i in range(len(target))]\n",
        "\n",
        "    data = pd.DataFrame({'targets':targets, 'raters':raters, 'ratings':ratings})\n",
        "    icc = pg.intraclass_corr(data=data, targets='targets', \n",
        "                            raters='raters', ratings='ratings')\n",
        "    df_icc = icc.set_index('Type')\n",
        "    ICC_list.append(df_icc.loc[\"ICC2\",\"ICC\"])\n",
        "    pval_list.append(df_icc.loc[\"ICC2\",\"pval\"])\n",
        "    ave_list.append(statistics.mean(fold))\n",
        "    std_list.append(statistics.stdev(fold))\n",
        "    ttest_list.append(stats.ttest_rel(target, fold)[1])\n",
        "\n",
        "\n",
        "print(\"target: {}±{}\".format(statistics.mean(target), statistics.stdev(target)))\n",
        "print(\"folds: {}±{}\".format(statistics.mean(ave_list), statistics.mean(std_list)))\n",
        "print(\"p-value (ttest): {}\".format(statistics.mean(ttest_list)))\n",
        "print(\"ICC(2,1): {}±{}\".format(statistics.mean(ICC_list), statistics.stdev(ICC_list)))\n",
        "print(\"p-value (ICC): {}\".format(statistics.mean(pval_list)))\n"
      ],
      "metadata": {
        "id": "FSm7VDfYwBwj",
        "outputId": "c730e3ed-f856-48eb-b1be-80a16cb7a591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target: 16.86519607843137±2.7894442938967283\n",
            "folds: 16.86519607845098±2.3422292408301435\n",
            "p-value (ttest): 0.9999999991062075\n",
            "ICC(2,1): 0.704768158145101±0.030114555646246675\n",
            "p-value (ICC): 3.4573877614181293e-29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate residual error\n",
        "df_result[\"fold0_residual_error\"] = df_result[\"fold0_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold1_residual_error\"] = df_result[\"fold1_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold2_residual_error\"] = df_result[\"fold2_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold3_residual_error\"] = df_result[\"fold3_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold4_residual_error\"] = df_result[\"fold4_corrected\"] - df_result[\"target\"]\n",
        "\n",
        "under1mm_list, under2mm_list, sensitivity_list, specificity_list = [], [], [], []\n",
        "k=0\n",
        "for fold in [fold0, fold1, fold2, fold3, fold4]: \n",
        "    print(\"fold {}\".format(k))\n",
        "    print(\"\")\n",
        "\n",
        "    ########################\n",
        "    ##Draw Graphs（散布図)##\n",
        "    ########################\n",
        "    df = pd.DataFrame({'estimate':fold, 'target':target})\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.set_palette('gray')\n",
        "    sns.lmplot(x='estimate', y='target', data=df)\n",
        "    plt.xlim(10,24)\n",
        "    plt.ylim(10,24)\n",
        "    plt.title('Scatter Plot')\n",
        "    plt.show()\n",
        "\n",
        "    ###########################################\n",
        "    ##Bland-Altman-Plot using corrected value##\n",
        "    ###########################################\n",
        "    def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "        data1     = np.asarray(data1)\n",
        "        data2     = np.asarray(data2)\n",
        "        mean      = np.mean([data1, data2], axis=0)\n",
        "        diff      = data1 - data2                   # Difference between data1 and data2\n",
        "        md        = np.mean(diff)                   # Mean of the difference\n",
        "        sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "        plt.scatter(mean, diff, *args, **kwargs)\n",
        "        plt.axhline(md,           color='gray', linestyle='--')\n",
        "        plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "        plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "    corrected_estimate = fold\n",
        "    target = df.loc[:,'target']\n",
        "\n",
        "    bland_altman_plot(corrected_estimate, target)\n",
        "    plt.title('Bland-Altman Plot')\n",
        "    plt.show()\n",
        "\n",
        "    ####################\n",
        "    ## Draw histogram ##\n",
        "    ####################\n",
        "    sns.distplot(\n",
        "    df_result['fold'+str(k)+'_residual_error'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        "    )\n",
        "    plt.legend() # 凡例を表示\n",
        "    plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "    #Draw Graphs\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.set_palette('gray')\n",
        "    sns.lmplot(x='fold'+str(k)+\"_corrected\", y='target', data=df_result)\n",
        "    plt.xlim(10,24)\n",
        "    plt.ylim(10,24)\n",
        "\n",
        "    corrected_AbsError = [abs(i) for i in df_result['fold'+str(k)+'_residual_error']]\n",
        "    print('AveError: '+str(statistics.mean(df_result['fold'+str(k)+'_residual_error'])))\n",
        "    print('StdError: '+str(statistics.stdev(df_result['fold'+str(k)+'_residual_error'])))\n",
        "    print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "\n",
        "    print('')\n",
        "    print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('Error<=-2: ' +  str(sum((i <= -2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('Error>=2: ' +  str(sum((i >= 2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN = 0,0,0,0\n",
        "    for i in range(len(df_result)):\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]>= 18:\n",
        "            TP += 1\n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]>= 18:\n",
        "            FP += 1\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]< 18:\n",
        "            FN += 1 \n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]< 18:\n",
        "            TN += 1     \n",
        "\n",
        "    print('')\n",
        "    print('Hertel 18mm以上の検出精度')\n",
        "    print('TP: '+str(TP))\n",
        "    print('FP: '+str(FP))\n",
        "    print('FN: '+str(FN))\n",
        "    print('TN: '+str(TN))\n",
        "    print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "    print('Specificity: '+str(TN/(FP+TN)))\n",
        "    print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "    print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "    okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "    for i in range(len(df)):\n",
        "        if df_result.loc[i,\"target\"]>=16 and df_result.loc[i,'fold'+str(k)+'_corrected']> 18:\n",
        "            okpositive += 1\n",
        "        if df_result.loc[i,\"target\"]<16 and df_result.loc[i,'fold'+str(k)+'_corrected']>= 18:\n",
        "            kajyou += 1\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+'_corrected']<= 16:\n",
        "            minogashi += 1 \n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+'_corrected']<= 16:\n",
        "            oknegative += 1     \n",
        "\n",
        "    print('')\n",
        "    print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "    print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    under1mm_list.append(sum((i < 1 and i > -1 for i in df_result['fold'+str(k)+'_residual_error']))/len(target))\n",
        "    under2mm_list.append(sum((i < 2 and i > -2 for i in df_result['fold'+str(k)+'_residual_error']))/len(target))\n",
        "    sensitivity_list.append(TP/(TP+FN))\n",
        "    specificity_list.append(TN/(FP+TN))\n",
        "    k+=1\n",
        "\n",
        "print(\"under1mm: {}±{}\".format(statistics.mean(under1mm_list), statistics.stdev(under1mm_list)))\n",
        "print(\"under2mm: {}±{}\".format(statistics.mean(under2mm_list), statistics.stdev(under2mm_list)))\n",
        "print(\"Sensitivity: {}±{}\".format(statistics.mean(sensitivity_list), statistics.stdev(sensitivity_list)))\n",
        "print(\"Specificity: {}±{}\".format(statistics.mean(specificity_list), statistics.stdev(specificity_list)))"
      ],
      "metadata": {
        "id": "oiaPxhIb-I9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9uu8S7EAhSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}