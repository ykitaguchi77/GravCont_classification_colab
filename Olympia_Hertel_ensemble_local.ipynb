{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled72.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Olympia_Hertel_ensemble_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJiUlScYrIgg"
      },
      "source": [
        "#**Olympia_Hertel_estimation_RepVGG-A2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import modules"
      ],
      "metadata": {
        "id": "EZvxdGnfLm8o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1FDbAxrAsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d10e28-9867-4490-cfb1-f90c281df28f"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install --q torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import statistics\n",
        "import math\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "import shutil\n",
        "import codecs\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "!pip install --q pingouin\n",
        "import pingouin as pg\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "# #google driveをcolabolatoryにマウント\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 15 10:19:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 526.67       Driver Version: 526.67       CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Quadro RTX 5000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   45C    P0    33W /  N/A |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Random Seed:  1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XD7y5oqsMwg"
      },
      "source": [
        "## **Set Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Er_Gm6sRDv"
      },
      "source": [
        "path = r'C:\\Users\\ykita\\OneDrive\\デスクトップ\\Hertel_dataset'\n",
        "os.chdir(path)\n",
        "\n",
        "# grav or cont, age, and sex\n",
        "#NUM_CLASSES = 3\n",
        "\n",
        "# contains train, val\n",
        "#DATASET_PATH = r\"./dataset_500px\"\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "DATASET_PATH_0 = f\"./dataset_250px_uni_{AREA[0]}\"\n",
        "DATASET_PATH_1 = f\"./dataset_250px_uni_{AREA[1]}\"\n",
        "DATASET_PATH_2 = f\"./dataset_250px_uni_{AREA[2]}\"\n",
        "PARENT_PATHS = [DATASET_PATH_0, DATASET_PATH_1, DATASET_PATH_2]\n",
        "#TRAIN_FOLDER_NAME = \"train\"\n",
        "#VAL_FOLDER_NAME = \"val\"\n",
        "#EFFICIENT_NET_NAME = \"RepVGG-A2-train\"\n",
        "MODEL_PATH = \"./RepVGG-A2-train.pth\"\n",
        "CSV_PATH = \"./Hertel_unilateral.csv\"\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "#SEX_DICT_PATH = \"gender_json\"\n",
        "#AGE_DICT_PATH = \"age_json\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "#CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# transforms param　　左右分けているのでflipはしない\n",
        "PX = 224\n",
        "TRAIN_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "ROTATION_DEGREES = 3\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "\n",
        "VAL_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "# train_data_transforms = transforms.Compose([\n",
        "#                 transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "#                 #transforms.RandomRotation(ROTATION_DEGREES),\n",
        "#                 transforms.RandomHorizontalFlip(),\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\n",
        "# val_data_transforms = transforms.Compose([\n",
        "#                 transforms.Resize(PX),\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])]) \n",
        "\n",
        "# https://buildersbox.corp-sansan.com/entry/2020/11/05/110000\n",
        "train_data_transforms = nn.Sequential(\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                #transforms.RandomRotation(ROTATION_DEGREES),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])\n",
        "                ).to(device)\n",
        "val_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])\n",
        "                ).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-Foldに分割**"
      ],
      "metadata": {
        "id": "aLBpMuFwhz1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    #id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    id_list = [os.path.basename(name).split(\".\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "def extract_patient_number(path_list):\n",
        "    patient_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(patient_list)\n",
        "\n",
        "\n",
        "path_list = make_path_list(PARENT_PATHS[1])\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "id = extract_ids(path_list)\n",
        "patient = extract_patient_number(id)\n",
        "\n",
        "print(\"id_num: {}\".format(len(id)))\n",
        "print(\"patient_num: {}\".format(len(patient)))\n",
        "\n",
        "print(len(path_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZXXWIO9k9Cq",
        "outputId": "76f378f1-6251-49ad-e78a-ae7c0003f2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_num: 1959\n",
            "patient_num: 1959\n",
            "1959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_list_0 = extract_ids(make_path_list(DATASET_PATH_0))\n",
        "id_list_1 = extract_ids(make_path_list(DATASET_PATH_1))\n",
        "id_list_2 = extract_ids(make_path_list(DATASET_PATH_2))\n",
        "common_id = set(id_list_0) & set(id_list_1) & set(id_list_2)\n",
        "common_patient = list([id.split(\"_\")[0] for id in common_id])\n",
        "\n",
        "path_list_0 = [f\"{DATASET_PATH_0}/{id}.JPG\" for id in common_id]    \n",
        "path_list_1 = [f\"{DATASET_PATH_1}/{id}.JPG\" for id in common_id]    \n",
        "path_list_2 = [f\"{DATASET_PATH_2}/{id}.JPG\" for id in common_id]    \n",
        "path_list_list = [path_list_0, path_list_1, path_list_2]\n",
        "\n",
        "print(f\"common_ids: {len(common_id)}\")\n",
        "print(f\"common_patients: {len(common_patient)}\")\n",
        "print(f\"{path_list_0[20]}\")\n",
        "print(f\"{path_list_1[20]}\")\n",
        "print(f\"{path_list_2[20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9H3EZ2B3Dl",
        "outputId": "a1cd740f-f20d-40e5-f864-dfe1d06739f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_ids: 1959\n",
            "common_patients: 1959\n",
            "./dataset_250px_uni_half/802_L.JPG\n",
            "./dataset_250px_uni_periocular/802_L.JPG\n",
            "./dataset_250px_uni_eye/802_L.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Group Shuffle Split ＋　Group K-foldを用いてデータセット分け(idxを抜き出し)\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "#fold数だけ空のリストを作成\n",
        "num_folds = 5\n",
        "train_set, val_set =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "train_idx, val_idx =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "test_idx = []\n",
        "test_set, remain_set = [], []\n",
        "\n",
        "#remain:test = 1:9で分割\n",
        "X = np.ones(len(common_id))\n",
        "y = np.ones(len(common_id))\n",
        "groups = common_patient\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=0.9, random_state=random_seed)\n",
        "for remain_idxs, test_idxs in gss.split(X, y, groups):\n",
        "    pass\n",
        "\n",
        "test_idx = [idx for idx in test_idxs]\n",
        "# test_set = [path_list[idxs] for idxs in test_idxs]\n",
        "\n",
        "remain_patients = [patient[idxs] for idxs in remain_idxs]\n",
        "# remain_set = [path_list[idxs] for idxs in remain_idxs]\n",
        "\n",
        "X = np.ones(len(remain_idxs))\n",
        "y = np.ones(len(remain_idxs))\n",
        "gkf = GroupKFold(n_splits=num_folds)\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(X, y, groups=remain_patients):\n",
        "    for idx in train_idxs:\n",
        "        # train_set[i].append(remain_set[idx])\n",
        "        train_idx[i].append(idx)\n",
        "    for idx in val_idxs:\n",
        "        # val_set[i].append(remain_set[idx])\n",
        "        val_idx[i].append(idx)\n",
        "    i+=1\n",
        "\n",
        "print(\"train_dataset: {}\".format(len(train_idx[0])))\n",
        "print(\"val_dataset: {}\".format(len(val_idx[0])))\n",
        "print(\"test_dataset: {}\".format(len(test_idx)))\n",
        "# print(\"\")\n",
        "# print(\"extracted_id (example): {}\".format(extract_ids(test_set)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzjZhrg3lrdU",
        "outputId": "abac6c8a-1f94-46d1-f6fa-a8a1c5392369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset: 1410\n",
            "val_dataset: 353\n",
            "test_dataset: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GURyJLkrtsx"
      },
      "source": [
        "## **Create Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Create_Datasets(Dataset):\n",
        "     \n",
        "    def __init__(self, image_path_list_list, idxs, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.path_list_list = path_list_list\n",
        "        self.idxs = idxs\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        df = self.df\n",
        "\n",
        "        k=0\n",
        "        for idx in idxs:\n",
        "            path_0, path_1, path_2 = path_list_list[0][idx], path_list_list[1][idx], path_list_list[2][idx]\n",
        "            base_name = os.path.splitext(os.path.basename(path_0))[0] #フォルダより画像番号を抜き出す\n",
        "            hertel = df[df['number']==str(base_name)].iloc[0,1] #CSV上で一致した番号の画像についてHertel値を抜き出す\n",
        "            self.item_paths.append([path_0, path_1, path_2, hertel]) #[path, hertel]の組み合わせをリストに追加する\n",
        "            item_paths = self.item_paths\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "     \n",
        "    def __getitem__(self, index):\n",
        "        # [tensor[path0, path1, path2], hertel_value]\n",
        "        def tensor_img(image_path):\n",
        "            pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "            tensor_image = transforms.functional.to_tensor(pilr_image)\n",
        "            tensor_image = self.transform(tensor_image)\n",
        "            # tensor_image = self.transform(pilr_image).float()\n",
        "            # tensor_image = self.transform(read_image(path=image_path))\n",
        "            return tensor_image\n",
        "        tensor_image_0 = tensor_img(self.item_paths[index][0]) \n",
        "        tensor_image_1 = tensor_img(self.item_paths[index][1])      \n",
        "        tensor_image_2 = tensor_img(self.item_paths[index][2])      \n",
        "        tensor_image = torch.stack([tensor_image_0, tensor_image_1, tensor_image_2])\n",
        "        #tensor_image = tensor_image_0\n",
        "        hertel = self.item_paths[index][3]\n",
        "        target= torch.tensor([hertel]).float()\n",
        "        return  tensor_image, target\n",
        "\n",
        "train_dataset = Create_Datasets(path_list_list, train_idx[0], CSV_PATH, train_data_transforms)\n",
        "val_dataset = Create_Datasets(path_list_list, val_idx[0], CSV_PATH, val_data_transforms)\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "print('train_dataset_size: ' +str(len(train_dataset)))\n",
        "print('val_dataset_size: ' +str(len(val_dataset)))\n",
        "print('test_dataset_size: ' +str(len(test_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXqKg2jfswY3",
        "outputId": "27a83f29-d66a-4dc9-f6c5-241e2e35b2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_size: 1410\n",
            "val_dataset_size: 353\n",
            "test_dataset_size: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMch8ogOX1X6"
      },
      "source": [
        "## **Test with early-stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IIK64KHX1nA"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#1つずつ解析するバージョン\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device, area_num, alpha=0):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # define scaler for fastening\n",
        "        scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,area_num])  #16,3,3,224,224 --> 16,3,224,224 (バッチサイズの次の次元でスライスすることによりtensorを取り出す)\n",
        "            # calculate the loss\n",
        "            with torch.cuda.amp.autocast(): \n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "                ################\n",
        "                ##l2_normalization##\n",
        "                ################\n",
        "                l2 = torch.tensor(0., requires_grad=True)\n",
        "                for w in model.parameters():\n",
        "                    l2 = l2 + torch.norm(w)**2\n",
        "                loss = loss + alpha*l2\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer) \n",
        "            scaler.update() \n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,area_num])\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "\n",
        "        \n",
        "        #Scheduler step for SGD\n",
        "        #scheduler.step() #val_lossが下がらなければ減衰\n",
        "        \n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXAxIikRdQEu"
      },
      "source": [
        "## **define RepVGG-A2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZk-1LhdQTK"
      },
      "source": [
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc = nn.Linear(in_features=1408, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYO37TYHeFwG"
      },
      "source": [
        "## **ConvNetの調整**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6p9djzEeF7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdad065-5e08-4e74-9e60-d6cbeb0260c8"
      },
      "source": [
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "# !pip install ranger_adabelief\n",
        "# from ranger_adabelief import RangerAdaBelief\n",
        "# optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft =  optim.AdaBound(\n",
        "#     model_ft.parameters(),\n",
        "#     lr= 1e-3,\n",
        "#     betas= (0.9, 0.999),\n",
        "#     final_lr = 0.1,\n",
        "#     gamma=1e-3,\n",
        "#     eps= 1e-8,\n",
        "#     weight_decay=5e-4,\n",
        "#     amsbound=False,\n",
        "# )"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**モデルのトレーニング**"
      ],
      "metadata": {
        "id": "bGofj_nxPfx1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lPDAqyEEx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ed2c10e-e4a2-4784-fbc5-1639854d4b94"
      },
      "source": [
        "\"\"\"\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "データセットからそれぞれの画像を読みこんでトレーニング\n",
        "\"\"\"\n",
        "train_dataset = Create_Datasets(path_list_list, train_idx[0], CSV_PATH, train_data_transforms)\n",
        "val_dataset = Create_Datasets(path_list_list, val_idx[0], CSV_PATH, val_data_transforms)\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "print('train_dataset_size: ' +str(len(train_dataset)))\n",
        "print('val_dataset_size: ' +str(len(val_dataset)))\n",
        "print('test_dataset_size: ' +str(len(test_dataset)))\n",
        "\n",
        "\n",
        "for area_num in [0]:\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "    model_ft = model_ft.to(device)\n",
        "    loss_func = nn.MSELoss()\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device, area_num=area_num)\n",
        "\n",
        "    #save the model\n",
        "    PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_test_RepVGGA2.pth\"\n",
        "    torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_size: 1410\n",
            "val_dataset_size: 353\n",
            "test_dataset_size: 196\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Epoch: [  1/100] \n",
            "train_loss: 23.68999 \n",
            "valid_loss: 12.41374 \n",
            "Validation loss decreased (inf --> 12.413740).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 4.13531 \n",
            "valid_loss: 3.94686 \n",
            "Validation loss decreased (12.413740 --> 3.946857).  Saving model ...\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 3.54612 \n",
            "valid_loss: 6.82275 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 3.25421 \n",
            "valid_loss: 9.64995 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 3.01224 \n",
            "valid_loss: 4.63676 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [  6/100] \n",
            "train_loss: 2.78526 \n",
            "valid_loss: 6.79342 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [  7/100] \n",
            "train_loss: 2.55843 \n",
            "valid_loss: 3.40311 \n",
            "Validation loss decreased (3.946857 --> 3.403112).  Saving model ...\n",
            "\n",
            "Epoch: [  8/100] \n",
            "train_loss: 2.53047 \n",
            "valid_loss: 3.16447 \n",
            "Validation loss decreased (3.403112 --> 3.164472).  Saving model ...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [174]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     26\u001b[0m optimizer_ft \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model_ft\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.0002\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m model, train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marea_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#save the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models_Hertel_estimation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAREA[area_num]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test_RepVGGA2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, area_num, alpha)\u001b[0m\n\u001b[0;32m    116\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# prep model for evaluation\u001b[39;00m\n\u001b[0;32m    118\u001b[0m running_corrects, val_acc\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_tensor, target \u001b[38;5;129;01min\u001b[39;00m val_loader:  \n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#target = target.squeeze(1)         \u001b[39;00m\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(target), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    124\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36mCreate_Datasets.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# tensor_image = self.transform(pilr_image).float()\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# tensor_image = self.transform(read_image(path=image_path))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor_image\n\u001b[1;32m---> 32\u001b[0m tensor_image_0 \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     33\u001b[0m tensor_image_1 \u001b[38;5;241m=\u001b[39m tensor_img(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_paths[index][\u001b[38;5;241m1\u001b[39m])      \n\u001b[0;32m     34\u001b[0m tensor_image_2 \u001b[38;5;241m=\u001b[39m tensor_img(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_paths[index][\u001b[38;5;241m2\u001b[39m])      \n",
            "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36mCreate_Datasets.__getitem__.<locals>.tensor_img\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_img\u001b[39m(image_path):\n\u001b[1;32m---> 26\u001b[0m     pilr_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     tensor_image \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mto_tensor(pilr_image)\n\u001b[0;32m     28\u001b[0m     tensor_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(tensor_image)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\Image.py:889\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\ImageFile.py:235\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\JpegImagePlugin.py:402\u001b[0m, in \u001b[0;36mJpegImageFile.load_read\u001b[1;34m(self, read_bytes)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, read_bytes):\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    internal: read more image data\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    so libjpeg can finish decoding\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ended\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Premature EOF.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;66;03m# Pretend file is finished adding EOI marker\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_test_RepVGGA2.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "hp5LBdAGNJGb"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#backup models\n",
        "for area_num in [0,1,2]:\n",
        "    orig_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    dst_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2_backup.pth\"\n",
        "    shutil.copy(orig_path, dst_path)"
      ],
      "metadata": {
        "id": "NXLBk6vDZqqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEkl9xMiIno_"
      },
      "source": [
        "#Draw learning curve\n",
        "\"\"\"\n",
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss', color=\"#377eb8\")\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss', color=\"#ff7f00\")\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 10.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "BAdFoY4h22gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "#Training\n",
        "\n",
        "for fold in [0,1,2,3,4]:\n",
        "    # Define dataset and dataloader\n",
        "    train_dataset = Create_Datasets(path_list_list, train_idx[fold], CSV_PATH, train_data_transforms)\n",
        "    val_dataset = Create_Datasets(path_list_list, val_idx[fold], CSV_PATH, val_data_transforms)\n",
        "    test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers=0, pin_memory=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    #train models\n",
        "    AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "    for area_num in [0,1,2]:\n",
        "        print(f\"area: {AREA[area_num], fold: {fold}}\")\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "        model_ft = mod_RepVGG()\n",
        "        model_ft = model_ft.to(device)\n",
        "        loss_func = nn.MSELoss()\n",
        "        optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "        model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device, area_num=area_num)\n",
        "\n",
        "        #save the model\n",
        "        PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "        torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "        PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_backup_RepVGGA2.pth\"\n",
        "        torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "metadata": {
        "id": "EDC5obyi26YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference on single model\n",
        "\n",
        "model_path = f\"./models_Hertel_estimation/half_test_RepVGGA2.pth\"\n",
        "\n",
        "#model_path = f\"./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\"\n",
        "#model_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False) \n",
        "model_ft = mod_RepVGG()\n",
        "model_ft = model_ft.to(device)\n",
        "model_ft.load_state_dict(torch.load(model_path))\n",
        "model_ft.eval() # prep model for evaluation\n",
        "print(f\"model_path: {model_path}\")\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs = []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "          outputs.append(output[0].item())      \n",
        "df[f'{area}_fold{str(fold)}'] = outputs\n",
        "print(f\"targets: {targets}\")\n",
        "print(f\"outputs: {[my_round(i) for i in outputs]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_AUuV--W4NV",
        "outputId": "5cf35b15-f50f-4c35-fb35-6be30389195c"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/half_test_RepVGGA2.pth\n",
            "targets: 0      14.0\n",
            "1      17.0\n",
            "2      16.0\n",
            "3      18.0\n",
            "4      19.0\n",
            "       ... \n",
            "191    19.0\n",
            "192    17.0\n",
            "193    16.0\n",
            "194    20.0\n",
            "195    16.0\n",
            "Name: targets, Length: 196, dtype: float64\n",
            "outputs: [13.66, 17.57, 14.77, 16.4, 18.65, 20.58, 15.0, 21.19, 13.52, 15.45, 14.29, 13.33, 15.51, 11.22, 20.15, 16.62, 12.68, 17.48, 15.13, 22.25, 16.45, 16.84, 17.99, 12.89, 16.12, 13.07, 18.79, 18.45, 10.49, 15.34, 12.44, 17.69, 15.45, 14.66, 16.99, 15.14, 15.41, 19.55, 17.15, 10.13, 14.01, 16.22, 20.47, 14.95, 14.77, 18.2, 16.53, 20.21, 15.45, 13.32, 17.58, 15.53, 19.49, 17.49, 18.59, 21.45, 16.31, 14.14, 19.8, 13.96, 18.85, 15.64, 12.17, 19.97, 14.16, 19.24, 16.73, 19.42, 16.34, 9.95, 16.96, 15.42, 15.32, 21.43, 15.06, 17.03, 18.69, 13.81, 15.56, 16.83, 15.44, 15.63, 12.12, 20.4, 14.08, 13.68, 18.89, 14.38, 16.64, 15.58, 19.26, 18.94, 14.88, 16.78, 14.7, 12.44, 18.74, 14.39, 16.73, 15.21, 18.97, 19.67, 17.74, 17.27, 14.9, 21.73, 13.74, 13.27, 19.7, 17.05, 19.96, 16.0, 15.99, 19.84, 13.66, 15.46, 14.65, 16.39, 13.97, 17.05, 14.93, 20.24, 19.87, 15.39, 15.51, 15.72, 14.09, 13.95, 13.45, 12.23, 14.22, 18.61, 13.03, 18.55, 14.06, 18.5, 14.37, 17.24, 17.31, 24.47, 18.75, 15.97, 14.58, 14.8, 20.9, 19.26, 17.37, 22.83, 14.65, 17.96, 13.38, 15.1, 16.52, 16.83, 17.3, 16.88, 11.48, 13.22, 17.26, 14.45, 13.15, 16.12, 11.63, 15.07, 24.86, 20.11, 17.75, 16.38, 15.72, 18.57, 14.96, 22.81, 14.0, 14.6, 13.77, 17.13, 15.43, 23.38, 13.45, 18.1, 16.73, 18.13, 16.75, 18.81, 14.77, 19.64, 19.1, 13.34, 15.67, 15.5, 16.96, 18.34, 18.65, 15.54, 19.86, 14.98]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load backup\n",
        "\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "\n",
        "for area_num in [0,1,2]:\n",
        "  for fold in [0,1,2,3,4]:\n",
        "      backup_PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_backup_RepVGGA2.pth\"\n",
        "      main_PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "      shutil.copy(backup_PATH, main_PATH)"
      ],
      "metadata": {
        "id": "VEbHbassgvrf"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "# カラムがないindexだけ設定されている\n",
        "# DataFrameを作成\n",
        "df = pd.DataFrame(index=[], columns=[])\n",
        "\n",
        "#Define dataset\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "#Interference\n",
        "with torch.inference_mode():\n",
        "    targets = []\n",
        "    for image_tensor, target in test_loader:  \n",
        "            target = target.view(len(target), 1)         \n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device) \n",
        "            targets.append(target[0].item())\n",
        "    df['targets'] = targets\n",
        "\n",
        "FOLD = [0,1,2,3,4]\n",
        "AREA = [\"half\", \"periocular\", \"eye\"]\n",
        "for area_num in [0,1,2]:\n",
        "    for fold in FOLD:\n",
        "        model_path = f\"./models_Hertel_estimation/5-fold-crossvalidation/{AREA[area_num]}_fold{str(fold)}_RepVGGA2.pth\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False) \n",
        "        model_ft = mod_RepVGG()\n",
        "        model_ft = model_ft.to(device)\n",
        "        model_ft.load_state_dict(torch.load(model_path))\n",
        "        model_ft.eval() # prep model for evaluation\n",
        "        print(f\"model_path: {model_path}\")\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = []\n",
        "            for image_tensor, target in test_loader:  \n",
        "                  target = target.view(len(target), 1)         \n",
        "                  image_tensor = image_tensor.to(device)\n",
        "                  target = target.to(device)\n",
        "                  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                  output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "                  outputs.append(output[0].item())      \n",
        "        df[f'{AREA[area_num]}_fold{str(fold)}'] = outputs\n",
        "        print(f\"targets: {targets}\")\n",
        "        print(f\"outputs: {my_round(i) for i in outputs}\")\n",
        "\n",
        "#Analysis\n",
        "df_analysis = pd.DataFrame(index=[\"AveError\", \"StdError\", \"AveAbsError\", \"StdAbsError\", \"Corrected_AveAbsError\", \"Corrected_StdAbsError\", \"Corr_coef\", \"<=1mm_rate\", \"<=2mm_rate\", \">2mm_rate\", \">18mm_sensitivity\", \">18mm_specificity\", \">18mm_positive_predictive\", \">18mm_negative_predictive\"], columns=df.columns[1:])\n",
        "targets = df['targets']\n",
        "\n",
        "for column in df.columns[1:]:\n",
        "    outputs = df[column]\n",
        "    df_analysis.loc[df_analysis.index[0],column] = statistics.mean(outputs-targets) #AveError\n",
        "    df_analysis.loc[df_analysis.index[1],column] = statistics.stdev(outputs-targets) #StdError\n",
        "    df_analysis.loc[df_analysis.index[2],column] = statistics.mean(abs(outputs-targets)) #AveAbsError\n",
        "    df_analysis.loc[df_analysis.index[3],column] = statistics.stdev(abs(outputs-targets)) #StdAbsError\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_error = (np.array(outputs)-np.array(targets)-np.array(statistics.mean(outputs-targets))).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "    df_analysis.loc[df_analysis.index[4],column] = statistics.mean(corrected_AbsError) #Corrected_AveAbsError\n",
        "    df_analysis.loc[df_analysis.index[5],column] = statistics.stdev(corrected_AbsError) #Corrected_StdAbsError\n",
        "    df_analysis.loc[df_analysis.index[6],column] = np.corrcoef(outputs, targets)[0,1] #Corr_coef\n",
        "    total = len(df)\n",
        "    within1 = sum((i <= 1 and i >= -1 for i in outputs-targets))\n",
        "    within2 = sum((i <= 2 and i >= -2 for i in outputs-targets))\n",
        "    over2 = sum((i > 2 or i < -2 for i in outputs-targets))\n",
        "\n",
        "    df_analysis.loc[df_analysis.index[7],column] = my_round(within1/total*100) #<=1mm_rate\n",
        "    df_analysis.loc[df_analysis.index[8],column] = my_round(within2/total*100) #<=2mm_rate\n",
        "    df_analysis.loc[df_analysis.index[9],column] = my_round(over2/total*100) #>2mm_rate\n",
        "\n",
        "    TP, FP, TN, FN = 0,0,0,0\n",
        "    for i in range(len(df)):\n",
        "      if df[\"targets\"][i]>=18 and df[column][i]>= 18:\n",
        "          TP += 1\n",
        "      if df[\"targets\"][i]<18 and df[column][i]>= 18:\n",
        "          FP += 1\n",
        "      if df[\"targets\"][i]>=18 and df[column][i]< 18:\n",
        "          FN += 1 \n",
        "      if df[\"targets\"][i]<18 and df[column][i]< 18:\n",
        "          TN += 1    \n",
        "\n",
        "    df_analysis.loc[df_analysis.index[10],column] = TP/(TP+FN) #Sensitivity\n",
        "    df_analysis.loc[df_analysis.index[11],column] = TN/(FP+TN) #Specificity\n",
        "    df_analysis.loc[df_analysis.index[12],column] = TP/(TP+FP) #Positive predictive value\n",
        "    df_analysis.loc[df_analysis.index[13],column] = TN/(TN+FN) #Negative predictive value\n",
        "\n",
        "df.to_csv( f\"./models_Hertel_estimation/5-fold-crossvalidation/result.csv\", header=True, index=False)\n",
        "df_analysis.to_csv( f\"./models_Hertel_estimation/5-fold-crossvalidation/analysis.csv\", header=True, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_mo_HU99r-",
        "outputId": "fd167e24-2408-46d4-93b4-00088ec24043"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.378623008728027, 16.52786636352539, 14.41368293762207, 17.310123443603516, 18.193490982055664, 18.63250732421875, 15.866581916809082, 19.918441772460938, 14.061344146728516, 15.13662338256836, 14.522603034973145, 14.548233985900879, 14.629607200622559, 11.67783260345459, 17.516704559326172, 17.708431243896484, 15.047475814819336, 15.46951961517334, 15.383627891540527, 21.722124099731445, 16.031721115112305, 19.10263442993164, 17.255619049072266, 12.973820686340332, 17.27155876159668, 14.486808776855469, 17.736249923706055, 18.7500057220459, 12.000103950500488, 16.01093864440918, 13.4608793258667, 17.0961971282959, 15.659000396728516, 15.311763763427734, 18.674848556518555, 15.063380241394043, 15.929156303405762, 19.954532623291016, 17.015457153320312, 9.10715389251709, 14.499024391174316, 17.65038299560547, 22.163698196411133, 15.29515266418457, 14.998238563537598, 19.632640838623047, 17.370023727416992, 19.54566764831543, 15.270207405090332, 13.529583930969238, 18.156003952026367, 16.60053253173828, 17.71754264831543, 17.804229736328125, 16.788042068481445, 19.31800651550293, 17.94780731201172, 14.775107383728027, 19.745101928710938, 15.801980018615723, 19.627504348754883, 15.810635566711426, 12.446627616882324, 19.80118179321289, 15.081377029418945, 18.222949981689453, 16.552791595458984, 19.876670837402344, 16.88095474243164, 8.981207847595215, 15.718888282775879, 17.429861068725586, 14.434524536132812, 17.742685317993164, 15.639605522155762, 18.62410545349121, 17.0516300201416, 15.350199699401855, 16.61648941040039, 16.53133201599121, 14.99679183959961, 15.90589714050293, 13.083527565002441, 18.558292388916016, 14.751753807067871, 15.031128883361816, 18.196517944335938, 14.259568214416504, 16.35134506225586, 14.850818634033203, 19.14324188232422, 18.617835998535156, 14.807503700256348, 16.382083892822266, 14.908904075622559, 13.823689460754395, 20.060216903686523, 13.181025505065918, 15.028328895568848, 15.086997032165527, 18.63804817199707, 18.86446189880371, 17.09891128540039, 16.447002410888672, 15.36043643951416, 21.297897338867188, 13.352775573730469, 14.025788307189941, 19.878787994384766, 15.984419822692871, 18.780916213989258, 15.898146629333496, 15.396921157836914, 20.41539764404297, 14.348152160644531, 17.765886306762695, 15.19423770904541, 16.752168655395508, 14.79985237121582, 16.475553512573242, 15.098559379577637, 18.291595458984375, 20.241252899169922, 13.412836074829102, 15.20240592956543, 15.882224082946777, 14.869064331054688, 14.124470710754395, 15.249518394470215, 12.7532377243042, 15.445794105529785, 19.059650421142578, 12.285660743713379, 17.694236755371094, 14.440678596496582, 18.87700653076172, 13.531987190246582, 18.148500442504883, 17.245813369750977, 22.981985092163086, 18.420778274536133, 15.622040748596191, 16.74179458618164, 15.908775329589844, 21.565780639648438, 18.193138122558594, 15.771754264831543, 21.753461837768555, 14.74777603149414, 18.115503311157227, 14.342243194580078, 14.59882640838623, 15.722517967224121, 16.184432983398438, 18.545658111572266, 18.50202178955078, 13.285330772399902, 14.19869613647461, 19.245588302612305, 14.737025260925293, 12.756974220275879, 15.713203430175781, 11.717183113098145, 16.72288703918457, 23.57969856262207, 19.94176483154297, 17.85376739501953, 17.772357940673828, 15.123563766479492, 18.14637565612793, 15.679877281188965, 20.682327270507812, 14.081783294677734, 15.283907890319824, 15.16957950592041, 16.601205825805664, 16.17353630065918, 20.799650192260742, 13.54210090637207, 17.73057746887207, 17.29668617248535, 18.988353729248047, 17.62610626220703, 17.40579605102539, 14.868840217590332, 20.62948226928711, 18.606708526611328, 14.855022430419922, 14.243762969970703, 14.652841567993164, 17.87848663330078, 16.332292556762695, 18.421607971191406, 15.132609367370605, 19.492591857910156, 15.496404647827148]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.685627937316895, 17.42046356201172, 15.394675254821777, 20.631778717041016, 18.763925552368164, 20.075674057006836, 14.374516487121582, 20.9547061920166, 13.705263137817383, 17.78512191772461, 15.791290283203125, 14.0407075881958, 15.688864707946777, 10.838789939880371, 20.553876876831055, 16.385679244995117, 14.518665313720703, 17.0823917388916, 15.075350761413574, 21.975379943847656, 16.109420776367188, 17.056438446044922, 18.926837921142578, 15.818367004394531, 19.92437171936035, 13.468585014343262, 19.385244369506836, 17.519140243530273, 11.165142059326172, 18.640636444091797, 12.299351692199707, 17.247943878173828, 15.80007553100586, 17.195402145385742, 17.429712295532227, 16.471708297729492, 11.7498140335083, 23.259424209594727, 18.171274185180664, 9.802298545837402, 17.556055068969727, 19.351572036743164, 24.172239303588867, 13.52307415008545, 14.55107593536377, 20.71548080444336, 18.67122459411621, 22.4290828704834, 16.172794342041016, 13.393477439880371, 19.980134963989258, 17.262775421142578, 19.299875259399414, 19.396787643432617, 17.143146514892578, 20.99727439880371, 18.202932357788086, 16.087587356567383, 20.208600997924805, 15.065241813659668, 20.15486717224121, 17.5537109375, 14.410252571105957, 18.163043975830078, 15.295361518859863, 18.54176139831543, 17.515214920043945, 20.514747619628906, 16.031755447387695, 10.203211784362793, 16.137630462646484, 17.173768997192383, 14.826165199279785, 20.352535247802734, 15.701773643493652, 20.47845458984375, 19.490272521972656, 17.084430694580078, 16.891801834106445, 14.78773021697998, 16.58159065246582, 15.523425102233887, 12.930374145507812, 20.788131713867188, 13.908798217773438, 15.114770889282227, 18.886425018310547, 15.745381355285645, 16.33323097229004, 16.068042755126953, 20.630027770996094, 19.04789161682129, 17.258949279785156, 19.78268814086914, 15.846945762634277, 15.2092866897583, 19.21036720275879, 13.51293659210205, 17.99258041381836, 15.615656852722168, 21.176109313964844, 19.417205810546875, 18.633390426635742, 17.879697799682617, 16.078901290893555, 21.585948944091797, 14.59451675415039, 15.484532356262207, 20.9012393951416, 18.25565528869629, 20.032724380493164, 16.77989959716797, 16.101024627685547, 20.575958251953125, 15.434422492980957, 16.26717185974121, 13.312357902526855, 18.511625289916992, 15.311362266540527, 16.91718864440918, 15.376578330993652, 18.744356155395508, 20.047887802124023, 13.860312461853027, 14.45983600616455, 15.612879753112793, 15.536246299743652, 16.08750343322754, 15.971235275268555, 12.835464477539062, 15.192214012145996, 17.987600326538086, 12.982884407043457, 19.089067459106445, 14.76714038848877, 21.08924102783203, 15.184554100036621, 21.264230728149414, 17.335248947143555, 23.23272132873535, 17.791379928588867, 17.187463760375977, 17.009197235107422, 17.138792037963867, 21.541309356689453, 19.95207977294922, 17.9904842376709, 23.090391159057617, 15.262019157409668, 17.656206130981445, 13.649552345275879, 15.131998062133789, 18.015634536743164, 16.9038028717041, 19.382165908813477, 18.708866119384766, 13.485398292541504, 14.919567108154297, 18.93229103088379, 16.687753677368164, 11.964728355407715, 15.782405853271484, 12.89645004272461, 17.005983352661133, 21.654157638549805, 19.453693389892578, 17.711685180664062, 17.396465301513672, 16.71466636657715, 19.72669792175293, 15.947832107543945, 21.040084838867188, 16.316137313842773, 14.36103630065918, 13.831416130065918, 17.01429557800293, 17.417570114135742, 23.42449378967285, 13.806044578552246, 18.939525604248047, 19.056640625, 19.46031951904297, 18.111705780029297, 18.618667602539062, 15.925675392150879, 21.309982299804688, 21.710973739624023, 14.477090835571289, 15.850629806518555, 15.439577102661133, 18.30236053466797, 18.5112361907959, 19.502391815185547, 16.224700927734375, 22.159860610961914, 16.312719345092773]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.294028282165527, 18.572322845458984, 13.035701751708984, 17.513378143310547, 18.263946533203125, 20.37727928161621, 13.856710433959961, 21.11419105529785, 13.044377326965332, 16.808433532714844, 15.759886741638184, 11.96503734588623, 16.740272521972656, 9.319304466247559, 18.36231803894043, 14.85970401763916, 13.082019805908203, 15.00998592376709, 14.994046211242676, 23.327999114990234, 15.816393852233887, 17.62160301208496, 18.987754821777344, 10.53676986694336, 18.244998931884766, 11.514981269836426, 17.83156967163086, 18.65824317932129, 10.432534217834473, 16.73796844482422, 12.73023509979248, 17.533447265625, 14.273402214050293, 15.02004337310791, 18.653074264526367, 13.893177032470703, 14.19064712524414, 21.624433517456055, 17.846904754638672, 7.524720668792725, 15.800036430358887, 17.880340576171875, 22.358863830566406, 13.151304244995117, 12.997133255004883, 20.0286922454834, 16.876211166381836, 22.122697830200195, 16.527843475341797, 10.963497161865234, 19.242185592651367, 15.227246284484863, 18.949003219604492, 16.465360641479492, 16.95537567138672, 19.663721084594727, 16.3270320892334, 14.20238971710205, 19.859838485717773, 15.927910804748535, 19.572160720825195, 15.826330184936523, 11.627754211425781, 17.045841217041016, 15.540390014648438, 18.913450241088867, 17.166183471679688, 19.687992095947266, 15.664323806762695, 8.664714813232422, 17.399063110351562, 14.670510292053223, 16.57251739501953, 20.306264877319336, 14.92104434967041, 18.657926559448242, 18.934885025024414, 14.866443634033203, 15.924696922302246, 15.255507469177246, 15.3527250289917, 15.10274600982666, 10.683826446533203, 20.482177734375, 13.734552383422852, 13.772435188293457, 18.497211456298828, 13.767361640930176, 17.286863327026367, 15.1731538772583, 20.109546661376953, 18.04470443725586, 15.959424018859863, 15.386101722717285, 13.861212730407715, 13.986428260803223, 18.404138565063477, 12.350111961364746, 16.9393253326416, 14.360968589782715, 18.80783462524414, 18.168188095092773, 18.321386337280273, 16.542421340942383, 15.59028148651123, 20.642148971557617, 13.410445213317871, 13.311966896057129, 19.074676513671875, 14.924376487731934, 19.728315353393555, 16.388227462768555, 16.51860237121582, 17.751497268676758, 13.682901382446289, 15.677870750427246, 11.530806541442871, 17.43984603881836, 13.884873390197754, 17.14021873474121, 14.634631156921387, 18.1943302154541, 19.125957489013672, 14.856524467468262, 15.37302017211914, 14.610224723815918, 14.549210548400879, 13.799225807189941, 14.473753929138184, 10.760090827941895, 13.986918449401855, 18.044706344604492, 9.747101783752441, 17.192537307739258, 13.867667198181152, 21.0787410736084, 13.745651245117188, 19.884721755981445, 16.987470626831055, 22.106229782104492, 18.692806243896484, 15.563935279846191, 14.956961631774902, 16.15313148498535, 22.8781795501709, 19.559202194213867, 15.27631664276123, 22.704580307006836, 13.843302726745605, 17.728837966918945, 15.713217735290527, 15.590768814086914, 15.96504020690918, 14.983272552490234, 17.9105281829834, 16.648998260498047, 11.954937934875488, 11.24239444732666, 16.93167495727539, 15.10203742980957, 12.773539543151855, 16.82803726196289, 9.00130844116211, 16.347675323486328, 23.531755447387695, 16.728208541870117, 17.491310119628906, 17.650468826293945, 15.984318733215332, 18.476333618164062, 14.104043006896973, 21.996137619018555, 14.236873626708984, 15.049790382385254, 12.465229988098145, 16.862167358398438, 16.055334091186523, 21.556377410888672, 11.33893871307373, 18.355873107910156, 19.00969123840332, 19.13858985900879, 16.890810012817383, 17.57979393005371, 13.58545207977295, 22.54749870300293, 19.252286911010742, 13.823819160461426, 14.578340530395508, 14.4834566116333, 16.927152633666992, 16.109682083129883, 19.346492767333984, 15.771391868591309, 20.409103393554688, 13.045690536499023]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.973372459411621, 18.026185989379883, 15.077651023864746, 18.86676597595215, 18.002565383911133, 19.13922882080078, 14.705296516418457, 19.959184646606445, 14.15832805633545, 16.99224281311035, 16.06154441833496, 13.018007278442383, 15.920527458190918, 12.40735149383545, 20.199848175048828, 18.968015670776367, 14.970242500305176, 16.953378677368164, 14.01838207244873, 23.09086799621582, 15.65557861328125, 17.788414001464844, 20.596418380737305, 13.9351224899292, 18.05284881591797, 12.488697052001953, 18.32924461364746, 18.325761795043945, 12.097526550292969, 18.007343292236328, 12.924223899841309, 18.622045516967773, 14.578097343444824, 16.36762809753418, 19.7940673828125, 16.2828311920166, 14.377903938293457, 20.01300811767578, 19.292268753051758, 10.926050186157227, 15.371420860290527, 17.638900756835938, 20.693138122558594, 15.168266296386719, 13.976495742797852, 20.496227264404297, 17.012008666992188, 20.139862060546875, 16.08322525024414, 12.996195793151855, 18.312149047851562, 14.840694427490234, 17.24205780029297, 18.109066009521484, 16.729162216186523, 20.87147331237793, 16.791549682617188, 14.481209754943848, 18.580120086669922, 16.535432815551758, 20.170289993286133, 18.0981502532959, 13.825035095214844, 17.733816146850586, 15.066266059875488, 18.605051040649414, 19.798036575317383, 19.829267501831055, 16.272443771362305, 10.06800365447998, 16.67764663696289, 14.019112586975098, 14.204305648803711, 18.540132522583008, 14.789254188537598, 16.123985290527344, 18.42367935180664, 13.656182289123535, 16.594709396362305, 15.952615737915039, 15.377994537353516, 14.564447402954102, 13.097983360290527, 20.99506187438965, 14.342482566833496, 15.060906410217285, 17.204891204833984, 15.342570304870605, 17.012784957885742, 16.000347137451172, 17.628562927246094, 18.261035919189453, 15.707124710083008, 19.156274795532227, 14.99905776977539, 13.858667373657227, 17.22591209411621, 13.17465877532959, 16.271934509277344, 14.364261627197266, 17.325092315673828, 19.343379974365234, 18.94817543029785, 18.590280532836914, 15.930054664611816, 19.96697425842285, 15.585615158081055, 14.626474380493164, 19.885807037353516, 16.602781295776367, 19.836271286010742, 16.195053100585938, 15.145787239074707, 18.864242553710938, 13.65738582611084, 16.346952438354492, 13.821134567260742, 17.924598693847656, 13.584967613220215, 16.556529998779297, 14.272133827209473, 18.585718154907227, 18.768213272094727, 13.390032768249512, 14.631547927856445, 15.140519142150879, 13.131105422973633, 15.121426582336426, 15.020272254943848, 12.127372741699219, 13.264548301696777, 16.933944702148438, 12.25484848022461, 16.906251907348633, 15.243021965026855, 20.634471893310547, 13.876118659973145, 19.032615661621094, 16.680484771728516, 21.15937042236328, 18.07735252380371, 16.84624481201172, 17.064258575439453, 15.315886497497559, 20.558395385742188, 19.45096778869629, 17.27347183227539, 21.541675567626953, 17.112844467163086, 16.61021614074707, 14.653938293457031, 13.863336563110352, 17.059730529785156, 15.870844841003418, 17.776884078979492, 17.161611557006836, 12.597207069396973, 13.576180458068848, 18.611196517944336, 15.399812698364258, 12.9368314743042, 15.3995943069458, 11.45610523223877, 13.626843452453613, 22.60971450805664, 17.508716583251953, 16.810426712036133, 17.710220336914062, 15.498319625854492, 18.572832107543945, 14.999710083007812, 21.23410415649414, 13.721917152404785, 16.290925979614258, 13.404501914978027, 17.09446144104004, 16.36295509338379, 21.416650772094727, 14.050797462463379, 18.75776481628418, 18.744556427001953, 19.560941696166992, 17.524707794189453, 18.059497833251953, 15.44002628326416, 21.798948287963867, 19.713871002197266, 14.630529403686523, 14.83313274383545, 16.62202262878418, 16.97804069519043, 16.466678619384766, 18.655588150024414, 16.42499351501465, 19.957969665527344, 15.777009963989258]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/half_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.123014450073242, 17.61446189880371, 14.736662864685059, 18.29134178161621, 18.58228874206543, 20.99728012084961, 17.762205123901367, 21.32840919494629, 13.66073226928711, 15.816253662109375, 15.657649993896484, 14.617029190063477, 15.881574630737305, 11.048604965209961, 19.68118667602539, 17.258399963378906, 14.868305206298828, 14.858942031860352, 14.425630569458008, 24.661571502685547, 17.09063148498535, 18.857196807861328, 18.632953643798828, 11.171300888061523, 17.481569290161133, 13.68846607208252, 18.74755096435547, 18.970346450805664, 10.197731018066406, 17.60039710998535, 12.861663818359375, 18.955291748046875, 14.725208282470703, 16.04149055480957, 18.402610778808594, 14.372045516967773, 11.620864868164062, 22.180673599243164, 16.22934913635254, 8.608464241027832, 16.679574966430664, 20.05620574951172, 19.15794563293457, 15.430213928222656, 15.119220733642578, 20.264244079589844, 17.729921340942383, 22.100269317626953, 17.036819458007812, 12.773609161376953, 19.839521408081055, 16.934450149536133, 18.199464797973633, 19.420011520385742, 16.026023864746094, 21.455596923828125, 18.988744735717773, 14.054085731506348, 19.65781021118164, 17.14971923828125, 18.956127166748047, 16.370750427246094, 13.439529418945312, 18.545793533325195, 13.271459579467773, 18.408512115478516, 19.634185791015625, 19.764217376708984, 15.212617874145508, 9.997062683105469, 15.042619705200195, 15.954158782958984, 12.455984115600586, 20.29118537902832, 14.881082534790039, 18.74568748474121, 19.74477767944336, 15.348876953125, 17.226165771484375, 16.019878387451172, 16.114652633666992, 15.405523300170898, 11.153977394104004, 20.450191497802734, 13.000732421875, 14.34957504272461, 18.88159942626953, 15.208616256713867, 17.12103843688965, 15.291598320007324, 20.020170211791992, 17.29926872253418, 16.713693618774414, 17.9666748046875, 14.759366989135742, 13.026795387268066, 20.68099021911621, 13.695222854614258, 15.652616500854492, 17.624975204467773, 20.200136184692383, 18.921672821044922, 17.69270896911621, 18.1572322845459, 15.799951553344727, 20.772735595703125, 13.877558708190918, 12.615043640136719, 20.103422164916992, 16.294740676879883, 18.44874382019043, 15.727386474609375, 18.067350387573242, 21.18055534362793, 14.457260131835938, 15.458024024963379, 12.00967788696289, 16.3638858795166, 14.753664016723633, 17.689756393432617, 16.05655288696289, 18.458768844604492, 18.106382369995117, 13.885411262512207, 15.403196334838867, 15.736252784729004, 16.442209243774414, 14.210649490356445, 16.120718002319336, 13.712823867797852, 14.465387344360352, 17.625566482543945, 11.421159744262695, 18.042591094970703, 15.077798843383789, 21.063846588134766, 13.902111053466797, 18.862613677978516, 16.994375228881836, 23.60187530517578, 17.57231903076172, 14.765181541442871, 16.84087562561035, 16.19773292541504, 22.4685115814209, 19.928667068481445, 16.205570220947266, 24.161609649658203, 14.330639839172363, 15.988777160644531, 14.625059127807617, 14.17895793914795, 16.794769287109375, 16.622766494750977, 19.394763946533203, 18.250038146972656, 12.949023246765137, 14.83523941040039, 19.819711685180664, 15.920429229736328, 14.169471740722656, 15.364683151245117, 10.730436325073242, 16.67903709411621, 25.51227378845215, 18.61932373046875, 17.227378845214844, 18.568296432495117, 15.894736289978027, 19.16511344909668, 15.03891372680664, 22.955541610717773, 14.920562744140625, 15.81346321105957, 13.580337524414062, 17.41197395324707, 17.63642120361328, 22.64254379272461, 14.72767448425293, 19.612285614013672, 18.000356674194336, 19.348114013671875, 17.86394691467285, 16.60215950012207, 16.4480037689209, 22.23603057861328, 23.11817741394043, 13.599231719970703, 14.790434837341309, 14.280610084533691, 18.88009262084961, 17.397279739379883, 20.087976455688477, 15.88846206665039, 20.678409576416016, 15.306217193603516]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.628880500793457, 16.501270294189453, 15.614463806152344, 17.55476951599121, 18.36882972717285, 20.834209442138672, 14.463509559631348, 22.539968490600586, 14.519746780395508, 16.999086380004883, 14.248920440673828, 12.243545532226562, 16.18368148803711, 13.0444917678833, 20.988750457763672, 16.944719314575195, 14.516607284545898, 16.724971771240234, 13.6224365234375, 24.63283920288086, 17.300662994384766, 18.164100646972656, 19.612594604492188, 13.13848876953125, 19.386703491210938, 13.913792610168457, 19.045211791992188, 18.71436882019043, 11.144414901733398, 16.610076904296875, 12.026237487792969, 17.720115661621094, 14.966217994689941, 16.786741256713867, 18.10673713684082, 14.242183685302734, 16.791940689086914, 20.115894317626953, 18.455141067504883, 8.628554344177246, 16.511865615844727, 17.829126358032227, 24.3601016998291, 14.536940574645996, 13.72374153137207, 20.532089233398438, 18.51152992248535, 18.35003662109375, 15.305883407592773, 13.597820281982422, 19.312429428100586, 14.63401985168457, 18.000789642333984, 19.533716201782227, 17.203479766845703, 21.098987579345703, 17.828664779663086, 14.95236587524414, 20.84958839416504, 18.568817138671875, 19.014236450195312, 17.28803062438965, 11.71188735961914, 20.058847427368164, 14.965826034545898, 19.236888885498047, 17.01384735107422, 20.69869613647461, 14.150228500366211, 9.371231079101562, 16.476987838745117, 15.556892395019531, 12.669462203979492, 21.281702041625977, 14.29304027557373, 20.532947540283203, 18.788286209106445, 15.714655876159668, 18.73544692993164, 16.90194320678711, 14.76201343536377, 15.423151016235352, 12.93288803100586, 19.307186126708984, 16.054569244384766, 15.037433624267578, 19.088054656982422, 14.349668502807617, 15.839384078979492, 15.810497283935547, 20.493274688720703, 19.084529876708984, 15.676069259643555, 19.761394500732422, 15.704676628112793, 14.078361511230469, 19.513662338256836, 13.149682998657227, 16.493560791015625, 15.236845970153809, 20.443294525146484, 20.606117248535156, 18.48610496520996, 17.086639404296875, 16.262113571166992, 20.57158851623535, 15.040571212768555, 14.965826034545898, 19.65793800354004, 17.8940372467041, 18.66118812561035, 17.617300033569336, 14.733345031738281, 20.319644927978516, 14.919414520263672, 17.299556732177734, 14.329510688781738, 19.03112030029297, 15.764261245727539, 16.671846389770508, 16.051395416259766, 18.78145408630371, 19.47138023376465, 13.772001266479492, 12.901975631713867, 16.17322540283203, 15.145328521728516, 14.264853477478027, 15.480840682983398, 11.667553901672363, 13.55410385131836, 17.995027542114258, 12.836796760559082, 17.358808517456055, 14.327374458312988, 20.852699279785156, 14.301982879638672, 19.788206100463867, 17.735214233398438, 23.798873901367188, 18.695293426513672, 17.672035217285156, 17.920730590820312, 16.28173828125, 22.660545349121094, 20.616031646728516, 18.607219696044922, 22.267650604248047, 13.261963844299316, 17.013484954833984, 13.371374130249023, 12.852365493774414, 18.88450813293457, 17.275203704833984, 19.486778259277344, 18.56671142578125, 11.700385093688965, 13.961906433105469, 19.462013244628906, 15.805330276489258, 12.555597305297852, 16.791475296020508, 10.44202995300293, 16.878829956054688, 24.814273834228516, 19.364696502685547, 16.79605484008789, 17.802295684814453, 16.68451690673828, 18.36846923828125, 14.553293228149414, 21.242752075195312, 14.955633163452148, 14.513534545898438, 13.84214973449707, 17.766368865966797, 16.1435489654541, 22.017375946044922, 11.843202590942383, 17.93244171142578, 18.300846099853516, 19.540973663330078, 17.392154693603516, 18.458616256713867, 15.997106552124023, 20.572357177734375, 20.311004638671875, 13.656415939331055, 15.031106948852539, 16.630512237548828, 18.34473419189453, 18.765438079833984, 17.83807373046875, 16.716594696044922, 21.200632095336914, 15.312068939208984]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.5079984664917, 16.867992401123047, 16.265605926513672, 19.608226776123047, 18.018054962158203, 19.68177604675293, 14.21727180480957, 20.494874954223633, 13.075567245483398, 16.61208724975586, 15.31358528137207, 13.441017150878906, 15.412988662719727, 11.104788780212402, 20.506330490112305, 16.111366271972656, 15.281560897827148, 16.515634536743164, 13.988466262817383, 21.62482261657715, 15.543172836303711, 18.33778953552246, 18.230295181274414, 14.073351860046387, 18.547815322875977, 10.742637634277344, 18.828514099121094, 17.978839874267578, 11.647454261779785, 17.198915481567383, 12.527395248413086, 18.1173038482666, 16.003679275512695, 15.626899719238281, 17.72167205810547, 15.473936080932617, 10.310550689697266, 22.307640075683594, 18.710060119628906, 8.36611270904541, 16.411033630371094, 17.749088287353516, 23.93586540222168, 15.247783660888672, 12.739313125610352, 19.959583282470703, 18.333343505859375, 20.61050033569336, 15.397140502929688, 13.18718147277832, 17.4136905670166, 16.04557991027832, 18.883317947387695, 20.12125015258789, 17.416316986083984, 22.095233917236328, 18.486780166625977, 14.356369018554688, 20.947172164916992, 15.058387756347656, 18.218278884887695, 17.221248626708984, 11.583888053894043, 18.654970169067383, 14.932250022888184, 19.314754486083984, 17.08732795715332, 20.213478088378906, 15.252031326293945, 8.508332252502441, 16.433208465576172, 16.039588928222656, 13.514440536499023, 18.8465633392334, 15.803937911987305, 19.18789291381836, 19.020282745361328, 15.494651794433594, 15.646785736083984, 13.890096664428711, 14.857765197753906, 14.630256652832031, 14.319543838500977, 19.159975051879883, 13.65890121459961, 13.762219429016113, 18.571500778198242, 15.36823844909668, 15.5302095413208, 15.943931579589844, 18.158710479736328, 18.789234161376953, 15.428616523742676, 19.55048942565918, 14.686827659606934, 13.71535873413086, 18.110864639282227, 13.16370964050293, 15.355535507202148, 15.40560531616211, 20.92520523071289, 19.17913818359375, 17.939966201782227, 16.629871368408203, 14.50870132446289, 21.691190719604492, 14.198186874389648, 14.932250022888184, 20.4349422454834, 16.809717178344727, 19.892614364624023, 17.375398635864258, 17.48061180114746, 19.803224563598633, 15.733963012695312, 15.068815231323242, 13.002659797668457, 17.739795684814453, 14.384544372558594, 17.413421630859375, 14.597667694091797, 18.53614616394043, 16.831235885620117, 13.456437110900879, 13.784709930419922, 14.506193161010742, 15.654291152954102, 15.098917007446289, 14.984310150146484, 11.085660934448242, 14.14549446105957, 17.922344207763672, 11.608201026916504, 18.47379493713379, 13.528829574584961, 21.062891006469727, 14.15269660949707, 22.172639846801758, 17.258974075317383, 23.40140724182129, 18.94765853881836, 16.536582946777344, 16.81882667541504, 17.17214012145996, 19.723119735717773, 21.104028701782227, 16.402576446533203, 23.226455688476562, 13.529705047607422, 17.24184799194336, 14.26577377319336, 12.520601272583008, 16.890113830566406, 16.146081924438477, 18.61724090576172, 16.10960578918457, 13.286693572998047, 14.3929443359375, 19.287527084350586, 15.858692169189453, 11.420494079589844, 14.627211570739746, 13.060412406921387, 15.923225402832031, 19.40048599243164, 17.110109329223633, 17.772554397583008, 16.039775848388672, 15.717625617980957, 18.775405883789062, 15.235319137573242, 21.090660095214844, 15.031363487243652, 14.54934310913086, 12.816130638122559, 18.51686668395996, 15.132627487182617, 22.02104377746582, 12.967569351196289, 17.4781494140625, 18.260881423950195, 19.265949249267578, 16.650348663330078, 17.565906524658203, 14.989971160888672, 20.097320556640625, 20.28706169128418, 14.540446281433105, 15.618595123291016, 14.993143081665039, 17.721202850341797, 17.932435989379883, 18.12035369873047, 16.471412658691406, 20.7901554107666, 14.831355094909668]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.967015266418457, 17.573963165283203, 14.597241401672363, 17.5749454498291, 20.73162078857422, 20.667869567871094, 15.651177406311035, 20.87091064453125, 12.439370155334473, 16.711814880371094, 15.00432014465332, 11.864726066589355, 16.60521125793457, 9.554596900939941, 20.287525177001953, 15.687928199768066, 14.178105354309082, 15.868102073669434, 13.342361450195312, 26.17813491821289, 18.012842178344727, 16.61441993713379, 19.568744659423828, 12.837631225585938, 18.66489601135254, 11.333971977233887, 19.0009708404541, 18.249095916748047, 10.341166496276855, 16.89817237854004, 13.294837951660156, 17.10934066772461, 15.57340145111084, 14.794608116149902, 15.507353782653809, 14.582947731018066, 13.376885414123535, 21.779460906982422, 19.098073959350586, 9.780136108398438, 17.10638999938965, 17.225000381469727, 25.646303176879883, 13.697690963745117, 13.16601848602295, 19.151796340942383, 19.476655960083008, 22.435775756835938, 15.044632911682129, 12.2256441116333, 16.55596923828125, 16.711261749267578, 18.719837188720703, 16.654277801513672, 16.558975219726562, 21.97821044921875, 17.163084030151367, 13.215173721313477, 19.59342384338379, 19.007841110229492, 20.199995040893555, 16.823379516601562, 11.604568481445312, 18.28429412841797, 15.921086311340332, 20.08814811706543, 17.908185958862305, 19.13729476928711, 14.023491859436035, 9.18355941772461, 16.74055290222168, 18.462615966796875, 15.623627662658691, 19.67105484008789, 15.697815895080566, 17.729475021362305, 20.144550323486328, 13.317634582519531, 14.803500175476074, 14.856191635131836, 14.44305419921875, 14.869217872619629, 12.85998821258545, 21.12185287475586, 13.343997955322266, 13.383395195007324, 19.181598663330078, 15.072402000427246, 15.563414573669434, 15.80134105682373, 21.165142059326172, 18.05055046081543, 15.740199089050293, 17.3388729095459, 15.323498725891113, 12.626690864562988, 20.363853454589844, 13.181358337402344, 15.43285846710205, 14.37939739227295, 20.987070083618164, 19.21952247619629, 17.923208236694336, 17.02351951599121, 15.887969017028809, 23.02771759033203, 13.693387031555176, 15.921086311340332, 21.051067352294922, 18.089189529418945, 18.039981842041016, 16.898616790771484, 15.910025596618652, 16.190231323242188, 13.988755226135254, 16.353139877319336, 12.132272720336914, 18.06012535095215, 13.940982818603516, 17.718996047973633, 14.442822456359863, 18.0582218170166, 18.785354614257812, 15.024977684020996, 13.944418907165527, 14.7632417678833, 15.889692306518555, 14.92714786529541, 14.353437423706055, 10.026087760925293, 12.829890251159668, 18.686195373535156, 12.469773292541504, 19.05486297607422, 14.093219757080078, 19.97152328491211, 15.04636287689209, 21.414703369140625, 16.933256149291992, 22.48773193359375, 21.89141845703125, 15.20430850982666, 17.851245880126953, 14.160370826721191, 24.719385147094727, 20.246726989746094, 16.470733642578125, 24.333837509155273, 15.098650932312012, 18.80037498474121, 14.608607292175293, 16.15829849243164, 16.73056411743164, 15.229788780212402, 19.11400604248047, 17.245033264160156, 10.854680061340332, 13.37007999420166, 18.394208908081055, 14.890807151794434, 12.787109375, 15.500779151916504, 10.474331855773926, 15.096433639526367, 25.490407943725586, 18.714136123657227, 18.832868576049805, 17.80120277404785, 14.47060775756836, 17.70076560974121, 15.47630786895752, 21.708890914916992, 15.108019828796387, 15.037898063659668, 12.95914363861084, 16.80028533935547, 16.348934173583984, 23.042858123779297, 12.134703636169434, 17.08085823059082, 18.304725646972656, 20.61712646484375, 16.613666534423828, 17.23343276977539, 17.00919532775879, 22.055423736572266, 20.461076736450195, 14.656210899353027, 14.221185684204102, 17.060226440429688, 18.15540885925293, 17.75970458984375, 18.588302612304688, 16.55137825012207, 18.605188369750977, 16.32669448852539]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.757206916809082, 17.4162540435791, 16.31853485107422, 17.91559410095215, 18.140235900878906, 18.8956241607666, 14.593225479125977, 20.251325607299805, 15.904149055480957, 17.889015197753906, 15.345589637756348, 12.637972831726074, 16.222583770751953, 11.319504737854004, 19.25545310974121, 16.75825309753418, 15.758600234985352, 16.486045837402344, 13.869771003723145, 26.11724090576172, 18.382524490356445, 18.743999481201172, 18.702543258666992, 13.603250503540039, 18.857343673706055, 13.03046703338623, 18.59719467163086, 16.872838973999023, 11.78842830657959, 17.616724014282227, 12.608128547668457, 17.165464401245117, 15.68953800201416, 16.10327911376953, 20.388166427612305, 14.620573997497559, 11.281786918640137, 20.058225631713867, 18.763845443725586, 9.999585151672363, 16.519763946533203, 17.677038192749023, 24.353662490844727, 15.836573600769043, 12.730762481689453, 20.360538482666016, 19.37834358215332, 22.209272384643555, 15.68983268737793, 11.552445411682129, 18.82127571105957, 16.084054946899414, 19.084001541137695, 18.881572723388672, 17.568599700927734, 21.728187561035156, 17.82501792907715, 15.35617446899414, 20.56517219543457, 17.639314651489258, 20.947311401367188, 17.132396697998047, 12.158920288085938, 18.650531768798828, 15.54907512664795, 18.985424041748047, 19.691286087036133, 19.770252227783203, 16.22243309020996, 9.49128246307373, 16.651012420654297, 16.250581741333008, 12.887914657592773, 20.078466415405273, 15.171116828918457, 20.14576530456543, 20.997331619262695, 14.997259140014648, 17.198198318481445, 14.477530479431152, 15.017769813537598, 16.035783767700195, 11.596681594848633, 21.137178421020508, 13.660719871520996, 14.028338432312012, 19.331451416015625, 14.509225845336914, 16.138378143310547, 16.602005004882812, 20.488101959228516, 18.005165100097656, 16.58855628967285, 21.197282791137695, 15.33918285369873, 14.807910919189453, 17.4705753326416, 12.802910804748535, 17.649641036987305, 15.444663047790527, 18.58393669128418, 19.41263771057129, 17.134145736694336, 17.988283157348633, 17.24960708618164, 22.271928787231445, 14.259379386901855, 15.54907512664795, 20.817110061645508, 18.57350730895996, 18.80568504333496, 16.80796241760254, 16.836212158203125, 21.68779754638672, 14.334916114807129, 16.31065559387207, 12.887012481689453, 18.14817237854004, 14.21967601776123, 16.108139038085938, 15.375036239624023, 19.258188247680664, 22.47830581665039, 14.645156860351562, 15.591275215148926, 14.773369789123535, 14.365667343139648, 14.58184814453125, 15.948468208312988, 11.56786060333252, 13.284380912780762, 17.383821487426758, 12.479421615600586, 18.505905151367188, 15.135263442993164, 20.810243606567383, 14.899579048156738, 18.543256759643555, 17.917749404907227, 21.82987403869629, 16.626087188720703, 17.08543586730957, 16.888235092163086, 16.425189971923828, 24.156837463378906, 20.441389083862305, 16.072284698486328, 23.796125411987305, 15.034329414367676, 17.830242156982422, 14.222448348999023, 13.204427719116211, 17.35332489013672, 16.782651901245117, 17.588796615600586, 18.036596298217773, 13.055973052978516, 15.026932716369629, 20.953187942504883, 16.850431442260742, 11.825040817260742, 14.602944374084473, 11.758207321166992, 13.964755058288574, 25.403139114379883, 18.465761184692383, 17.723480224609375, 16.655733108520508, 16.271568298339844, 20.35616683959961, 15.347179412841797, 22.004087448120117, 14.847643852233887, 15.637521743774414, 13.540159225463867, 17.21772003173828, 15.554866790771484, 22.51898765563965, 13.193329811096191, 18.046850204467773, 18.50298309326172, 20.384748458862305, 17.136173248291016, 18.920244216918945, 15.642362594604492, 20.51807975769043, 20.58043098449707, 15.798011779785156, 16.396438598632812, 16.2147216796875, 18.658597946166992, 19.999835968017578, 19.190153121948242, 16.688138961791992, 20.71785545349121, 15.811577796936035]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/periocular_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.4871244430542, 15.861027717590332, 14.99499225616455, 18.106992721557617, 19.150447845458984, 19.14997100830078, 17.372560501098633, 20.327512741088867, 13.4711332321167, 16.33707046508789, 13.985804557800293, 13.6044340133667, 16.15695571899414, 11.720357894897461, 19.822994232177734, 17.070749282836914, 12.927437782287598, 16.01647186279297, 13.816732406616211, 22.96803855895996, 16.377370834350586, 18.17534637451172, 17.536195755004883, 13.373225212097168, 16.567916870117188, 12.147717475891113, 17.756919860839844, 18.10204315185547, 11.33570671081543, 19.009506225585938, 12.472092628479004, 17.720928192138672, 15.61447811126709, 16.37620735168457, 17.93293571472168, 13.95741081237793, 11.905852317810059, 20.591259002685547, 16.63351058959961, 9.937102317810059, 16.193164825439453, 17.929847717285156, 18.593772888183594, 15.261174201965332, 12.998941421508789, 20.506061553955078, 17.82306671142578, 22.162458419799805, 15.715986251831055, 12.682955741882324, 19.416414260864258, 16.01807403564453, 18.092538833618164, 19.347694396972656, 16.056961059570312, 20.78993797302246, 18.419475555419922, 15.137986183166504, 20.073389053344727, 16.937702178955078, 20.35578155517578, 16.048351287841797, 12.975930213928223, 17.163869857788086, 13.340388298034668, 18.472522735595703, 18.592529296875, 19.113983154296875, 16.235881805419922, 10.014639854431152, 15.296759605407715, 14.743721961975098, 13.757452964782715, 20.55923843383789, 14.600052833557129, 17.543434143066406, 18.76557159423828, 15.005263328552246, 16.40428352355957, 15.395231246948242, 15.307229995727539, 14.358626365661621, 12.017550468444824, 20.061498641967773, 13.940194129943848, 13.796208381652832, 18.821510314941406, 14.10125732421875, 16.471975326538086, 16.350616455078125, 17.815221786499023, 18.67498779296875, 17.83751106262207, 19.616317749023438, 14.058950424194336, 13.411646842956543, 19.038450241088867, 12.039156913757324, 14.300236701965332, 15.661238670349121, 19.554954528808594, 19.117530822753906, 17.9025936126709, 17.05202865600586, 18.34103012084961, 21.04466438293457, 14.785822868347168, 13.340388298034668, 20.32733154296875, 17.224361419677734, 19.094707489013672, 15.374017715454102, 16.575267791748047, 22.131986618041992, 14.109293937683105, 14.721516609191895, 12.997106552124023, 16.414146423339844, 14.291197776794434, 16.745159149169922, 15.630411148071289, 17.810726165771484, 19.64735984802246, 14.012307167053223, 16.298749923706055, 14.851140022277832, 15.988144874572754, 14.101973533630371, 14.791253089904785, 14.90621566772461, 13.39345645904541, 18.625198364257812, 15.111023902893066, 17.109779357910156, 14.94758129119873, 18.099485397338867, 13.064155578613281, 18.638179779052734, 16.08450698852539, 23.265169143676758, 18.79615020751953, 15.061108589172363, 16.318538665771484, 16.340120315551758, 21.680519104003906, 18.28493881225586, 17.349964141845703, 23.431350708007812, 13.868924140930176, 16.284564971923828, 14.27592945098877, 15.629359245300293, 17.896028518676758, 15.8400239944458, 17.655384063720703, 18.299026489257812, 12.13647747039795, 14.315271377563477, 19.12506866455078, 16.6649169921875, 13.90573787689209, 15.077767372131348, 11.905570030212402, 15.705817222595215, 24.57923126220703, 16.867835998535156, 17.223770141601562, 18.261978149414062, 15.083025932312012, 17.37978172302246, 15.679621696472168, 21.024808883666992, 13.912766456604004, 15.267860412597656, 13.371298789978027, 17.192834854125977, 16.46112060546875, 22.006868362426758, 12.669938087463379, 16.627483367919922, 17.709020614624023, 18.60907554626465, 17.910598754882812, 17.385801315307617, 15.114781379699707, 18.831722259521484, 20.426895141601562, 14.372834205627441, 14.308341026306152, 16.735198974609375, 17.034059524536133, 17.882871627807617, 18.343942642211914, 16.680049896240234, 19.788475036621094, 15.546432495117188]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold0_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.274809837341309, 16.626665115356445, 15.825631141662598, 18.756431579589844, 19.392269134521484, 20.21994400024414, 15.431116104125977, 21.8774356842041, 14.589242935180664, 16.643186569213867, 14.303628921508789, 14.119826316833496, 15.513434410095215, 13.2193603515625, 18.93772315979004, 15.329898834228516, 16.07366180419922, 17.086076736450195, 13.72495174407959, 22.48761558532715, 16.651538848876953, 17.35454750061035, 18.14364242553711, 13.282550811767578, 18.338924407958984, 12.672179222106934, 20.073200225830078, 17.598237991333008, 12.730443954467773, 17.518831253051758, 13.797016143798828, 16.52237892150879, 16.51353645324707, 15.401997566223145, 18.054737091064453, 15.585864067077637, 15.985343933105469, 20.536216735839844, 19.0983829498291, 10.454482078552246, 15.639833450317383, 16.982675552368164, 23.661455154418945, 15.732479095458984, 13.278190612792969, 18.524499893188477, 17.39167594909668, 20.680803298950195, 15.078802108764648, 12.91560173034668, 18.46359634399414, 15.481497764587402, 19.69194984436035, 18.988908767700195, 15.758859634399414, 21.21967887878418, 16.984722137451172, 14.326321601867676, 20.71427345275879, 15.33414077758789, 18.98015594482422, 16.837602615356445, 13.11343002319336, 19.994102478027344, 14.961090087890625, 21.296585083007812, 15.882755279541016, 19.89672088623047, 16.650421142578125, 10.351007461547852, 16.859655380249023, 15.373385429382324, 14.3076171875, 19.931514739990234, 15.098474502563477, 19.284326553344727, 16.942689895629883, 16.56476593017578, 15.01138687133789, 15.622537612915039, 14.881834030151367, 16.94965362548828, 13.443397521972656, 20.798206329345703, 17.450057983398438, 17.2476806640625, 19.830970764160156, 14.654187202453613, 16.844343185424805, 16.105104446411133, 20.06900405883789, 19.09040069580078, 15.969806671142578, 18.485733032226562, 14.598877906799316, 14.34146785736084, 18.9531192779541, 13.846973419189453, 15.74627685546875, 15.764544486999512, 19.511980056762695, 19.714757919311523, 17.917068481445312, 15.957426071166992, 15.917773246765137, 18.358081817626953, 15.118581771850586, 14.263690948486328, 19.927276611328125, 16.964176177978516, 18.858198165893555, 17.255029678344727, 16.688915252685547, 20.199621200561523, 16.20403480529785, 17.10373878479004, 13.749555587768555, 17.072765350341797, 13.916586875915527, 17.47098731994629, 15.204121589660645, 19.284343719482422, 19.243867874145508, 12.747528076171875, 13.906901359558105, 13.831740379333496, 15.718676567077637, 15.293838500976562, 16.046762466430664, 12.849040031433105, 15.215746879577637, 19.36302375793457, 13.132896423339844, 18.483495712280273, 14.752123832702637, 18.42885398864746, 14.234956741333008, 19.059112548828125, 16.107927322387695, 22.569849014282227, 18.427478790283203, 16.30538558959961, 17.719423294067383, 16.123327255249023, 20.864795684814453, 18.713134765625, 16.769784927368164, 22.64167022705078, 15.060113906860352, 17.834590911865234, 13.58540153503418, 12.930793762207031, 16.458749771118164, 15.702285766601562, 17.449748992919922, 17.582544326782227, 12.508692741394043, 14.850593566894531, 19.147783279418945, 15.05573558807373, 12.970701217651367, 15.274019241333008, 10.338088035583496, 16.97749900817871, 23.53719139099121, 20.568317413330078, 16.83361053466797, 18.08001136779785, 15.795303344726562, 18.85988426208496, 16.923879623413086, 21.688631057739258, 15.070233345031738, 15.854618072509766, 13.919865608215332, 18.174470901489258, 17.1445255279541, 22.208351135253906, 13.150398254394531, 15.572854995727539, 16.05307960510254, 19.85159683227539, 17.206157684326172, 20.754474639892578, 15.941125869750977, 20.265886306762695, 20.552671432495117, 15.6389741897583, 15.517135620117188, 16.17490005493164, 17.677072525024414, 20.34652328491211, 18.79205894470215, 15.400311470031738, 18.88775062561035, 14.627168655395508]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold1_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [14.551018714904785, 15.791634559631348, 17.309701919555664, 20.563533782958984, 19.751121520996094, 22.163108825683594, 15.361064910888672, 20.002912521362305, 13.971314430236816, 17.092567443847656, 16.516326904296875, 11.922945022583008, 14.452009201049805, 10.565755844116211, 18.897735595703125, 15.394428253173828, 15.139213562011719, 16.27630043029785, 13.537360191345215, 21.47966766357422, 16.770557403564453, 17.52518653869629, 18.333528518676758, 15.528111457824707, 19.612276077270508, 10.751394271850586, 19.05594253540039, 17.289527893066406, 11.762500762939453, 17.157833099365234, 13.34960651397705, 16.88286018371582, 16.279016494750977, 14.607372283935547, 18.160099029541016, 16.11809539794922, 12.500312805175781, 21.320547103881836, 18.197874069213867, 9.878192901611328, 16.264223098754883, 17.167123794555664, 24.74864387512207, 15.682403564453125, 12.952985763549805, 18.686649322509766, 18.299766540527344, 20.623741149902344, 15.174941062927246, 11.882186889648438, 18.192903518676758, 15.909639358520508, 18.799528121948242, 19.176095962524414, 15.528810501098633, 21.197364807128906, 17.102310180664062, 14.993634223937988, 20.44780158996582, 15.00953197479248, 18.810745239257812, 17.209518432617188, 13.503293991088867, 19.74729347229004, 13.729846000671387, 19.221097946166992, 17.471410751342773, 18.43538475036621, 15.114341735839844, 10.202776908874512, 17.002056121826172, 18.208101272583008, 14.090839385986328, 18.848400115966797, 14.859530448913574, 20.020078659057617, 18.2390079498291, 15.038460731506348, 14.078819274902344, 14.618566513061523, 17.105924606323242, 14.629050254821777, 13.681669235229492, 22.15361213684082, 15.473286628723145, 15.165789604187012, 18.885169982910156, 15.459135055541992, 15.93986701965332, 16.12210464477539, 19.374189376831055, 18.107942581176758, 14.557479858398438, 20.25719451904297, 15.580368995666504, 13.640844345092773, 18.858545303344727, 14.084283828735352, 15.51310920715332, 15.198858261108398, 20.770076751708984, 18.68029022216797, 18.820703506469727, 16.581987380981445, 15.165891647338867, 21.944589614868164, 13.964343070983887, 15.183292388916016, 20.737022399902344, 17.28949546813965, 19.781044006347656, 17.44525146484375, 18.075122833251953, 22.20023536682129, 15.792924880981445, 16.074037551879883, 14.013715744018555, 16.466665267944336, 11.636734008789062, 17.94594383239746, 14.950063705444336, 19.172670364379883, 21.201095581054688, 13.42016315460205, 16.268400192260742, 13.435548782348633, 16.556066513061523, 15.49499797821045, 14.730533599853516, 11.975744247436523, 15.309612274169922, 17.671239852905273, 13.931624412536621, 17.604772567749023, 16.52450180053711, 19.635168075561523, 11.74886417388916, 20.760879516601562, 16.94815444946289, 22.914104461669922, 18.95844841003418, 17.15601348876953, 17.603010177612305, 17.175519943237305, 19.19847297668457, 20.42765998840332, 16.917526245117188, 24.92918586730957, 15.042120933532715, 17.67706871032715, 13.37695598602295, 15.490872383117676, 15.875524520874023, 14.997392654418945, 18.692943572998047, 19.88300132751465, 12.120370864868164, 16.7867488861084, 19.401369094848633, 16.188901901245117, 12.960769653320312, 16.866724014282227, 12.293560981750488, 16.85125160217285, 21.228574752807617, 20.344106674194336, 18.235549926757812, 17.79283905029297, 14.535261154174805, 18.685171127319336, 16.326845169067383, 23.281986236572266, 15.93095588684082, 15.78413200378418, 13.419589042663574, 17.532590866088867, 17.86582374572754, 23.53789710998535, 13.353300094604492, 16.360515594482422, 17.255605697631836, 19.760953903198242, 17.98705291748047, 20.019197463989258, 15.405235290527344, 19.720657348632812, 20.15399742126465, 14.229697227478027, 14.932741165161133, 17.2503604888916, 16.5581111907959, 19.70894432067871, 18.316455841064453, 16.4421443939209, 20.95985221862793, 15.276861190795898]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold2_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [15.181062698364258, 16.090890884399414, 13.36292839050293, 17.468339920043945, 18.823760986328125, 19.19106674194336, 13.709132194519043, 19.86121368408203, 13.590286254882812, 17.830677032470703, 16.15036392211914, 14.219202041625977, 16.760255813598633, 10.930639266967773, 18.82701301574707, 14.881328582763672, 15.010571479797363, 15.420680046081543, 13.630290985107422, 25.478450775146484, 17.794307708740234, 17.234939575195312, 19.019338607788086, 11.782573699951172, 20.245288848876953, 12.341631889343262, 18.64492416381836, 17.775970458984375, 10.34611988067627, 16.383596420288086, 14.710016250610352, 17.292444229125977, 12.826979637145996, 15.667814254760742, 18.281827926635742, 13.482610702514648, 9.043743133544922, 20.87783432006836, 18.524269104003906, 9.276744842529297, 14.518070220947266, 17.922649383544922, 23.64930534362793, 13.99415111541748, 12.486664772033691, 19.057964324951172, 17.184555053710938, 20.50550651550293, 15.545978546142578, 12.200031280517578, 17.650388717651367, 16.87282371520996, 17.70130157470703, 16.655128479003906, 17.307395935058594, 21.057579040527344, 16.774093627929688, 14.245468139648438, 19.551034927368164, 17.754236221313477, 18.015308380126953, 16.82616424560547, 10.657827377319336, 18.003856658935547, 15.408571243286133, 18.761751174926758, 18.161449432373047, 17.97186279296875, 15.298063278198242, 9.856270790100098, 17.182262420654297, 16.76163673400879, 15.569735527038574, 19.3450927734375, 16.65325355529785, 20.71392059326172, 19.967185974121094, 15.302751541137695, 16.439119338989258, 14.059141159057617, 14.0556001663208, 15.377235412597656, 10.106813430786133, 20.24456214904785, 12.487250328063965, 14.843242645263672, 17.916826248168945, 13.004226684570312, 16.42452049255371, 14.975595474243164, 19.72243881225586, 17.646259307861328, 15.579143524169922, 15.95796012878418, 15.220891952514648, 13.835193634033203, 19.36775779724121, 15.51651382446289, 14.367240905761719, 13.075729370117188, 18.787273406982422, 19.26874351501465, 16.452083587646484, 16.10482406616211, 15.608490943908691, 20.397308349609375, 12.63622760772705, 15.089794158935547, 18.40536117553711, 17.546142578125, 19.780323028564453, 17.87659454345703, 16.842424392700195, 17.248132705688477, 13.716809272766113, 14.289363861083984, 10.372694969177246, 17.480802536010742, 13.665180206298828, 16.33641815185547, 15.004928588867188, 18.856470108032227, 20.08404541015625, 17.808979034423828, 14.847792625427246, 13.726526260375977, 15.454973220825195, 13.712331771850586, 13.598773002624512, 12.185539245605469, 13.9050931930542, 16.53321647644043, 11.295387268066406, 17.430204391479492, 14.07395076751709, 19.277618408203125, 15.058816909790039, 17.41061782836914, 17.47710418701172, 23.613025665283203, 17.340904235839844, 15.558686256408691, 16.69061279296875, 13.561301231384277, 22.159406661987305, 20.052841186523438, 15.062085151672363, 23.732643127441406, 13.169744491577148, 16.38585090637207, 15.920220375061035, 15.236248016357422, 15.997126579284668, 16.01717758178711, 18.447431564331055, 15.633399963378906, 11.610427856445312, 13.014013290405273, 17.621318817138672, 14.508098602294922, 11.24348258972168, 14.863719940185547, 10.219534873962402, 16.524478912353516, 24.530912399291992, 18.395347595214844, 15.843460083007812, 17.336881637573242, 15.200462341308594, 19.232254028320312, 14.271537780761719, 20.959579467773438, 15.954151153564453, 14.822347640991211, 12.096485137939453, 16.748807907104492, 16.16227912902832, 22.30193519592285, 11.41668701171875, 18.115880966186523, 16.815731048583984, 18.025686264038086, 18.052539825439453, 20.162527084350586, 16.048969268798828, 20.43840217590332, 20.919633865356445, 14.072216033935547, 15.09918212890625, 15.846346855163574, 17.588714599609375, 19.171804428100586, 19.37957763671875, 17.395538330078125, 19.78040885925293, 15.286697387695312]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold3_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [12.912588119506836, 18.06675910949707, 16.382545471191406, 19.188146591186523, 18.247440338134766, 18.35305404663086, 13.66677188873291, 20.815547943115234, 15.549701690673828, 18.145946502685547, 15.115947723388672, 12.905776023864746, 15.43233871459961, 9.071243286132812, 17.98362922668457, 15.77529525756836, 15.496675491333008, 17.05650520324707, 13.36703872680664, 24.95558738708496, 16.979347229003906, 17.425376892089844, 19.092111587524414, 13.547136306762695, 20.03790283203125, 12.393041610717773, 19.172748565673828, 18.095300674438477, 9.327543258666992, 18.97460174560547, 11.56108283996582, 17.232566833496094, 15.106086730957031, 14.196516036987305, 19.237140655517578, 13.998525619506836, 10.957983016967773, 21.055280685424805, 17.16268539428711, 8.533656120300293, 15.666966438293457, 16.91577911376953, 25.36304473876953, 13.47438907623291, 12.314035415649414, 19.53900909423828, 18.324237823486328, 20.886306762695312, 16.138442993164062, 11.78359603881836, 17.87493896484375, 15.87636947631836, 17.638187408447266, 19.042583465576172, 15.720948219299316, 19.929359436035156, 16.653841018676758, 14.420191764831543, 18.888151168823242, 17.37021255493164, 20.764074325561523, 16.741519927978516, 11.066300392150879, 17.976900100708008, 15.403586387634277, 18.817520141601562, 19.12000274658203, 18.276350021362305, 15.893362998962402, 8.680708885192871, 15.775514602661133, 13.922327995300293, 14.256448745727539, 20.227672576904297, 12.956518173217773, 20.723600387573242, 19.31026840209961, 14.521313667297363, 17.136991500854492, 13.168842315673828, 15.160905838012695, 15.001813888549805, 12.300836563110352, 22.240379333496094, 13.989946365356445, 14.411688804626465, 18.039737701416016, 13.757390975952148, 13.699211120605469, 14.693605422973633, 18.740028381347656, 20.05450439453125, 14.746252059936523, 20.988433837890625, 13.057705879211426, 12.43725299835205, 17.209064483642578, 13.43586540222168, 16.758752822875977, 15.93065357208252, 17.95524787902832, 18.41699981689453, 17.35478973388672, 16.775514602661133, 15.747896194458008, 20.18451499938965, 12.44047737121582, 16.093936920166016, 21.02810287475586, 17.34284019470215, 18.66617774963379, 16.325613021850586, 16.197664260864258, 19.620769500732422, 14.404654502868652, 15.554425239562988, 11.927192687988281, 17.2301025390625, 14.407510757446289, 17.169342041015625, 15.67338752746582, 19.541606903076172, 20.11087417602539, 11.508353233337402, 15.11672592163086, 14.341099739074707, 14.453192710876465, 15.096870422363281, 15.83020305633545, 10.795150756835938, 13.376205444335938, 16.293737411499023, 12.473686218261719, 17.774490356445312, 15.263971328735352, 20.698196411132812, 13.095178604125977, 18.95261001586914, 16.78820037841797, 23.73943519592285, 17.954952239990234, 17.64776039123535, 17.31749725341797, 17.85367202758789, 23.242443084716797, 20.923646926879883, 16.04213523864746, 24.387081146240234, 15.078539848327637, 17.103158950805664, 12.95344066619873, 14.84712028503418, 17.739791870117188, 15.40731430053711, 16.591209411621094, 18.24099349975586, 11.189287185668945, 14.7277193069458, 19.407167434692383, 15.996594429016113, 10.451628684997559, 13.513193130493164, 9.313962936401367, 15.763919830322266, 23.004762649536133, 17.96516990661621, 16.101884841918945, 18.366008758544922, 15.692031860351562, 20.50497817993164, 14.728285789489746, 23.70221519470215, 14.565214157104492, 16.25944709777832, 11.286214828491211, 18.420352935791016, 16.788890838623047, 22.41057586669922, 11.689953804016113, 17.255943298339844, 17.35886001586914, 19.007259368896484, 18.557220458984375, 18.353118896484375, 15.97553539276123, 20.638551712036133, 21.39514923095703, 14.269898414611816, 15.114908218383789, 15.550992965698242, 17.64975929260254, 22.20734214782715, 19.479604721069336, 16.100852966308594, 18.981382369995117, 14.995595932006836]\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "model_path: ./models_Hertel_estimation/5-fold-crossvalidation/eye_fold4_RepVGGA2.pth\n",
            "targets: [14.0, 17.0, 16.0, 18.0, 19.0, 21.0, 14.0, 20.5, 13.0, 17.0, 15.0, 13.0, 17.0, 11.0, 20.0, 16.0, 15.0, 17.0, 14.0, 24.0, 18.0, 18.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 11.0, 18.0, 12.0, 17.0, 16.0, 16.0, 17.0, 14.0, 10.0, 22.0, 19.0, 9.0, 17.0, 18.0, 24.0, 15.0, 13.0, 20.0, 19.0, 21.0, 15.0, 12.0, 18.0, 17.0, 19.0, 20.0, 17.0, 21.0, 18.0, 16.0, 20.0, 18.0, 19.0, 17.0, 12.0, 19.0, 15.0, 19.0, 19.0, 20.0, 15.0, 9.0, 16.0, 16.0, 13.0, 20.0, 15.0, 20.0, 20.0, 16.0, 17.0, 14.0, 15.0, 15.0, 12.0, 20.0, 13.0, 14.0, 19.0, 13.0, 16.0, 16.0, 20.0, 19.0, 16.0, 20.0, 15.0, 14.0, 19.0, 13.0, 16.0, 15.0, 21.0, 20.0, 18.0, 17.0, 17.0, 21.0, 14.0, 15.0, 20.0, 17.0, 19.0, 17.0, 17.0, 21.0, 14.0, 15.0, 12.0, 18.0, 15.0, 17.0, 15.0, 18.0, 20.0, 14.0, 15.0, 15.0, 16.0, 15.0, 15.0, 12.0, 15.0, 18.0, 12.0, 18.0, 15.0, 20.0, 14.0, 18.0, 17.0, 23.0, 18.0, 17.0, 17.0, 17.0, 23.0, 20.0, 16.0, 23.0, 14.0, 17.0, 14.0, 15.0, 18.0, 17.0, 19.0, 18.0, 12.0, 15.0, 20.0, 16.0, 12.0, 16.0, 10.0, 17.0, 25.0, 18.0, 17.0, 18.0, 16.0, 19.0, 16.0, 21.0, 14.0, 16.0, 15.0, 17.0, 17.0, 21.0, 12.0, 19.0, 18.0, 19.0, 15.0, 20.0, 17.0, 19.0, 21.0, 15.0, 17.0, 15.0, 21.0, 19.0, 17.0, 16.0, 20.0, 16.0]\n",
            "outputs: [13.956069946289062, 16.905662536621094, 16.692049026489258, 18.581377029418945, 18.200075149536133, 19.565881729125977, 16.253013610839844, 20.882112503051758, 13.000081062316895, 15.407083511352539, 14.14693832397461, 11.435545921325684, 14.227433204650879, 10.346579551696777, 19.44770050048828, 16.75094223022461, 13.61349105834961, 15.683865547180176, 13.93529224395752, 24.25604820251465, 17.049081802368164, 17.813020706176758, 17.908456802368164, 14.660615921020508, 18.38736915588379, 10.098877906799316, 17.413557052612305, 17.829952239990234, 11.31591796875, 17.499183654785156, 13.174564361572266, 16.440982818603516, 16.8989315032959, 15.944732666015625, 16.33347511291504, 15.377835273742676, 12.759283065795898, 20.58445167541504, 18.106840133666992, 10.181276321411133, 16.67184066772461, 18.005462646484375, 18.875423431396484, 14.631439208984375, 12.922033309936523, 19.72414207458496, 17.569887161254883, 21.455514907836914, 15.832549095153809, 12.549768447875977, 18.244630813598633, 15.420092582702637, 19.66403579711914, 18.60188102722168, 15.62714958190918, 20.432876586914062, 18.727052688598633, 15.19263744354248, 19.743497848510742, 16.150245666503906, 19.665220260620117, 16.47434425354004, 13.136364936828613, 18.831483840942383, 15.565740585327148, 19.54200553894043, 17.991695404052734, 19.33165168762207, 15.627771377563477, 9.017848014831543, 16.63991355895996, 16.186548233032227, 13.803964614868164, 21.1210880279541, 15.458138465881348, 17.14712142944336, 19.043872833251953, 14.385361671447754, 15.6585693359375, 14.82237434387207, 16.14947509765625, 16.227140426635742, 12.85405158996582, 22.191499710083008, 14.9193754196167, 14.36275863647461, 20.54275894165039, 14.135848999023438, 15.406458854675293, 15.715784072875977, 21.17437744140625, 20.919004440307617, 15.090883255004883, 18.87946891784668, 13.260307312011719, 14.530807495117188, 20.53748321533203, 12.353072166442871, 14.032661437988281, 16.185522079467773, 18.96929931640625, 21.31081199645996, 18.846609115600586, 16.850704193115234, 16.751754760742188, 20.76230812072754, 15.006017684936523, 13.710067749023438, 21.16893196105957, 17.330698013305664, 20.012706756591797, 17.84610939025879, 15.514608383178711, 19.845382690429688, 14.814403533935547, 16.22213363647461, 10.985272407531738, 16.883426666259766, 12.54909610748291, 17.505294799804688, 15.213753700256348, 19.96568489074707, 18.41763687133789, 15.15661907196045, 14.199623107910156, 14.578015327453613, 15.170197486877441, 13.335626602172852, 15.299518585205078, 13.907397270202637, 14.644567489624023, 18.936784744262695, 14.278653144836426, 18.868976593017578, 14.83892822265625, 19.148418426513672, 14.396820068359375, 21.072376251220703, 17.111188888549805, 25.685558319091797, 18.826841354370117, 15.456026077270508, 17.905115127563477, 16.835615158081055, 19.984270095825195, 18.57355308532715, 13.798271179199219, 22.95784568786621, 13.699735641479492, 17.427413940429688, 14.310308456420898, 14.352596282958984, 17.82984733581543, 15.862953186035156, 18.000165939331055, 17.648290634155273, 11.865947723388672, 14.517135620117188, 18.61619758605957, 16.542556762695312, 13.630434036254883, 16.023847579956055, 10.212736129760742, 16.79500389099121, 24.625102996826172, 19.410497665405273, 18.476951599121094, 19.409433364868164, 13.432228088378906, 19.42381477355957, 16.083099365234375, 24.094274520874023, 15.641469955444336, 15.425996780395508, 13.916415214538574, 17.947202682495117, 16.594491958618164, 22.626317977905273, 13.131041526794434, 16.12548065185547, 17.00677490234375, 19.82206153869629, 18.018667221069336, 18.43730354309082, 16.989091873168945, 19.97304916381836, 20.56041145324707, 15.365809440612793, 15.568231582641602, 16.584550857543945, 17.5581111907959, 20.069557189941406, 18.48554801940918, 15.945302963256836, 19.938316345214844, 13.456868171691895]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "8WbUvsaK3hKa",
        "outputId": "a387052e-7388-4928-ceb6-8c456f0ef34a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     targets  half_fold0  half_fold1  half_fold2  half_fold3  half_fold4  \\\n",
              "0       14.0   13.378623   14.685628   13.294028   13.973372   14.123014   \n",
              "1       17.0   16.527866   17.420464   18.572323   18.026186   17.614462   \n",
              "2       16.0   14.413683   15.394675   13.035702   15.077651   14.736663   \n",
              "3       18.0   17.310123   20.631779   17.513378   18.866766   18.291342   \n",
              "4       19.0   18.193491   18.763926   18.263947   18.002565   18.582289   \n",
              "..       ...         ...         ...         ...         ...         ...   \n",
              "191     19.0   16.332293   18.511236   16.109682   16.466679   17.397280   \n",
              "192     17.0   18.421608   19.502392   19.346493   18.655588   20.087976   \n",
              "193     16.0   15.132609   16.224701   15.771392   16.424994   15.888462   \n",
              "194     20.0   19.492592   22.159861   20.409103   19.957970   20.678410   \n",
              "195     16.0   15.496405   16.312719   13.045691   15.777010   15.306217   \n",
              "\n",
              "     periocular_fold0  periocular_fold1  periocular_fold2  periocular_fold3  \\\n",
              "0           14.628881         14.507998         14.967015         13.757207   \n",
              "1           16.501270         16.867992         17.573963         17.416254   \n",
              "2           15.614464         16.265606         14.597241         16.318535   \n",
              "3           17.554770         19.608227         17.574945         17.915594   \n",
              "4           18.368830         18.018055         20.731621         18.140236   \n",
              "..                ...               ...               ...               ...   \n",
              "191         18.765438         17.932436         17.759705         19.999836   \n",
              "192         17.838074         18.120354         18.588303         19.190153   \n",
              "193         16.716595         16.471413         16.551378         16.688139   \n",
              "194         21.200632         20.790155         18.605188         20.717855   \n",
              "195         15.312069         14.831355         16.326694         15.811578   \n",
              "\n",
              "     periocular_fold4  eye_fold0  eye_fold1  eye_fold2  eye_fold3  eye_fold4  \n",
              "0           13.487124  14.274810  14.551019  15.181063  12.912588  13.956070  \n",
              "1           15.861028  16.626665  15.791635  16.090891  18.066759  16.905663  \n",
              "2           14.994992  15.825631  17.309702  13.362928  16.382545  16.692049  \n",
              "3           18.106993  18.756432  20.563534  17.468340  19.188147  18.581377  \n",
              "4           19.150448  19.392269  19.751122  18.823761  18.247440  18.200075  \n",
              "..                ...        ...        ...        ...        ...        ...  \n",
              "191         17.882872  20.346523  19.708944  19.171804  22.207342  20.069557  \n",
              "192         18.343943  18.792059  18.316456  19.379578  19.479605  18.485548  \n",
              "193         16.680050  15.400311  16.442144  17.395538  16.100853  15.945303  \n",
              "194         19.788475  18.887751  20.959852  19.780409  18.981382  19.938316  \n",
              "195         15.546432  14.627169  15.276861  15.286697  14.995596  13.456868  \n",
              "\n",
              "[196 rows x 16 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>half_fold0</th>\n",
              "      <th>half_fold1</th>\n",
              "      <th>half_fold2</th>\n",
              "      <th>half_fold3</th>\n",
              "      <th>half_fold4</th>\n",
              "      <th>periocular_fold0</th>\n",
              "      <th>periocular_fold1</th>\n",
              "      <th>periocular_fold2</th>\n",
              "      <th>periocular_fold3</th>\n",
              "      <th>periocular_fold4</th>\n",
              "      <th>eye_fold0</th>\n",
              "      <th>eye_fold1</th>\n",
              "      <th>eye_fold2</th>\n",
              "      <th>eye_fold3</th>\n",
              "      <th>eye_fold4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.0</td>\n",
              "      <td>13.378623</td>\n",
              "      <td>14.685628</td>\n",
              "      <td>13.294028</td>\n",
              "      <td>13.973372</td>\n",
              "      <td>14.123014</td>\n",
              "      <td>14.628881</td>\n",
              "      <td>14.507998</td>\n",
              "      <td>14.967015</td>\n",
              "      <td>13.757207</td>\n",
              "      <td>13.487124</td>\n",
              "      <td>14.274810</td>\n",
              "      <td>14.551019</td>\n",
              "      <td>15.181063</td>\n",
              "      <td>12.912588</td>\n",
              "      <td>13.956070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17.0</td>\n",
              "      <td>16.527866</td>\n",
              "      <td>17.420464</td>\n",
              "      <td>18.572323</td>\n",
              "      <td>18.026186</td>\n",
              "      <td>17.614462</td>\n",
              "      <td>16.501270</td>\n",
              "      <td>16.867992</td>\n",
              "      <td>17.573963</td>\n",
              "      <td>17.416254</td>\n",
              "      <td>15.861028</td>\n",
              "      <td>16.626665</td>\n",
              "      <td>15.791635</td>\n",
              "      <td>16.090891</td>\n",
              "      <td>18.066759</td>\n",
              "      <td>16.905663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>14.413683</td>\n",
              "      <td>15.394675</td>\n",
              "      <td>13.035702</td>\n",
              "      <td>15.077651</td>\n",
              "      <td>14.736663</td>\n",
              "      <td>15.614464</td>\n",
              "      <td>16.265606</td>\n",
              "      <td>14.597241</td>\n",
              "      <td>16.318535</td>\n",
              "      <td>14.994992</td>\n",
              "      <td>15.825631</td>\n",
              "      <td>17.309702</td>\n",
              "      <td>13.362928</td>\n",
              "      <td>16.382545</td>\n",
              "      <td>16.692049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>17.310123</td>\n",
              "      <td>20.631779</td>\n",
              "      <td>17.513378</td>\n",
              "      <td>18.866766</td>\n",
              "      <td>18.291342</td>\n",
              "      <td>17.554770</td>\n",
              "      <td>19.608227</td>\n",
              "      <td>17.574945</td>\n",
              "      <td>17.915594</td>\n",
              "      <td>18.106993</td>\n",
              "      <td>18.756432</td>\n",
              "      <td>20.563534</td>\n",
              "      <td>17.468340</td>\n",
              "      <td>19.188147</td>\n",
              "      <td>18.581377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>18.193491</td>\n",
              "      <td>18.763926</td>\n",
              "      <td>18.263947</td>\n",
              "      <td>18.002565</td>\n",
              "      <td>18.582289</td>\n",
              "      <td>18.368830</td>\n",
              "      <td>18.018055</td>\n",
              "      <td>20.731621</td>\n",
              "      <td>18.140236</td>\n",
              "      <td>19.150448</td>\n",
              "      <td>19.392269</td>\n",
              "      <td>19.751122</td>\n",
              "      <td>18.823761</td>\n",
              "      <td>18.247440</td>\n",
              "      <td>18.200075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>19.0</td>\n",
              "      <td>16.332293</td>\n",
              "      <td>18.511236</td>\n",
              "      <td>16.109682</td>\n",
              "      <td>16.466679</td>\n",
              "      <td>17.397280</td>\n",
              "      <td>18.765438</td>\n",
              "      <td>17.932436</td>\n",
              "      <td>17.759705</td>\n",
              "      <td>19.999836</td>\n",
              "      <td>17.882872</td>\n",
              "      <td>20.346523</td>\n",
              "      <td>19.708944</td>\n",
              "      <td>19.171804</td>\n",
              "      <td>22.207342</td>\n",
              "      <td>20.069557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>17.0</td>\n",
              "      <td>18.421608</td>\n",
              "      <td>19.502392</td>\n",
              "      <td>19.346493</td>\n",
              "      <td>18.655588</td>\n",
              "      <td>20.087976</td>\n",
              "      <td>17.838074</td>\n",
              "      <td>18.120354</td>\n",
              "      <td>18.588303</td>\n",
              "      <td>19.190153</td>\n",
              "      <td>18.343943</td>\n",
              "      <td>18.792059</td>\n",
              "      <td>18.316456</td>\n",
              "      <td>19.379578</td>\n",
              "      <td>19.479605</td>\n",
              "      <td>18.485548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>16.0</td>\n",
              "      <td>15.132609</td>\n",
              "      <td>16.224701</td>\n",
              "      <td>15.771392</td>\n",
              "      <td>16.424994</td>\n",
              "      <td>15.888462</td>\n",
              "      <td>16.716595</td>\n",
              "      <td>16.471413</td>\n",
              "      <td>16.551378</td>\n",
              "      <td>16.688139</td>\n",
              "      <td>16.680050</td>\n",
              "      <td>15.400311</td>\n",
              "      <td>16.442144</td>\n",
              "      <td>17.395538</td>\n",
              "      <td>16.100853</td>\n",
              "      <td>15.945303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>20.0</td>\n",
              "      <td>19.492592</td>\n",
              "      <td>22.159861</td>\n",
              "      <td>20.409103</td>\n",
              "      <td>19.957970</td>\n",
              "      <td>20.678410</td>\n",
              "      <td>21.200632</td>\n",
              "      <td>20.790155</td>\n",
              "      <td>18.605188</td>\n",
              "      <td>20.717855</td>\n",
              "      <td>19.788475</td>\n",
              "      <td>18.887751</td>\n",
              "      <td>20.959852</td>\n",
              "      <td>19.780409</td>\n",
              "      <td>18.981382</td>\n",
              "      <td>19.938316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>16.0</td>\n",
              "      <td>15.496405</td>\n",
              "      <td>16.312719</td>\n",
              "      <td>13.045691</td>\n",
              "      <td>15.777010</td>\n",
              "      <td>15.306217</td>\n",
              "      <td>15.312069</td>\n",
              "      <td>14.831355</td>\n",
              "      <td>16.326694</td>\n",
              "      <td>15.811578</td>\n",
              "      <td>15.546432</td>\n",
              "      <td>14.627169</td>\n",
              "      <td>15.276861</td>\n",
              "      <td>15.286697</td>\n",
              "      <td>14.995596</td>\n",
              "      <td>13.456868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>196 rows × 16 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGpgBuX0PQNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_5fold = pd.DataFrame(index=[\"ave\", \"std\", \"median\", \"median3ave\"], columns=df.columns[1:])\n",
        "\n",
        "\n",
        "for fold in [0,1,2,3,4]:\n"
      ],
      "metadata": {
        "id": "5tyn53sGG8sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "p-JhpT5G1UOu",
        "outputId": "3a3961ed-d170-41c8-e2c7-4025b83b9f8c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          half_fold0 half_fold1 half_fold2 half_fold3  \\\n",
              "AveError                   -0.311591   0.417779   -0.56754  -0.211157   \n",
              "StdError                    1.335633   1.042371   1.310668   1.373913   \n",
              "AveAbsError                  1.06121   0.842036   1.098227   1.075447   \n",
              "StdAbsError                 0.865772   0.741156   0.910668    0.87746   \n",
              "Corrected_AveAbsError       1.013526   0.760527   0.988659   1.062684   \n",
              "Corrected_StdAbsError       0.866842   0.710753    0.85755   0.867495   \n",
              "Corr_coef                   0.894089   0.935201   0.903746   0.885183   \n",
              "<=1mm_rate                     54.08      66.84       55.1      52.55   \n",
              "<=2mm_rate                     86.73      91.33      86.22      87.76   \n",
              ">2mm_rate                      13.27       8.67      13.78      12.24   \n",
              ">18mm_sensitivity            0.64557   0.898734   0.670886   0.708861   \n",
              ">18mm_specificity           0.974359   0.974359   0.974359   0.940171   \n",
              ">18mm_positive_predictive   0.944444   0.959459   0.946429   0.888889   \n",
              ">18mm_negative_predictive   0.802817   0.934426   0.814286   0.827068   \n",
              "\n",
              "                          half_fold4 periocular_fold0 periocular_fold1  \\\n",
              "AveError                    0.041006         0.119423        -0.233782   \n",
              "StdError                    1.210769         1.103213         1.135609   \n",
              "AveAbsError                 0.897991         0.810026         0.813119   \n",
              "StdAbsError                 0.810635         0.756245         0.824614   \n",
              "Corrected_AveAbsError       0.898931         0.808215         0.807477   \n",
              "Corrected_StdAbsError       0.808544         0.748677         0.796395   \n",
              "Corr_coef                   0.915333         0.928942         0.923216   \n",
              "<=1mm_rate                     67.86            74.49            71.43   \n",
              "<=2mm_rate                     88.27            92.35            91.33   \n",
              ">2mm_rate                      11.73             7.65             8.67   \n",
              ">18mm_sensitivity           0.810127         0.873418         0.759494   \n",
              ">18mm_specificity           0.957265         0.974359         0.974359   \n",
              ">18mm_positive_predictive   0.927536         0.958333         0.952381   \n",
              ">18mm_negative_predictive    0.88189         0.919355         0.857143   \n",
              "\n",
              "                          periocular_fold2 periocular_fold3 periocular_fold4  \\\n",
              "AveError                         -0.109735         0.190205        -0.258897   \n",
              "StdError                          1.307174         0.963924           1.1881   \n",
              "AveAbsError                       1.000586         0.769067         0.913971   \n",
              "StdAbsError                       0.845282          0.60911         0.799578   \n",
              "Corrected_AveAbsError             0.996806         0.737531         0.894902   \n",
              "Corrected_StdAbsError             0.842607         0.618391         0.778861   \n",
              "Corr_coef                         0.911439         0.947002         0.914935   \n",
              "<=1mm_rate                           57.14            73.47            65.82   \n",
              "<=2mm_rate                           87.76             94.9            92.86   \n",
              ">2mm_rate                            12.24              5.1             7.14   \n",
              ">18mm_sensitivity                 0.759494         0.835443         0.696203   \n",
              ">18mm_specificity                 0.957265         0.974359         0.982906   \n",
              ">18mm_positive_predictive         0.923077         0.956522         0.964912   \n",
              ">18mm_negative_predictive         0.854962         0.897638         0.827338   \n",
              "\n",
              "                          eye_fold0 eye_fold1 eye_fold2 eye_fold3 eye_fold4  \n",
              "AveError                     0.0262  0.077994 -0.448521 -0.279955 -0.069103  \n",
              "StdError                   1.297795  1.347517  1.197901  1.193373  1.311887  \n",
              "AveAbsError                0.994437  1.047419  0.976815  0.961311  1.033183  \n",
              "StdAbsError                0.831254  0.848058  0.823475  0.757666  0.808027  \n",
              "Corrected_AveAbsError      0.995507   1.04406  0.877378  0.943396  1.031191  \n",
              "Corrected_StdAbsError      0.829551  0.848617  0.813159  0.727721  0.807613  \n",
              "Corr_coef                   0.89777  0.891774   0.91788  0.927838  0.899911  \n",
              "<=1mm_rate                     55.1     57.65     63.27     58.67     55.61  \n",
              "<=2mm_rate                    91.33     84.18      89.8     90.82      89.8  \n",
              ">2mm_rate                      8.67     15.82      10.2      9.18      10.2  \n",
              ">18mm_sensitivity          0.772152  0.797468  0.632911  0.708861  0.797468  \n",
              ">18mm_specificity          0.974359  0.957265  0.974359  0.948718  0.974359  \n",
              ">18mm_positive_predictive  0.953125  0.926471  0.943396  0.903226  0.954545  \n",
              ">18mm_negative_predictive  0.863636     0.875  0.797203  0.828358  0.876923  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>half_fold0</th>\n",
              "      <th>half_fold1</th>\n",
              "      <th>half_fold2</th>\n",
              "      <th>half_fold3</th>\n",
              "      <th>half_fold4</th>\n",
              "      <th>periocular_fold0</th>\n",
              "      <th>periocular_fold1</th>\n",
              "      <th>periocular_fold2</th>\n",
              "      <th>periocular_fold3</th>\n",
              "      <th>periocular_fold4</th>\n",
              "      <th>eye_fold0</th>\n",
              "      <th>eye_fold1</th>\n",
              "      <th>eye_fold2</th>\n",
              "      <th>eye_fold3</th>\n",
              "      <th>eye_fold4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AveError</th>\n",
              "      <td>-0.311591</td>\n",
              "      <td>0.417779</td>\n",
              "      <td>-0.56754</td>\n",
              "      <td>-0.211157</td>\n",
              "      <td>0.041006</td>\n",
              "      <td>0.119423</td>\n",
              "      <td>-0.233782</td>\n",
              "      <td>-0.109735</td>\n",
              "      <td>0.190205</td>\n",
              "      <td>-0.258897</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.077994</td>\n",
              "      <td>-0.448521</td>\n",
              "      <td>-0.279955</td>\n",
              "      <td>-0.069103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StdError</th>\n",
              "      <td>1.335633</td>\n",
              "      <td>1.042371</td>\n",
              "      <td>1.310668</td>\n",
              "      <td>1.373913</td>\n",
              "      <td>1.210769</td>\n",
              "      <td>1.103213</td>\n",
              "      <td>1.135609</td>\n",
              "      <td>1.307174</td>\n",
              "      <td>0.963924</td>\n",
              "      <td>1.1881</td>\n",
              "      <td>1.297795</td>\n",
              "      <td>1.347517</td>\n",
              "      <td>1.197901</td>\n",
              "      <td>1.193373</td>\n",
              "      <td>1.311887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AveAbsError</th>\n",
              "      <td>1.06121</td>\n",
              "      <td>0.842036</td>\n",
              "      <td>1.098227</td>\n",
              "      <td>1.075447</td>\n",
              "      <td>0.897991</td>\n",
              "      <td>0.810026</td>\n",
              "      <td>0.813119</td>\n",
              "      <td>1.000586</td>\n",
              "      <td>0.769067</td>\n",
              "      <td>0.913971</td>\n",
              "      <td>0.994437</td>\n",
              "      <td>1.047419</td>\n",
              "      <td>0.976815</td>\n",
              "      <td>0.961311</td>\n",
              "      <td>1.033183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StdAbsError</th>\n",
              "      <td>0.865772</td>\n",
              "      <td>0.741156</td>\n",
              "      <td>0.910668</td>\n",
              "      <td>0.87746</td>\n",
              "      <td>0.810635</td>\n",
              "      <td>0.756245</td>\n",
              "      <td>0.824614</td>\n",
              "      <td>0.845282</td>\n",
              "      <td>0.60911</td>\n",
              "      <td>0.799578</td>\n",
              "      <td>0.831254</td>\n",
              "      <td>0.848058</td>\n",
              "      <td>0.823475</td>\n",
              "      <td>0.757666</td>\n",
              "      <td>0.808027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corrected_AveAbsError</th>\n",
              "      <td>1.013526</td>\n",
              "      <td>0.760527</td>\n",
              "      <td>0.988659</td>\n",
              "      <td>1.062684</td>\n",
              "      <td>0.898931</td>\n",
              "      <td>0.808215</td>\n",
              "      <td>0.807477</td>\n",
              "      <td>0.996806</td>\n",
              "      <td>0.737531</td>\n",
              "      <td>0.894902</td>\n",
              "      <td>0.995507</td>\n",
              "      <td>1.04406</td>\n",
              "      <td>0.877378</td>\n",
              "      <td>0.943396</td>\n",
              "      <td>1.031191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corrected_StdAbsError</th>\n",
              "      <td>0.866842</td>\n",
              "      <td>0.710753</td>\n",
              "      <td>0.85755</td>\n",
              "      <td>0.867495</td>\n",
              "      <td>0.808544</td>\n",
              "      <td>0.748677</td>\n",
              "      <td>0.796395</td>\n",
              "      <td>0.842607</td>\n",
              "      <td>0.618391</td>\n",
              "      <td>0.778861</td>\n",
              "      <td>0.829551</td>\n",
              "      <td>0.848617</td>\n",
              "      <td>0.813159</td>\n",
              "      <td>0.727721</td>\n",
              "      <td>0.807613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corr_coef</th>\n",
              "      <td>0.894089</td>\n",
              "      <td>0.935201</td>\n",
              "      <td>0.903746</td>\n",
              "      <td>0.885183</td>\n",
              "      <td>0.915333</td>\n",
              "      <td>0.928942</td>\n",
              "      <td>0.923216</td>\n",
              "      <td>0.911439</td>\n",
              "      <td>0.947002</td>\n",
              "      <td>0.914935</td>\n",
              "      <td>0.89777</td>\n",
              "      <td>0.891774</td>\n",
              "      <td>0.91788</td>\n",
              "      <td>0.927838</td>\n",
              "      <td>0.899911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt;=1mm_rate</th>\n",
              "      <td>54.08</td>\n",
              "      <td>66.84</td>\n",
              "      <td>55.1</td>\n",
              "      <td>52.55</td>\n",
              "      <td>67.86</td>\n",
              "      <td>74.49</td>\n",
              "      <td>71.43</td>\n",
              "      <td>57.14</td>\n",
              "      <td>73.47</td>\n",
              "      <td>65.82</td>\n",
              "      <td>55.1</td>\n",
              "      <td>57.65</td>\n",
              "      <td>63.27</td>\n",
              "      <td>58.67</td>\n",
              "      <td>55.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt;=2mm_rate</th>\n",
              "      <td>86.73</td>\n",
              "      <td>91.33</td>\n",
              "      <td>86.22</td>\n",
              "      <td>87.76</td>\n",
              "      <td>88.27</td>\n",
              "      <td>92.35</td>\n",
              "      <td>91.33</td>\n",
              "      <td>87.76</td>\n",
              "      <td>94.9</td>\n",
              "      <td>92.86</td>\n",
              "      <td>91.33</td>\n",
              "      <td>84.18</td>\n",
              "      <td>89.8</td>\n",
              "      <td>90.82</td>\n",
              "      <td>89.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;2mm_rate</th>\n",
              "      <td>13.27</td>\n",
              "      <td>8.67</td>\n",
              "      <td>13.78</td>\n",
              "      <td>12.24</td>\n",
              "      <td>11.73</td>\n",
              "      <td>7.65</td>\n",
              "      <td>8.67</td>\n",
              "      <td>12.24</td>\n",
              "      <td>5.1</td>\n",
              "      <td>7.14</td>\n",
              "      <td>8.67</td>\n",
              "      <td>15.82</td>\n",
              "      <td>10.2</td>\n",
              "      <td>9.18</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;18mm_sensitivity</th>\n",
              "      <td>0.64557</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.670886</td>\n",
              "      <td>0.708861</td>\n",
              "      <td>0.810127</td>\n",
              "      <td>0.873418</td>\n",
              "      <td>0.759494</td>\n",
              "      <td>0.759494</td>\n",
              "      <td>0.835443</td>\n",
              "      <td>0.696203</td>\n",
              "      <td>0.772152</td>\n",
              "      <td>0.797468</td>\n",
              "      <td>0.632911</td>\n",
              "      <td>0.708861</td>\n",
              "      <td>0.797468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;18mm_specificity</th>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.940171</td>\n",
              "      <td>0.957265</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.957265</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.982906</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.957265</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.974359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;18mm_positive_predictive</th>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.946429</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>0.926471</td>\n",
              "      <td>0.943396</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.954545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;18mm_negative_predictive</th>\n",
              "      <td>0.802817</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.814286</td>\n",
              "      <td>0.827068</td>\n",
              "      <td>0.88189</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.854962</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.827338</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.797203</td>\n",
              "      <td>0.828358</td>\n",
              "      <td>0.876923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1G9vgI2Djy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBy1BeytJGel"
      },
      "source": [
        "#**Evaluation using testset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "area_num\n",
        "0: half \n",
        "1: periocular\n",
        "2: eye\n",
        "\"\"\"\n",
        "area_num = 0\n",
        "\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "#PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "#PATH = f\"./models_Hertel_estimation/5-fold-crossvalidation/half_fold0_RepVGGA2.pth\"\n",
        "\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "r3FmwmZ8P9ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "#evaluation using validation dataset\n",
        "\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "\n",
        "model_ft.eval() # prep model for evaluation\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor[:,area_num]) #dim0はbach_size、dim1がarea_num\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          print(f\"estimate: {my_round(output[0].item())} mm, target: {target[0].item()} mm\")\n",
        "\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "print('')\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n"
      ],
      "metadata": {
        "id": "9uZfA263UUhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lamJcFxkjkxA",
        "outputId": "36158ec7-2a62-4470-c2f0-05eceb76bd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "#Draw Graphs（もともとの散布図\n",
        "df = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.0, 24.0)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['target']-df['estimate'], bins=15, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示"
      ],
      "metadata": {
        "id": "IumsUK1p29SL",
        "outputId": "849cb508-71d5-4073-c58a-1b28c6f14aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "IfRogutV3Y4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(df)\n",
        "within1 = sum((i <= 1 and i >= -1 for i in df['estimate']-df['target']))\n",
        "within2 = sum((i <= 2 and i >= -2 for i in df['estimate']-df['target']))\n",
        "over2 = sum((i > 2 or i < -2 for i in df['estimate']-df['target']))\n",
        "\n",
        "print(f'-1<Error<1: {within1}, ({my_round(within1/total*100)}%)')\n",
        "print(f'-2<Error<2: {within1}, ({my_round(within2/total*100)}%)')\n",
        "print(f'Error over 2: {within1}, ({my_round(over2/total*100)}%)')\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]>= 18:\n",
        "        FN += 1\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]< 18:\n",
        "        FP += 1 \n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,0]>=16 and df.iloc[i,1]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,0]<16 and df.iloc[i,1]>= 18:\n",
        "        minogashi += 1\n",
        "    if df.iloc[i,0]>=18 and df.iloc[i,1]<= 16:\n",
        "        kajyou += 1 \n",
        "    if df.iloc[i,0]<18 and df.iloc[i,1]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n",
        "\n"
      ],
      "metadata": {
        "id": "QDNfYarsk3eI",
        "outputId": "3a01747d-1cce-4f87-9ffe-60bea1f67908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1<Error<1: 136, (69.39%)\n",
            "-2<Error<2: 136, (91.84%)\n",
            "Error over 2: 136, (8.16%)\n",
            "\n",
            "Hertel 18mm以上の検出精度\n",
            "TP: 68\n",
            "FP: 5\n",
            "FN: 11\n",
            "TN: 112\n",
            "Sensitivity: 0.8607594936708861\n",
            "Specificity: 0.9572649572649573\n",
            "Positive predictive value: 0.9315068493150684\n",
            "Negative predictive value: 0.9105691056910569\n",
            "\n",
            "推測18mm以上だが実は16mm未満(過剰): 1例\n",
            "推測16mm未満だが実は18mm以上（見逃がし）: 0例\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSxjXrglZc4k"
      },
      "source": [
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**平均値、線形近似による補正**"
      ],
      "metadata": {
        "id": "ctOezTjprVyF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R6aSRMkWEZO",
        "outputId": "92602d57-c35f-4e7f-bed2-1d6f617ace49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#線形近似式算出\n",
        "from sklearn import linear_model\n",
        "\n",
        "estimate = df.loc[:,'estimate']\n",
        "target = df.loc[:,'target']\n",
        "clf = linear_model.LinearRegression()\n",
        "\n",
        "# 説明変数xに \"x1\"のデータを使用\n",
        "x = np.array([estimate]).T\n",
        "\n",
        "# 目的変数yに \"x2\"のデータを使用\n",
        "y = target.values\n",
        "\n",
        "# 予測モデルを作成（単回帰）\n",
        "clf.fit(x, y)\n",
        "\n",
        "# パラメータ（回帰係数、切片）を抽出\n",
        "[a] = clf.coef_\n",
        "b = clf.intercept_\n",
        "\n",
        "# パラメータの表示\n",
        "print(\"回帰係数:\", a)\n",
        "print(\"切片:\", b)\n",
        "print(\"決定係数:\", clf.score(x, y))\n",
        "\n",
        "#平均値により補正した値\n",
        "df['Corrected_estimate_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,2] = corrected_output[i]\n",
        "\n",
        "#回帰直線により補正した値\n",
        "df['Corrected_estimate_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,3] = df.iloc[i,0]*a+b\n",
        "\n",
        "#残差\n",
        "df['Residual_error_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,4] = df.iloc[i,2]-df.iloc[i,1]\n",
        "\n",
        "#残差\n",
        "df['Residual_error_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,5] = df.iloc[i,3]-df.iloc[i,1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "回帰係数: 0.9243867958397015\n",
            "切片: 1.2198555301736356\n",
            "決定係数: 0.8391249673052268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlWXLynoKxy"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiUi44-jGIZ"
      },
      "source": [
        "#平均近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_1'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_1', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_1']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_1'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_1'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "\n",
        "print('')\n",
        "print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df['Residual_error_2']))))\n",
        "print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df['Residual_error_2']))))\n",
        "print('Error<=-2: ' +  str(sum((i <= -2 for i in df['Residual_error_2']))))\n",
        "print('Error>=2: ' +  str(sum((i >= 2 for i in df['Residual_error_2']))))\n",
        "\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]>= 18:\n",
        "        FP += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]< 18:\n",
        "        FN += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=16 and df.iloc[i,2]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,1]<16 and df.iloc[i,2]>= 18:\n",
        "        kajyou += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,2]<= 16:\n",
        "        minogashi += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,2]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x96i5oZDM0dm"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (平均値により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_1']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBFhobtCbv6t"
      },
      "source": [
        "#線形近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_2'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_2', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_2']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_2'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_2'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "print('')\n",
        "print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df['Residual_error_2']))))\n",
        "print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df['Residual_error_2']))))\n",
        "print('Error<=-2: ' +  str(sum((i <= -2 for i in df['Residual_error_2']))))\n",
        "print('Error>=2: ' +  str(sum((i >= 2 for i in df['Residual_error_2']))))\n",
        "\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]>= 18:\n",
        "        FP += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]< 18:\n",
        "        FN += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=16 and df.iloc[i,3]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,1]<16 and df.iloc[i,3]>= 18:\n",
        "        kajyou += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]<= 16:\n",
        "        minogashi += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPJMCKTFqFnQ"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (線形近似により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_2']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ensemble learning (Stacking)**"
      ],
      "metadata": {
        "id": "qf7jBK7E3ns_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define training"
      ],
      "metadata": {
        "id": "0hfU2ZFPKwwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load backup models\n",
        "for area_num in [0,1,2]:\n",
        "    orig_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2_backup.pth\"\n",
        "    dst_path = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    shutil.copy(orig_path, dst_path)\n",
        "    print(f\"loading: {os.path.basename(dst_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgP6XtWzak6R",
        "outputId": "c3835c57-ba50-414f-8782-7ee5d8bad0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: half_RepVGGA2.pth\n",
            "loading: periocular_RepVGGA2.pth\n",
            "loading: eye_RepVGGA2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#1つずつ解析するバージョン\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha=0):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    # define scaler (for fastening)\n",
        "    scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2])  #16,3,3,224,224 --> 16,3,224,224 (バッチサイズの次の次元でスライスすることによりtensorを取り出す)\n",
        "            \n",
        "            with torch.cuda.amp.autocast(): \n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "                ################\n",
        "                ##l2_normalization##\n",
        "                ################\n",
        "                l2 = torch.tensor(0., requires_grad=True)\n",
        "                for w in model.parameters():\n",
        "                    l2 = l2 + torch.norm(w)**2\n",
        "                loss = loss + alpha*l2\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer) \n",
        "            scaler.update() \n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2])\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            #print(f\"val_output: {output}\")\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "\n",
        "        \n",
        "        #Scheduler step for SGD\n",
        "        #scheduler.step() #val_lossが下がらなければ減衰\n",
        "        \n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "metadata": {
        "id": "DZny1BiR3dsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select model"
      ],
      "metadata": {
        "id": "jjrVJYPyLJCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output(half, periocular, eye, 各1層)を連結してトレーニング"
      ],
      "metadata": {
        "id": "-Bvoufo1yr04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        self.model_0 = model_ft_half\n",
        "        self.model_1 = model_ft_periocular\n",
        "        self.model_2 = model_ft_eye\n",
        "        self.fc = nn.Linear(in_features=3, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x1 = self.model_1(x1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSvjVD8U3n8T",
        "outputId": "d6fe3b14-6f09-40ba-b68a-30a7882da5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fc layer（各1408層）を直接連結してトレーニング（dropoutを追加）"
      ],
      "metadata": {
        "id": "wm0ywdRwy7VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        model_0 = model_ft_half\n",
        "        model_1 = model_ft_periocular\n",
        "        model_2 = model_ft_eye\n",
        "        self.model_0 = nn.Sequential(*list(model_0.children())[:-1])\n",
        "        self.model_1 = nn.Sequential(*list(model_1.children())[:-1])\n",
        "        self.model_2 = nn.Sequential(*list(model_2.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc = nn.Linear(in_features=1408*3, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x0 = torch.flatten(x0, 1)\n",
        "        x1 = self.model_1(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FJSZRKuQzKvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### さらに全結合層を追加"
      ],
      "metadata": {
        "id": "XnSzr6k3jJms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "area_num\n",
        "1: half \n",
        "2: periocular\n",
        "3: eye\n",
        "\"\"\"\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft = mod_RepVGG()\n",
        "model_ft.to(device)\n",
        "\n",
        "model_ft_half = model_ft\n",
        "model_ft_periocular = model_ft\n",
        "model_ft_eye = model_ft\n",
        "\n",
        "class Ensemble_three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Ensemble_three, self).__init__()\n",
        "        model_0 = model_ft_half\n",
        "        model_1 = model_ft_periocular\n",
        "        model_2 = model_ft_eye\n",
        "        self.model_0 = nn.Sequential(*list(model_0.children())[:-1])\n",
        "        self.model_1 = nn.Sequential(*list(model_1.children())[:-1])\n",
        "        self.model_2 = nn.Sequential(*list(model_2.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc1 = nn.Linear(in_features=1408*3, out_features=20)\n",
        "        self.fc2 = nn.Linear(in_features=20, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x0, x1, x2):\n",
        "        x0 = self.model_0(x0)\n",
        "        x0 = torch.flatten(x0, 1)\n",
        "        x1 = self.model_1(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "        x2 = self.model_2(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "        x = torch.cat([x0, x1, x2], dim=1)\n",
        "        x = self.fc1(x) \n",
        "        x = self.dropout(x) #dropoutを1層追加\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4m8_K8siyes",
        "outputId": "37043144-c2d4-4948-972b-12b4c8e29f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train ensemble model"
      ],
      "metadata": {
        "id": "Q4cFAvKSMHIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    del model_ft_ensemble\n",
        "    print(\"renewing modell_ft_ensemble...\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "model_ft_ensemble = Ensemble_three()\n",
        "model_ft_ensemble.to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "#optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "!pip install ranger_adabelief\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "def read_path(area_num):\n",
        "    #ネットワークの読み込み\n",
        "    PATH = f\"./models_Hertel_estimation/{AREA[area_num]}_RepVGGA2.pth\"\n",
        "    print(\"...\")\n",
        "    print(f\"loading: {os.path.basename(PATH)}\")\n",
        "    return PATH\n",
        "\n",
        "model_ft_half = model_ft.load_state_dict(torch.load(read_path(0)))\n",
        "model_ft_periocular = model_ft.load_state_dict(torch.load(read_path(1)))\n",
        "model_ft_eye = model_ft.load_state_dict(torch.load(read_path(2)))\n",
        "\n",
        "# パラメータを固定\n",
        "\n",
        "# Fix model parameters\n",
        "for param in model_ft_ensemble.parameters():\n",
        "    param.requres_grad = False\n",
        "\n",
        "try:\n",
        "    # Let fc parameters rewritable\n",
        "    for param in model_ft_ensemble.fc1.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model_ft_ensemble.fc2.parameters():\n",
        "        param.requires_grad = True\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Let fc parameters rewritable\n",
        "    for param in model_ft_ensemble.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCiRr7ss_G3i",
        "outputId": "962fff88-b173-49a3-c061-b9ee18b76718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "renewing modell_ft_ensemble...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ranger_adabelief in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger_adabelief) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger_adabelief) (4.1.1)\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "...\n",
            "loading: half_RepVGGA2.pth\n",
            "...\n",
            "loading: periocular_RepVGGA2.pth\n",
            "...\n",
            "loading: eye_RepVGGA2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model, train_loss, valid_loss = train_model(model_ft_ensemble, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "aI1dpdwc2VSp",
        "outputId": "926ecf99-9768-4cc7-aa36-90888a346228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d5b8fcfdbf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_ensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-6a0303635654>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mrunning_corrects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;31m# convert batch-size labels to batch-size x 1 tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#target = target.squeeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-aec368febf3c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtensor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtensor_image_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtensor_image_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtensor_image_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-aec368febf3c>\u001b[0m in \u001b[0;36mtensor_img\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# [tensor[path0, path1, path2], hertel_value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtensor_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mpilr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtensor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "PATH = f\"./models_Hertel_estimation/fc_ensemble.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "backup_path = f\"./models_Hertel_estimation/fc_ensemble_backup.pth\"\n",
        "shutil.copy(PATH, backup_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "suqWif1v2VU_",
        "outputId": "43ff8145-ab18-4a4c-a163-78b2e2071d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./models_Hertel_estimation/fc_ensemble_backup.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = f\"./models_Hertel_estimation/fc_ensemble.pth\"\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQwmK8WDnfOh",
        "outputId": "ae2ed462-7aea-4386-865a-8bcf73e3d1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 全ての層を書き換え可能にしてfine tuningする\n",
        "\n",
        "# Let all model parameters rewritable\n",
        "for param in model_ft_ensemble.parameters():\n",
        "    param.requres_grad = True\n",
        "\n",
        "# Train model\n",
        "model, train_loss, valid_loss = train_model(model_ft_ensemble, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "sNvccMAV0gT6",
        "outputId": "687f339f-d734-477c-832d-a34443c24a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [  1/100] \n",
            "train_loss: 156.08770 \n",
            "valid_loss: 55.77340 \n",
            "Validation loss decreased (inf --> 55.773396).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 3.82457 \n",
            "valid_loss: 54.45423 \n",
            "Validation loss decreased (55.773396 --> 54.454226).  Saving model ...\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 1.51321 \n",
            "valid_loss: 49.26537 \n",
            "Validation loss decreased (54.454226 --> 49.265373).  Saving model ...\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 1.45142 \n",
            "valid_loss: 85.19647 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 1.22514 \n",
            "valid_loss: 88.91958 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-3b9011eb2d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_ensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-144-6a0303635654>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device, alpha)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# perform a single optimization step (parameter update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# record training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ranger_adabelief/ranger_adabelief.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mp_data_fp32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_data_fp32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# integrated look ahead...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3634sCn0gpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation using validation dataset\n",
        "\n",
        "test_dataset = Create_Datasets(path_list_list, test_idx, CSV_PATH, val_data_transforms) \n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "\n",
        "def my_round(x, d=2):\n",
        "    p = Decimal(str(x)).quantize(Decimal(str(1/10**d)), rounding=ROUND_HALF_UP)\n",
        "    p = float(p)\n",
        "    return p\n",
        "\n",
        "\n",
        "model_ft_ensemble.eval() # prep model for evaluation\n",
        "\n",
        "outputs,targets,errors =[], [], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      target = target.view(len(target), 1)         \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft_ensemble(image_tensor[:,0], image_tensor[:,1], image_tensor[:,2]) #dim0はbach_size、dim1がarea_num\n",
        "\n",
        "      outputs.append(output[0].item())      \n",
        "      targets.append(target[0].item())\n",
        "      print(f\"estimate: {my_round(output[0].item())} mm, target: {target[0].item()} mm\")\n",
        "\n",
        "      errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "print('')\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYzQCiD02VXJ",
        "outputId": "008c8112-bfae-4e1e-cf1a-8e197b79bc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimate: 13.93 mm, target: 16.0 mm\n",
            "estimate: 10.97 mm, target: 12.0 mm\n",
            "estimate: 14.95 mm, target: 16.0 mm\n",
            "estimate: 14.16 mm, target: 16.0 mm\n",
            "estimate: 13.76 mm, target: 15.0 mm\n",
            "estimate: 17.25 mm, target: 19.0 mm\n",
            "estimate: 16.1 mm, target: 19.0 mm\n",
            "estimate: 11.14 mm, target: 12.0 mm\n",
            "estimate: 19.53 mm, target: 20.0 mm\n",
            "estimate: 15.94 mm, target: 19.0 mm\n",
            "estimate: 12.18 mm, target: 14.0 mm\n",
            "estimate: 19.04 mm, target: 20.0 mm\n",
            "estimate: 24.27 mm, target: 25.0 mm\n",
            "estimate: 12.08 mm, target: 13.0 mm\n",
            "estimate: 8.55 mm, target: 9.0 mm\n",
            "estimate: 18.41 mm, target: 21.0 mm\n",
            "estimate: 19.33 mm, target: 23.0 mm\n",
            "estimate: 16.5 mm, target: 20.0 mm\n",
            "estimate: 17.09 mm, target: 19.0 mm\n",
            "estimate: 16.17 mm, target: 20.0 mm\n",
            "estimate: 14.19 mm, target: 16.0 mm\n",
            "estimate: 17.25 mm, target: 21.0 mm\n",
            "estimate: 15.87 mm, target: 18.0 mm\n",
            "estimate: 19.1 mm, target: 21.0 mm\n",
            "estimate: 21.71 mm, target: 24.0 mm\n",
            "estimate: 13.35 mm, target: 14.0 mm\n",
            "estimate: 17.33 mm, target: 20.0 mm\n",
            "estimate: 15.82 mm, target: 17.0 mm\n",
            "estimate: 15.41 mm, target: 16.0 mm\n",
            "estimate: 13.79 mm, target: 16.0 mm\n",
            "estimate: 17.01 mm, target: 19.0 mm\n",
            "estimate: 13.32 mm, target: 15.0 mm\n",
            "estimate: 12.81 mm, target: 15.0 mm\n",
            "estimate: 12.59 mm, target: 13.0 mm\n",
            "estimate: 13.91 mm, target: 18.0 mm\n",
            "estimate: 13.53 mm, target: 14.0 mm\n",
            "estimate: 17.63 mm, target: 19.0 mm\n",
            "estimate: 13.22 mm, target: 16.0 mm\n",
            "estimate: 14.56 mm, target: 16.0 mm\n",
            "estimate: 20.9 mm, target: 23.0 mm\n",
            "estimate: 14.36 mm, target: 16.0 mm\n",
            "estimate: 15.98 mm, target: 19.0 mm\n",
            "estimate: 16.82 mm, target: 18.0 mm\n",
            "estimate: 12.6 mm, target: 14.0 mm\n",
            "estimate: 15.5 mm, target: 17.0 mm\n",
            "estimate: 16.34 mm, target: 15.0 mm\n",
            "estimate: 15.04 mm, target: 17.0 mm\n",
            "estimate: 14.96 mm, target: 17.0 mm\n",
            "estimate: 17.02 mm, target: 19.0 mm\n",
            "estimate: 16.26 mm, target: 18.0 mm\n",
            "estimate: 16.23 mm, target: 18.0 mm\n",
            "estimate: 11.85 mm, target: 13.0 mm\n",
            "estimate: 14.37 mm, target: 15.0 mm\n",
            "estimate: 11.32 mm, target: 12.0 mm\n",
            "estimate: 16.57 mm, target: 18.0 mm\n",
            "estimate: 13.66 mm, target: 16.0 mm\n",
            "estimate: 12.67 mm, target: 15.0 mm\n",
            "estimate: 14.34 mm, target: 15.0 mm\n",
            "estimate: 17.38 mm, target: 21.0 mm\n",
            "estimate: 14.18 mm, target: 15.0 mm\n",
            "estimate: 14.21 mm, target: 16.0 mm\n",
            "estimate: 17.12 mm, target: 18.0 mm\n",
            "estimate: 13.31 mm, target: 15.0 mm\n",
            "estimate: 18.99 mm, target: 21.0 mm\n",
            "estimate: 12.31 mm, target: 14.0 mm\n",
            "estimate: 16.05 mm, target: 18.0 mm\n",
            "estimate: 13.6 mm, target: 15.0 mm\n",
            "estimate: 18.26 mm, target: 19.0 mm\n",
            "estimate: 12.91 mm, target: 13.0 mm\n",
            "estimate: 16.71 mm, target: 17.0 mm\n",
            "estimate: 17.58 mm, target: 20.0 mm\n",
            "estimate: 11.87 mm, target: 13.0 mm\n",
            "estimate: 15.77 mm, target: 17.0 mm\n",
            "estimate: 14.45 mm, target: 16.0 mm\n",
            "estimate: 18.1 mm, target: 19.0 mm\n",
            "estimate: 19.01 mm, target: 21.0 mm\n",
            "estimate: 20.7 mm, target: 22.0 mm\n",
            "estimate: 16.74 mm, target: 18.0 mm\n",
            "estimate: 20.66 mm, target: 24.0 mm\n",
            "estimate: 14.64 mm, target: 16.0 mm\n",
            "estimate: 13.45 mm, target: 15.0 mm\n",
            "estimate: 11.8 mm, target: 12.0 mm\n",
            "estimate: 14.13 mm, target: 16.0 mm\n",
            "estimate: 18.62 mm, target: 20.5 mm\n",
            "estimate: 18.3 mm, target: 20.0 mm\n",
            "estimate: 13.69 mm, target: 15.0 mm\n",
            "estimate: 18.5 mm, target: 20.0 mm\n",
            "estimate: 14.13 mm, target: 14.0 mm\n",
            "estimate: 18.52 mm, target: 20.0 mm\n",
            "estimate: 13.96 mm, target: 17.0 mm\n",
            "estimate: 13.72 mm, target: 15.0 mm\n",
            "estimate: 15.07 mm, target: 18.0 mm\n",
            "estimate: 15.78 mm, target: 17.0 mm\n",
            "estimate: 13.48 mm, target: 16.0 mm\n",
            "estimate: 16.22 mm, target: 13.0 mm\n",
            "estimate: 14.15 mm, target: 16.0 mm\n",
            "estimate: 14.23 mm, target: 15.0 mm\n",
            "estimate: 15.26 mm, target: 18.0 mm\n",
            "estimate: 19.61 mm, target: 20.0 mm\n",
            "estimate: 15.78 mm, target: 18.0 mm\n",
            "estimate: 14.82 mm, target: 16.0 mm\n",
            "estimate: 17.4 mm, target: 19.0 mm\n",
            "estimate: 14.03 mm, target: 15.0 mm\n",
            "estimate: 19.36 mm, target: 21.0 mm\n",
            "estimate: 17.0 mm, target: 20.0 mm\n",
            "estimate: 17.45 mm, target: 20.0 mm\n",
            "estimate: 17.02 mm, target: 19.0 mm\n",
            "estimate: 17.1 mm, target: 20.0 mm\n",
            "estimate: 17.37 mm, target: 19.0 mm\n",
            "estimate: 18.98 mm, target: 21.0 mm\n",
            "estimate: 13.77 mm, target: 15.0 mm\n",
            "estimate: 15.83 mm, target: 17.0 mm\n",
            "estimate: 15.53 mm, target: 20.0 mm\n",
            "estimate: 13.25 mm, target: 15.0 mm\n",
            "estimate: 18.04 mm, target: 20.0 mm\n",
            "estimate: 15.78 mm, target: 17.0 mm\n",
            "estimate: 16.41 mm, target: 19.0 mm\n",
            "estimate: 14.94 mm, target: 20.0 mm\n",
            "estimate: 15.46 mm, target: 17.0 mm\n",
            "estimate: 17.32 mm, target: 19.0 mm\n",
            "estimate: 15.5 mm, target: 17.0 mm\n",
            "estimate: 15.62 mm, target: 21.0 mm\n",
            "estimate: 15.35 mm, target: 17.0 mm\n",
            "estimate: 18.28 mm, target: 21.0 mm\n",
            "estimate: 14.1 mm, target: 15.0 mm\n",
            "estimate: 11.5 mm, target: 12.0 mm\n",
            "estimate: 16.04 mm, target: 17.0 mm\n",
            "estimate: 14.74 mm, target: 17.0 mm\n",
            "estimate: 17.48 mm, target: 19.0 mm\n",
            "estimate: 15.33 mm, target: 17.0 mm\n",
            "estimate: 12.54 mm, target: 14.0 mm\n",
            "estimate: 15.8 mm, target: 17.0 mm\n",
            "estimate: 15.38 mm, target: 17.0 mm\n",
            "estimate: 14.67 mm, target: 15.0 mm\n",
            "estimate: 13.62 mm, target: 14.0 mm\n",
            "estimate: 16.57 mm, target: 18.0 mm\n",
            "estimate: 9.27 mm, target: 9.0 mm\n",
            "estimate: 16.91 mm, target: 18.0 mm\n",
            "estimate: 11.57 mm, target: 12.0 mm\n",
            "estimate: 12.77 mm, target: 14.0 mm\n",
            "estimate: 15.93 mm, target: 17.0 mm\n",
            "estimate: 13.79 mm, target: 15.0 mm\n",
            "estimate: 10.37 mm, target: 11.0 mm\n",
            "estimate: 17.84 mm, target: 20.0 mm\n",
            "estimate: 18.99 mm, target: 18.0 mm\n",
            "estimate: 12.52 mm, target: 14.0 mm\n",
            "estimate: 17.55 mm, target: 19.0 mm\n",
            "estimate: 15.55 mm, target: 17.0 mm\n",
            "estimate: 17.94 mm, target: 19.0 mm\n",
            "estimate: 14.94 mm, target: 17.0 mm\n",
            "estimate: 15.33 mm, target: 15.0 mm\n",
            "estimate: 15.66 mm, target: 17.0 mm\n",
            "estimate: 15.96 mm, target: 16.0 mm\n",
            "estimate: 11.73 mm, target: 12.0 mm\n",
            "estimate: 17.28 mm, target: 18.0 mm\n",
            "estimate: 21.1 mm, target: 23.0 mm\n",
            "estimate: 13.4 mm, target: 15.0 mm\n",
            "estimate: 10.18 mm, target: 12.0 mm\n",
            "estimate: 16.71 mm, target: 19.0 mm\n",
            "estimate: 13.57 mm, target: 14.0 mm\n",
            "estimate: 13.16 mm, target: 15.0 mm\n",
            "estimate: 11.56 mm, target: 15.0 mm\n",
            "estimate: 12.72 mm, target: 15.0 mm\n",
            "estimate: 10.27 mm, target: 11.0 mm\n",
            "estimate: 10.06 mm, target: 10.0 mm\n",
            "estimate: 12.11 mm, target: 13.0 mm\n",
            "estimate: 11.36 mm, target: 12.0 mm\n",
            "estimate: 15.22 mm, target: 17.0 mm\n",
            "estimate: 15.44 mm, target: 17.0 mm\n",
            "estimate: 15.46 mm, target: 17.0 mm\n",
            "estimate: 16.01 mm, target: 20.0 mm\n",
            "estimate: 15.3 mm, target: 17.0 mm\n",
            "estimate: 16.39 mm, target: 17.0 mm\n",
            "estimate: 12.52 mm, target: 14.0 mm\n",
            "estimate: 15.84 mm, target: 18.0 mm\n",
            "estimate: 12.57 mm, target: 14.0 mm\n",
            "estimate: 12.83 mm, target: 16.0 mm\n",
            "estimate: 13.62 mm, target: 15.0 mm\n",
            "estimate: 17.45 mm, target: 20.0 mm\n",
            "estimate: 14.81 mm, target: 16.0 mm\n",
            "estimate: 14.18 mm, target: 16.0 mm\n",
            "estimate: 19.02 mm, target: 20.0 mm\n",
            "estimate: 15.39 mm, target: 17.0 mm\n",
            "estimate: 15.1 mm, target: 18.0 mm\n",
            "estimate: 14.73 mm, target: 18.0 mm\n",
            "estimate: 20.03 mm, target: 18.0 mm\n",
            "estimate: 17.78 mm, target: 19.0 mm\n",
            "estimate: 12.68 mm, target: 12.0 mm\n",
            "estimate: 14.38 mm, target: 14.0 mm\n",
            "estimate: 13.59 mm, target: 13.0 mm\n",
            "estimate: 14.43 mm, target: 17.0 mm\n",
            "estimate: 14.96 mm, target: 17.0 mm\n",
            "estimate: 12.54 mm, target: 15.0 mm\n",
            "estimate: 12.96 mm, target: 13.0 mm\n",
            "estimate: 15.68 mm, target: 10.0 mm\n",
            "estimate: 16.33 mm, target: 18.0 mm\n",
            "AveError: -1.522510372862524\n",
            "StdError: 1.2268599775878566\n",
            "AveAbsError: 1.6827616983530473\n",
            "StdAbsError: 0.9944356232046988\n",
            "\n",
            "Corrected_AveAbsError: 0.8255372273827631\n",
            "Corrected_StdAbsError: 0.9056372115513152\n",
            "Round_Corrected_AveAbsError: 0.8254081632653061\n",
            "Round_Corrected_StdAbsError: 0.9057810550723012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw Graphs（もともとの散布図\n",
        "df_ensemble = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df_ensemble)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Li8BDOr12VZa",
        "outputId": "53b26515-c71a-462f-b7c9-7ca1e79e7694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.0, 24.0)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df_ensemble['target']-df_ensemble['estimate'], bins=15, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "DA4wwJtT2Vbj",
        "outputId": "55389ae8-9eea-49d5-e45a-84265ee8e42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(df_ensemble)\n",
        "within1 = sum((i <= 1 and i >= -1 for i in df_ensemble['estimate']-df_ensemble['target']))\n",
        "within2 = sum((i <= 2 and i >= -2 for i in df_ensemble['estimate']-df_ensemble['target']))\n",
        "over2 = sum((i > 2 or i < -2 for i in df['estimate']-df['target']))\n",
        "\n",
        "print(f'-1<Error<1: {within1}, ({my_round(within1/total*100)}%)')\n",
        "print(f'-2<Error<2: {within1}, ({my_round(within2/total*100)}%)')\n",
        "print(f'Error over 2: {within1}, ({my_round(over2/total*100)}%)')\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df_ensemble)):\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]>= 18:\n",
        "        TP += 1\n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]>= 18:\n",
        "        FN += 1\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]< 18:\n",
        "        FP += 1 \n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df_ensemble)):\n",
        "    if df_ensemble.iloc[i,0]>=16 and df_ensemble.iloc[i,1]> 18:\n",
        "        okpositive += 1\n",
        "    if df_ensemble.iloc[i,0]<16 and df_ensemble.iloc[i,1]>= 18:\n",
        "        minogashi += 1\n",
        "    if df_ensemble.iloc[i,0]>=18 and df_ensemble.iloc[i,1]<= 16:\n",
        "        kajyou += 1 \n",
        "    if df_ensemble.iloc[i,0]<18 and df_ensemble.iloc[i,1]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5JBKBJ2Vdp",
        "outputId": "138f3ffd-c30c-4fe5-af74-cc4d0d786bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1<Error<1: 48, (24.49%)\n",
            "-2<Error<2: 48, (71.43%)\n",
            "Error over 2: 48, (15.31%)\n",
            "\n",
            "Hertel 18mm以上の検出精度\n",
            "TP: 27\n",
            "FP: 0\n",
            "FN: 52\n",
            "TN: 117\n",
            "Sensitivity: 0.34177215189873417\n",
            "Specificity: 1.0\n",
            "Positive predictive value: 1.0\n",
            "Negative predictive value: 0.6923076923076923\n",
            "\n",
            "推測18mm以上だが実は16mm未満(過剰): 0例\n",
            "推測16mm未満だが実は18mm以上（見逃がし）: 13例\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "3bdeNzKQ2Vfz",
        "outputId": "60708a03-8ea1-4b18-bf2a-623edf358495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsMX4OLR2Vh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZ6K3ah3_G7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3uDlMtU3oFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated 5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "h1pCIJY5NeiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['target', 'fold0', 'fold1', 'fold2', 'fold3', 'fold4', 'fold0_corrected', 'fold1_corrected', 'fold2_corrected', 'fold3_corrected', 'fold4_corrected',]\n",
        "df_result = pd.DataFrame(index=[], columns=cols)\n",
        "\n",
        "cols = ['AveError', 'AveStdError', 'AveAbsError', 'StdAbsError', 'Corrected_AveAbsError', 'Corrected_StdAbsError', 'Round_Corrected_AveAbsError', 'Round_Corrected_StdAbsError']\n",
        "indices = ['fold0', 'fold1', 'fold2', 'fold3', 'fold4']\n",
        "df_summary = pd.DataFrame(index=indices, columns=cols)"
      ],
      "metadata": {
        "id": "akk3glokkBIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_start = 0 #スタートするfold\n",
        "dst_result_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_result.csv\"\n",
        "dst_summary_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_summary.csv\"\n",
        "\n",
        "#四捨五入のモジュール\n",
        "def my_round(x, d=0):\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "for fold in range(fold_start,5,1):    \n",
        "    ###############\n",
        "    ##Define model ##\n",
        "    ###############\n",
        "\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "    model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), lr=1e-5)\n",
        "    alpha = 1e-6 #l2_normalization\n",
        "\n",
        "    #################\n",
        "    ## select dataset ##\n",
        "    ################\n",
        "    train_dataset = Create_Datasets(train_set[fold], CSV_PATH, train_data_transforms)\n",
        "    val_dataset = Create_Datasets(val_set[fold], CSV_PATH, val_data_transforms)\n",
        "    test_dataset = Create_Datasets(test_set, CSV_PATH, val_data_transforms) \n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "    #################\n",
        "    ## train model ##\n",
        "    #################\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE,optimizer_ft, PATIENCE, EPOCH, device, alpha)\n",
        "\n",
        "    ####################\n",
        "    ## Draw learning curve ##\n",
        "    ####################\n",
        "\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss', color=\"#377eb8\")\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss', color=\"#ff7f00\")\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, 10.0) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot(Hertel)_fold'+str(fold)+'.png', bbox_inches='tight', dpi=350)\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ## eval using validation dataset ##\n",
        "    ###########################\n",
        "\n",
        "    #evaluation using validation dataset (1枚ずつevalする)\n",
        "    val_dataset = Create_Datasets(val_set[fold], CSV_PATH, val_data_transforms)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = 1)\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "\n",
        "    print('fold '+str(fold))\n",
        "    print('')\n",
        "    print('--evaluation using val dataset--')\n",
        "    print('AveError: '+str(statistics.mean(errors)))\n",
        "    print('StdError: '+str(statistics.stdev(errors)))\n",
        "    print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "    print('')\n",
        "\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "    corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "    round_output = [my_round(i) for i in outputs]\n",
        "    round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "    print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "    print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "    print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n",
        "    print('')\n",
        "    ###########################\n",
        "    ## eval using test dataset ##\n",
        "    ###########################\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in test_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append(output[0].item())      \n",
        "          targets.append(target[0].item())\n",
        "          errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "\n",
        "    \n",
        "    print('--evaluation using test dataset--')\n",
        "    print('AveError: '+str(statistics.mean(errors)))\n",
        "    print('StdError: '+str(statistics.stdev(errors)))\n",
        "    print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "    print('')\n",
        "\n",
        "\n",
        "    #平均からの差分を補正\n",
        "    corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "    corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "    corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "    round_output = [my_round(i) for i in outputs]\n",
        "    round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "    print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "    print('Round_Corrected_AveAbsError: '+str(statistics.mean(round_corrected_AbsError)))\n",
        "    print('Round_Corrected_StdAbsError: '+str(statistics.stdev(round_corrected_AbsError)))\n",
        "    print('')\n",
        "    print('')\n",
        "\n",
        "    #結果をdataframeに書き込む\n",
        "    df_result['target'] = targets\n",
        "    df_result['fold'+str(fold)] = outputs\n",
        "    df_result['fold'+str(fold)+'_corrected'] = corrected_output\n",
        "    df_summary.iloc[fold, 0] = statistics.mean(errors)\n",
        "    df_summary.iloc[fold, 1] = statistics.stdev(errors)\n",
        "    df_summary.iloc[fold, 2] = statistics.mean(AbsError)\n",
        "    df_summary.iloc[fold, 3] = statistics.stdev(AbsError)\n",
        "    df_summary.iloc[fold, 4] = statistics.mean(corrected_AbsError)\n",
        "    df_summary.iloc[fold, 5] = statistics.stdev(corrected_AbsError)\n",
        "    df_summary.iloc[fold, 6] = statistics.mean(round_corrected_AbsError)\n",
        "    df_summary.iloc[fold, 7] = statistics.stdev(round_corrected_AbsError)\n",
        "\n",
        "    df_result.to_csv(dst_result_path,index=False)\n",
        "    df_summary.to_csv(dst_summary_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "5O9JFMDTjHRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_result_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/Hertel_estimation_result_1.csv\"\n",
        "\n",
        "#Open reslut_csv\n",
        "with codecs.open(dst_result_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "    df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "df_result"
      ],
      "metadata": {
        "id": "6qPNRLAhs9nY",
        "outputId": "6a9800bd-0e41-46b0-fcba-121b5eea96ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     target      fold0      fold1      fold2      fold3      fold4  \\\n",
              "0      16.0  18.274897  18.086258  16.982693  16.731331  18.360825   \n",
              "1      16.0  18.240702  16.648167  17.850836  19.017797  18.382151   \n",
              "2      16.0  18.401655  16.097504  17.015856  16.246473  16.902615   \n",
              "3      16.0  16.841370  16.170847  17.116571  17.318340  19.125807   \n",
              "4      21.0  19.725548  21.173748  20.488394  20.001635  20.520454   \n",
              "..      ...        ...        ...        ...        ...        ...   \n",
              "199    17.0  14.232739  13.812715  14.326204  13.889405  14.692945   \n",
              "200    19.0  21.097057  21.475121  20.992577  21.097054  20.442337   \n",
              "201    19.0  20.500013  18.138063  18.657246  19.152702  19.862629   \n",
              "202    15.0  17.755945  17.409885  16.379116  16.741234  16.965052   \n",
              "203    15.0  15.876468  17.173515  15.093376  14.462296  16.130594   \n",
              "\n",
              "     fold0_corrected  fold1_corrected  fold2_corrected  fold3_corrected  \\\n",
              "0          17.683797        18.048479        17.346565        16.704272   \n",
              "1          17.649602        16.610387        18.214708        18.990738   \n",
              "2          17.810555        16.059725        17.379728        16.219414   \n",
              "3          16.250270        16.133068        17.480444        17.291281   \n",
              "4          19.134448        21.135969        20.852266        19.974575   \n",
              "..               ...              ...              ...              ...   \n",
              "199        13.641640        13.774935        14.690077        13.862346   \n",
              "200        20.505957        21.437341        21.356449        21.069994   \n",
              "201        19.908913        18.100284        19.021118        19.125643   \n",
              "202        17.164845        17.372106        16.742989        16.714175   \n",
              "203        15.285368        17.135736        15.457249        14.435236   \n",
              "\n",
              "     fold4_corrected  \n",
              "0          18.388139  \n",
              "1          18.409465  \n",
              "2          16.929929  \n",
              "3          19.153122  \n",
              "4          20.547769  \n",
              "..               ...  \n",
              "199        14.720260  \n",
              "200        20.469652  \n",
              "201        19.889944  \n",
              "202        16.992366  \n",
              "203        16.157909  \n",
              "\n",
              "[204 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71713c29-0ea2-4991-beeb-69d28c5d665f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>fold0</th>\n",
              "      <th>fold1</th>\n",
              "      <th>fold2</th>\n",
              "      <th>fold3</th>\n",
              "      <th>fold4</th>\n",
              "      <th>fold0_corrected</th>\n",
              "      <th>fold1_corrected</th>\n",
              "      <th>fold2_corrected</th>\n",
              "      <th>fold3_corrected</th>\n",
              "      <th>fold4_corrected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.274897</td>\n",
              "      <td>18.086258</td>\n",
              "      <td>16.982693</td>\n",
              "      <td>16.731331</td>\n",
              "      <td>18.360825</td>\n",
              "      <td>17.683797</td>\n",
              "      <td>18.048479</td>\n",
              "      <td>17.346565</td>\n",
              "      <td>16.704272</td>\n",
              "      <td>18.388139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.240702</td>\n",
              "      <td>16.648167</td>\n",
              "      <td>17.850836</td>\n",
              "      <td>19.017797</td>\n",
              "      <td>18.382151</td>\n",
              "      <td>17.649602</td>\n",
              "      <td>16.610387</td>\n",
              "      <td>18.214708</td>\n",
              "      <td>18.990738</td>\n",
              "      <td>18.409465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>18.401655</td>\n",
              "      <td>16.097504</td>\n",
              "      <td>17.015856</td>\n",
              "      <td>16.246473</td>\n",
              "      <td>16.902615</td>\n",
              "      <td>17.810555</td>\n",
              "      <td>16.059725</td>\n",
              "      <td>17.379728</td>\n",
              "      <td>16.219414</td>\n",
              "      <td>16.929929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>16.841370</td>\n",
              "      <td>16.170847</td>\n",
              "      <td>17.116571</td>\n",
              "      <td>17.318340</td>\n",
              "      <td>19.125807</td>\n",
              "      <td>16.250270</td>\n",
              "      <td>16.133068</td>\n",
              "      <td>17.480444</td>\n",
              "      <td>17.291281</td>\n",
              "      <td>19.153122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>19.725548</td>\n",
              "      <td>21.173748</td>\n",
              "      <td>20.488394</td>\n",
              "      <td>20.001635</td>\n",
              "      <td>20.520454</td>\n",
              "      <td>19.134448</td>\n",
              "      <td>21.135969</td>\n",
              "      <td>20.852266</td>\n",
              "      <td>19.974575</td>\n",
              "      <td>20.547769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>17.0</td>\n",
              "      <td>14.232739</td>\n",
              "      <td>13.812715</td>\n",
              "      <td>14.326204</td>\n",
              "      <td>13.889405</td>\n",
              "      <td>14.692945</td>\n",
              "      <td>13.641640</td>\n",
              "      <td>13.774935</td>\n",
              "      <td>14.690077</td>\n",
              "      <td>13.862346</td>\n",
              "      <td>14.720260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>19.0</td>\n",
              "      <td>21.097057</td>\n",
              "      <td>21.475121</td>\n",
              "      <td>20.992577</td>\n",
              "      <td>21.097054</td>\n",
              "      <td>20.442337</td>\n",
              "      <td>20.505957</td>\n",
              "      <td>21.437341</td>\n",
              "      <td>21.356449</td>\n",
              "      <td>21.069994</td>\n",
              "      <td>20.469652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>19.0</td>\n",
              "      <td>20.500013</td>\n",
              "      <td>18.138063</td>\n",
              "      <td>18.657246</td>\n",
              "      <td>19.152702</td>\n",
              "      <td>19.862629</td>\n",
              "      <td>19.908913</td>\n",
              "      <td>18.100284</td>\n",
              "      <td>19.021118</td>\n",
              "      <td>19.125643</td>\n",
              "      <td>19.889944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>15.0</td>\n",
              "      <td>17.755945</td>\n",
              "      <td>17.409885</td>\n",
              "      <td>16.379116</td>\n",
              "      <td>16.741234</td>\n",
              "      <td>16.965052</td>\n",
              "      <td>17.164845</td>\n",
              "      <td>17.372106</td>\n",
              "      <td>16.742989</td>\n",
              "      <td>16.714175</td>\n",
              "      <td>16.992366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>15.0</td>\n",
              "      <td>15.876468</td>\n",
              "      <td>17.173515</td>\n",
              "      <td>15.093376</td>\n",
              "      <td>14.462296</td>\n",
              "      <td>16.130594</td>\n",
              "      <td>15.285368</td>\n",
              "      <td>17.135736</td>\n",
              "      <td>15.457249</td>\n",
              "      <td>14.435236</td>\n",
              "      <td>16.157909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71713c29-0ea2-4991-beeb-69d28c5d665f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71713c29-0ea2-4991-beeb-69d28c5d665f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71713c29-0ea2-4991-beeb-69d28c5d665f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5-foldのICC(2,1)とp-valueを算出\n",
        "target = df_result[\"target\"]\n",
        "fold0 = df_result[\"fold0_corrected\"]\n",
        "fold1 = df_result[\"fold1_corrected\"]\n",
        "fold2 = df_result[\"fold2_corrected\"]\n",
        "fold3 = df_result[\"fold3_corrected\"]\n",
        "fold4 = df_result[\"fold4_corrected\"]\n",
        "\n",
        "ICC_list, pval_list , ave_list, std_list, ttest_list= [], [], [], [], []\n",
        "for fold in [fold0,fold1,fold2,fold3,fold4]:\n",
        "    ratings = np.concatenate([target,fold])\n",
        "    raters = ['target'] * len(target) + ['pred'] *len(fold)\n",
        "    targets = [i for i in range(len(target))]+[i for i in range(len(target))]\n",
        "\n",
        "    data = pd.DataFrame({'targets':targets, 'raters':raters, 'ratings':ratings})\n",
        "    icc = pg.intraclass_corr(data=data, targets='targets', \n",
        "                            raters='raters', ratings='ratings')\n",
        "    df_icc = icc.set_index('Type')\n",
        "    ICC_list.append(df_icc.loc[\"ICC2\",\"ICC\"])\n",
        "    pval_list.append(df_icc.loc[\"ICC2\",\"pval\"])\n",
        "    ave_list.append(statistics.mean(fold))\n",
        "    std_list.append(statistics.stdev(fold))\n",
        "    ttest_list.append(stats.ttest_rel(target, fold)[1])\n",
        "\n",
        "\n",
        "print(\"target: {}±{}\".format(statistics.mean(target), statistics.stdev(target)))\n",
        "print(\"folds: {}±{}\".format(statistics.mean(ave_list), statistics.mean(std_list)))\n",
        "print(\"p-value (ttest): {}\".format(statistics.mean(ttest_list)))\n",
        "print(\"ICC(2,1): {}±{}\".format(statistics.mean(ICC_list), statistics.stdev(ICC_list)))\n",
        "print(\"p-value (ICC): {}\".format(statistics.mean(pval_list)))\n"
      ],
      "metadata": {
        "id": "FSm7VDfYwBwj",
        "outputId": "c730e3ed-f856-48eb-b1be-80a16cb7a591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target: 16.86519607843137±2.7894442938967283\n",
            "folds: 16.86519607845098±2.3422292408301435\n",
            "p-value (ttest): 0.9999999991062075\n",
            "ICC(2,1): 0.704768158145101±0.030114555646246675\n",
            "p-value (ICC): 3.4573877614181293e-29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate residual error\n",
        "df_result[\"fold0_residual_error\"] = df_result[\"fold0_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold1_residual_error\"] = df_result[\"fold1_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold2_residual_error\"] = df_result[\"fold2_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold3_residual_error\"] = df_result[\"fold3_corrected\"] - df_result[\"target\"]\n",
        "df_result[\"fold4_residual_error\"] = df_result[\"fold4_corrected\"] - df_result[\"target\"]\n",
        "\n",
        "under1mm_list, under2mm_list, sensitivity_list, specificity_list = [], [], [], []\n",
        "k=0\n",
        "for fold in [fold0, fold1, fold2, fold3, fold4]: \n",
        "    print(\"fold {}\".format(k))\n",
        "    print(\"\")\n",
        "\n",
        "    ########################\n",
        "    ##Draw Graphs（散布図)##\n",
        "    ########################\n",
        "    df = pd.DataFrame({'estimate':fold, 'target':target})\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.set_palette('gray')\n",
        "    sns.lmplot(x='estimate', y='target', data=df)\n",
        "    plt.xlim(10,24)\n",
        "    plt.ylim(10,24)\n",
        "    plt.title('Scatter Plot')\n",
        "    plt.show()\n",
        "\n",
        "    ###########################################\n",
        "    ##Bland-Altman-Plot using corrected value##\n",
        "    ###########################################\n",
        "    def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "        data1     = np.asarray(data1)\n",
        "        data2     = np.asarray(data2)\n",
        "        mean      = np.mean([data1, data2], axis=0)\n",
        "        diff      = data1 - data2                   # Difference between data1 and data2\n",
        "        md        = np.mean(diff)                   # Mean of the difference\n",
        "        sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "        plt.scatter(mean, diff, *args, **kwargs)\n",
        "        plt.axhline(md,           color='gray', linestyle='--')\n",
        "        plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "        plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "    corrected_estimate = fold\n",
        "    target = df.loc[:,'target']\n",
        "\n",
        "    bland_altman_plot(corrected_estimate, target)\n",
        "    plt.title('Bland-Altman Plot')\n",
        "    plt.show()\n",
        "\n",
        "    ####################\n",
        "    ## Draw histogram ##\n",
        "    ####################\n",
        "    sns.distplot(\n",
        "    df_result['fold'+str(k)+'_residual_error'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        "    )\n",
        "    plt.legend() # 凡例を表示\n",
        "    plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "    #Draw Graphs\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.set_palette('gray')\n",
        "    sns.lmplot(x='fold'+str(k)+\"_corrected\", y='target', data=df_result)\n",
        "    plt.xlim(10,24)\n",
        "    plt.ylim(10,24)\n",
        "\n",
        "    corrected_AbsError = [abs(i) for i in df_result['fold'+str(k)+'_residual_error']]\n",
        "    print('AveError: '+str(statistics.mean(df_result['fold'+str(k)+'_residual_error'])))\n",
        "    print('StdError: '+str(statistics.stdev(df_result['fold'+str(k)+'_residual_error'])))\n",
        "    print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "    print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "\n",
        "    print('')\n",
        "    print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('Error<=-2: ' +  str(sum((i <= -2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "    print('Error>=2: ' +  str(sum((i >= 2 for i in df_result['fold'+str(k)+'_residual_error']))))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN = 0,0,0,0\n",
        "    for i in range(len(df_result)):\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]>= 18:\n",
        "            TP += 1\n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]>= 18:\n",
        "            FP += 1\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]< 18:\n",
        "            FN += 1 \n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+\"_corrected\"]< 18:\n",
        "            TN += 1     \n",
        "\n",
        "    print('')\n",
        "    print('Hertel 18mm以上の検出精度')\n",
        "    print('TP: '+str(TP))\n",
        "    print('FP: '+str(FP))\n",
        "    print('FN: '+str(FN))\n",
        "    print('TN: '+str(TN))\n",
        "    print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "    print('Specificity: '+str(TN/(FP+TN)))\n",
        "    print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "    print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "    okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "    for i in range(len(df)):\n",
        "        if df_result.loc[i,\"target\"]>=16 and df_result.loc[i,'fold'+str(k)+'_corrected']> 18:\n",
        "            okpositive += 1\n",
        "        if df_result.loc[i,\"target\"]<16 and df_result.loc[i,'fold'+str(k)+'_corrected']>= 18:\n",
        "            kajyou += 1\n",
        "        if df_result.loc[i,\"target\"]>=18 and df_result.loc[i,'fold'+str(k)+'_corrected']<= 16:\n",
        "            minogashi += 1 \n",
        "        if df_result.loc[i,\"target\"]<18 and df_result.loc[i,'fold'+str(k)+'_corrected']<= 16:\n",
        "            oknegative += 1     \n",
        "\n",
        "    print('')\n",
        "    print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "    print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    under1mm_list.append(sum((i < 1 and i > -1 for i in df_result['fold'+str(k)+'_residual_error']))/len(target))\n",
        "    under2mm_list.append(sum((i < 2 and i > -2 for i in df_result['fold'+str(k)+'_residual_error']))/len(target))\n",
        "    sensitivity_list.append(TP/(TP+FN))\n",
        "    specificity_list.append(TN/(FP+TN))\n",
        "    k+=1\n",
        "\n",
        "print(\"under1mm: {}±{}\".format(statistics.mean(under1mm_list), statistics.stdev(under1mm_list)))\n",
        "print(\"under2mm: {}±{}\".format(statistics.mean(under2mm_list), statistics.stdev(under2mm_list)))\n",
        "print(\"Sensitivity: {}±{}\".format(statistics.mean(sensitivity_list), statistics.stdev(sensitivity_list)))\n",
        "print(\"Specificity: {}±{}\".format(statistics.mean(specificity_list), statistics.stdev(specificity_list)))"
      ],
      "metadata": {
        "id": "oiaPxhIb-I9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9uu8S7EAhSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}