{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled72.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Olympia_Hertel_estimation_RepVGGdropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJiUlScYrIgg"
      },
      "source": [
        "#**Olympia_Hertel_estimation_RepVGG-A2**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ1FDbAxrAsn",
        "outputId": "fd0e8479-9ab5-48e6-86d4-ec377fcf21a8"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import statistics\n",
        "import math\n",
        "import shutil\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "random_seed = 1 #shuffleのシード\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def torch_fix_seed(seed):\n",
        "    print(\"Random Seed: \", seed)\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "torch_fix_seed(seed=1)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "黒の空白を挿入することにより500px*500pxの画像を生成\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "Olympia_dataset----dataset_500px_divided----train (72%)\n",
        "                                            |\n",
        "                                            |--val (18%)\n",
        "                                            |\n",
        "                                            |--test (10%)\n",
        "\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Random Seed:  1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XD7y5oqsMwg"
      },
      "source": [
        "#**Set Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Er_Gm6sRDv"
      },
      "source": [
        "path = '/content/drive/MyDrive/Deep_learning/Olympia_dataset'\n",
        "os.chdir(path)\n",
        "\n",
        "# grav or cont, age, and sex\n",
        "#NUM_CLASSES = 3\n",
        "\n",
        "# contains train, val\n",
        "#DATASET_PATH = r\"./dataset_500px\"\n",
        "DATASET_PATH = r\"./dataset_500px_uni\"\n",
        "#TRAIN_FOLDER_NAME = \"train\"\n",
        "#VAL_FOLDER_NAME = \"val\"\n",
        "#EFFICIENT_NET_NAME = \"RepVGG-A2-train\"\n",
        "MODEL_PATH = \"./RepVGG-A2-train.pth\"\n",
        "CSV_PATH = \"./Hertel_unilateral.csv\"\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "#SEX_DICT_PATH = \"gender_json\"\n",
        "#AGE_DICT_PATH = \"age_json\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "#CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# transforms param　　左右分けているのでflipはしない\n",
        "PX = 224\n",
        "TRAIN_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "ROTATION_DEGREES = 3\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "\n",
        "VAL_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                #transforms.RandomRotation(ROTATION_DEGREES),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])]) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5-Foldに分割**"
      ],
      "metadata": {
        "id": "aLBpMuFwhz1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    #id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    id_list = [os.path.basename(name).split(\".\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "path_list = make_path_list(DATASET_PATH)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "id = extract_ids(path_list)\n",
        "\n",
        "print(\"patiend num: {}\".format(len(id)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZXXWIO9k9Cq",
        "outputId": "670ddd59-100f-42f8-80df-49ff7dc18bb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patiend num: 2032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5 #number of folds\n",
        "\n",
        "#fold数だけ空のリストを作成\n",
        "train_set, val_set =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "#まず全体の1割をテストセットとしてよけておく\n",
        "remain_set, test_set = train_test_split(path_list, test_size=0.1, shuffle=True, random_state=random_seed) \n",
        "\n",
        "i=0\n",
        "for train_idxs, val_idxs in kf.split(remain_set):\n",
        "    for idx in train_idxs:\n",
        "        train_set[i].append(remain_set[idx])\n",
        "    for idx in val_idxs:\n",
        "        val_set[i].append(remain_set[idx])\n",
        "    i+=1\n",
        "\n",
        "print(\"train_dataset: {}\".format(len(train_set[0])))\n",
        "print(\"val_dataset: {}\".format(len(val_set[0])))\n",
        "print(\"test_dataset: {}\".format(len(test_set)))\n",
        "print(\"\")\n",
        "print(\"extracted_id (example): {}\".format(extract_ids(test_set)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm3s5AMRh6U1",
        "outputId": "3624d4ad-5885-4a12-ddcc-4a5602ee7360"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset: 1462\n",
            "val_dataset: 366\n",
            "test_dataset: 204\n",
            "\n",
            "extracted_id (example): 512_R\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GURyJLkrtsx"
      },
      "source": [
        "#**Create Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Create_Datasets(Dataset):\n",
        "     \n",
        "    def __init__(self, img_list, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        df = self.df\n",
        "\n",
        "        k=0\n",
        "        for image_path in img_list:\n",
        "            base_name = os.path.splitext(os.path.basename(image_path))[0] #フォルダより画像番号を抜き出す\n",
        "            hertel = df[df['number']==str(base_name)].iloc[0,1] #CSV上で一致した番号の画像についてHertel値を抜き出す\n",
        "            self.item_paths.append([image_path, hertel]) #[path, hertel]の組み合わせをリストに追加する\n",
        "            item_paths = self.item_paths\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "     \n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.item_paths[index][0]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image).float()\n",
        "        hertel = self.item_paths[index][1]\n",
        "        target= torch.tensor([hertel]).float()\n",
        "        return  tensor_image, target\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = Create_Datasets(train_set[0], CSV_PATH, train_data_transforms)\n",
        "val_dataset = Create_Datasets(val_set[0], CSV_PATH, val_data_transforms)\n",
        "test_dataset = Create_Datasets(test_set, CSV_PATH, val_data_transforms) \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1)\n",
        "\n",
        "print('train_dataset_size: ' +str(len(train_dataset)))\n",
        "print('val_dataset_size: ' +str(len(val_dataset)))\n",
        "print('test_dataset_size: ' +str(len(test_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXqKg2jfswY3",
        "outputId": "6748ce8c-93c2-4fa4-ca2a-4e16455ca449"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_size: 1462\n",
            "val_dataset_size: 366\n",
            "test_dataset_size: 204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dmPkFnjiUXJ"
      },
      "source": [
        "print(train_dataset[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMch8ogOX1X6"
      },
      "source": [
        "#**Test with early-stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IIK64KHX1nA"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXAxIikRdQEu"
      },
      "source": [
        "#**define RepVGG-A2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZk-1LhdQTK"
      },
      "source": [
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.dropout = nn.Dropout(0.25) #Define proportion or neurons to dropout\n",
        "        self.fc1 = nn.Linear(in_features=1408, out_features=512) #out_featuresを1に\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=1) #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYO37TYHeFwG"
      },
      "source": [
        "#**ConvNetの調整**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6p9djzEeF7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ec01bb-3a1e-4e53-f8aa-aba07be48564"
      },
      "source": [
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lPDAqyEEx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e17f29c-28e3-4ae5-97e0-f6c1093267d1"
      },
      "source": [
        "model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [  1/100] \n",
            "train_loss: 23.34435 \n",
            "valid_loss: 7.86177 \n",
            "Validation loss decreased (inf --> 7.861765).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 6.28841 \n",
            "valid_loss: 7.53396 \n",
            "Validation loss decreased (7.861765 --> 7.533961).  Saving model ...\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 4.93534 \n",
            "valid_loss: 6.23126 \n",
            "Validation loss decreased (7.533961 --> 6.231261).  Saving model ...\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 4.86351 \n",
            "valid_loss: 4.95040 \n",
            "Validation loss decreased (6.231261 --> 4.950404).  Saving model ...\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 4.48180 \n",
            "valid_loss: 5.31333 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  6/100] \n",
            "train_loss: 4.27662 \n",
            "valid_loss: 4.13301 \n",
            "Validation loss decreased (4.950404 --> 4.133015).  Saving model ...\n",
            "\n",
            "Epoch: [  7/100] \n",
            "train_loss: 4.17237 \n",
            "valid_loss: 3.77444 \n",
            "Validation loss decreased (4.133015 --> 3.774444).  Saving model ...\n",
            "\n",
            "Epoch: [  8/100] \n",
            "train_loss: 4.01245 \n",
            "valid_loss: 4.27071 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  9/100] \n",
            "train_loss: 3.92990 \n",
            "valid_loss: 4.06380 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 10/100] \n",
            "train_loss: 3.88587 \n",
            "valid_loss: 3.96483 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 11/100] \n",
            "train_loss: 3.81391 \n",
            "valid_loss: 3.87354 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 12/100] \n",
            "train_loss: 3.18523 \n",
            "valid_loss: 3.68574 \n",
            "Validation loss decreased (3.774444 --> 3.685744).  Saving model ...\n",
            "\n",
            "Epoch: [ 13/100] \n",
            "train_loss: 3.26367 \n",
            "valid_loss: 3.80290 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 14/100] \n",
            "train_loss: 3.21864 \n",
            "valid_loss: 5.20500 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 15/100] \n",
            "train_loss: 3.33774 \n",
            "valid_loss: 4.23548 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 16/100] \n",
            "train_loss: 3.10612 \n",
            "valid_loss: 4.43897 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 17/100] \n",
            "train_loss: 2.86729 \n",
            "valid_loss: 4.60408 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "Epoch: [ 18/100] \n",
            "train_loss: 2.83432 \n",
            "valid_loss: 3.73718 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "Epoch: [ 19/100] \n",
            "train_loss: 2.67120 \n",
            "valid_loss: 4.01762 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "Epoch: [ 20/100] \n",
            "train_loss: 2.76664 \n",
            "valid_loss: 3.41012 \n",
            "Validation loss decreased (3.685744 --> 3.410120).  Saving model ...\n",
            "\n",
            "Epoch: [ 21/100] \n",
            "train_loss: 2.60427 \n",
            "valid_loss: 4.92863 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 22/100] \n",
            "train_loss: 2.49991 \n",
            "valid_loss: 4.22181 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 23/100] \n",
            "train_loss: 2.69708 \n",
            "valid_loss: 3.31867 \n",
            "Validation loss decreased (3.410120 --> 3.318667).  Saving model ...\n",
            "\n",
            "Epoch: [ 24/100] \n",
            "train_loss: 2.51750 \n",
            "valid_loss: 3.88206 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 25/100] \n",
            "train_loss: 2.51944 \n",
            "valid_loss: 3.29647 \n",
            "Validation loss decreased (3.318667 --> 3.296468).  Saving model ...\n",
            "\n",
            "Epoch: [ 26/100] \n",
            "train_loss: 2.66499 \n",
            "valid_loss: 3.77809 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 27/100] \n",
            "train_loss: 2.24833 \n",
            "valid_loss: 3.32688 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 28/100] \n",
            "train_loss: 2.19431 \n",
            "valid_loss: 3.90301 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 29/100] \n",
            "train_loss: 2.10022 \n",
            "valid_loss: 3.41580 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 30/100] \n",
            "train_loss: 2.26868 \n",
            "valid_loss: 3.00350 \n",
            "Validation loss decreased (3.296468 --> 3.003503).  Saving model ...\n",
            "\n",
            "Epoch: [ 31/100] \n",
            "train_loss: 2.10479 \n",
            "valid_loss: 3.12897 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 32/100] \n",
            "train_loss: 2.09077 \n",
            "valid_loss: 3.86657 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 33/100] \n",
            "train_loss: 1.84417 \n",
            "valid_loss: 3.42714 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 34/100] \n",
            "train_loss: 1.90893 \n",
            "valid_loss: 3.09645 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 35/100] \n",
            "train_loss: 1.91517 \n",
            "valid_loss: 3.31787 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "Epoch: [ 36/100] \n",
            "train_loss: 1.97332 \n",
            "valid_loss: 3.47655 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "Epoch: [ 37/100] \n",
            "train_loss: 1.91218 \n",
            "valid_loss: 3.29640 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "Epoch: [ 38/100] \n",
            "train_loss: 1.85812 \n",
            "valid_loss: 4.48124 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "Epoch: [ 39/100] \n",
            "train_loss: 1.61370 \n",
            "valid_loss: 3.91424 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "Epoch: [ 40/100] \n",
            "train_loss: 1.74247 \n",
            "valid_loss: 3.09306 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "Epoch: [ 41/100] \n",
            "train_loss: 1.68597 \n",
            "valid_loss: 2.98385 \n",
            "Validation loss decreased (3.003503 --> 2.983850).  Saving model ...\n",
            "\n",
            "Epoch: [ 42/100] \n",
            "train_loss: 1.81068 \n",
            "valid_loss: 3.52544 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 43/100] \n",
            "train_loss: 1.66814 \n",
            "valid_loss: 2.99084 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 44/100] \n",
            "train_loss: 1.67344 \n",
            "valid_loss: 3.33633 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 45/100] \n",
            "train_loss: 1.70985 \n",
            "valid_loss: 6.97069 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 46/100] \n",
            "train_loss: 1.82961 \n",
            "valid_loss: 5.56200 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "Epoch: [ 47/100] \n",
            "train_loss: 1.78217 \n",
            "valid_loss: 6.38901 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "Epoch: [ 48/100] \n",
            "train_loss: 1.59311 \n",
            "valid_loss: 4.34755 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "Epoch: [ 49/100] \n",
            "train_loss: 1.67510 \n",
            "valid_loss: 3.12173 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "Epoch: [ 50/100] \n",
            "train_loss: 1.93756 \n",
            "valid_loss: 3.30640 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-edd59922357c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-148b4722de77>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_func, batch_size, optimizer, patience, n_epochs, device)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-3a08f172a242>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-3a08f172a242>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mid_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbr_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbr_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbr_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4o3lkBGIOxj"
      },
      "source": [
        "#**Draw Learning Curves**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEkl9xMiIno_"
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 10.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBy1BeytJGel"
      },
      "source": [
        "#**Evaluation using testset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation using validation dataset\n",
        "val_dataset = Create_Datasets(val_set[0], CSV_PATH, val_data_transforms)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 1)\n",
        "\n",
        "def my_round(x, d=0):\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "model.eval() # prep model for evaluation\n",
        "\n",
        "outputs,targets,errors =[], [], []\n",
        "for image_tensor, target in val_loader:  \n",
        "      target = target.view(len(target), 1)         \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model(image_tensor)\n",
        "\n",
        "\n",
        "      outputs.append(output[0].item())      \n",
        "      targets.append(target[0].item())\n",
        "      #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "      errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n"
      ],
      "metadata": {
        "id": "9uZfA263UUhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aMQX9LzJJBC"
      },
      "source": [
        "def my_round(x, d=0):\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "\n",
        "model.eval() # prep model for evaluation\n",
        "\n",
        "outputs,targets,errors =[], [], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      target = target.view(len(target), 1)         \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model(image_tensor)\n",
        "\n",
        "\n",
        "      outputs.append(output[0].item())      \n",
        "      targets.append(target[0].item())\n",
        "      #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "      errors.append(output[0].item()-target[0].item())\n",
        "\n",
        "AbsError = [abs(i) for i in errors]\n",
        "\n",
        "print('AveError: '+str(statistics.mean(errors)))\n",
        "print('StdError: '+str(statistics.stdev(errors)))\n",
        "print('AveAbsError: '+str(statistics.mean(AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(AbsError)))\n",
        "\n",
        "\n",
        "#平均からの差分を補正\n",
        "corrected_output = (np.array(outputs)-np.array(statistics.mean(errors))).tolist()\n",
        "corrected_error = (np.array(corrected_output)-np.array(targets)).tolist()\n",
        "corrected_AbsError = [abs(i) for i in corrected_error]\n",
        "\n",
        "round_output = [my_round(i) for i in outputs]\n",
        "round_corrected_AbsError = [my_round(i) for i in corrected_AbsError]\n",
        "\n",
        "print('Corrected_AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('Corrected_StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lamJcFxkjkxA"
      },
      "source": [
        "#Draw Graphs（もともとの散布図\n",
        "df = pd.DataFrame({'estimate':outputs, 'target':targets})\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='estimate', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSxjXrglZc4k",
        "outputId": "7d99d567-5cb0-4453-d485-b25741013508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "#Bland-Altman-Plot \n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "bland_altman_plot(outputs, targets)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R6aSRMkWEZO"
      },
      "source": [
        "#線形近似式算出\n",
        "from sklearn import linear_model\n",
        "\n",
        "estimate = df.loc[:,'estimate']\n",
        "target = df.loc[:,'target']\n",
        "clf = linear_model.LinearRegression()\n",
        "\n",
        "# 説明変数xに \"x1\"のデータを使用\n",
        "x = np.array([estimate]).T\n",
        "\n",
        "# 目的変数yに \"x2\"のデータを使用\n",
        "y = target.values\n",
        "\n",
        "# 予測モデルを作成（単回帰）\n",
        "clf.fit(x, y)\n",
        "\n",
        "# パラメータ（回帰係数、切片）を抽出\n",
        "[a] = clf.coef_\n",
        "b = clf.intercept_\n",
        "\n",
        "# パラメータの表示\n",
        "print(\"回帰係数:\", a)\n",
        "print(\"切片:\", b)\n",
        "print(\"決定係数:\", clf.score(x, y))\n",
        "\n",
        "#平均値により補正した値\n",
        "df['Corrected_estimate_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,2] = corrected_output[i]\n",
        "\n",
        "#回帰直線により補正した値\n",
        "df['Corrected_estimate_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,3] = df.iloc[i,0]*a+b\n",
        "\n",
        "#残差\n",
        "df['Residual_error_1']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,4] = df.iloc[i,2]-df.iloc[i,1]\n",
        "\n",
        "#残差\n",
        "df['Residual_error_2']=0\n",
        "for i in range(len(df)):\n",
        "    df.iloc[i,5] = df.iloc[i,3]-df.iloc[i,1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlWXLynoKxy",
        "outputId": "ef9eadf8-bb26-47ff-fed9-f4927b9d0fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      estimate  target  Corrected_estimate_1  Corrected_estimate_2  \\\n",
            "0    17.221966    22.0             19.631564             20.248560   \n",
            "1    14.117248    14.0             16.526845             16.232585   \n",
            "2    13.923048    15.0             16.332646             15.981386   \n",
            "3    13.549201    15.0             15.958799             15.497812   \n",
            "4    15.702682    19.0             18.112280             18.283356   \n",
            "..         ...     ...                   ...                   ...   \n",
            "199  12.128220    15.0             14.537817             13.659763   \n",
            "200  15.005243    18.0             17.414841             17.381214   \n",
            "201  12.970710    15.0             15.380308             14.749530   \n",
            "202  16.962021    20.0             19.371619             19.912320   \n",
            "203  17.364050    20.0             19.773648             20.432347   \n",
            "\n",
            "     Residual_error_1  Residual_error_2  \n",
            "0           -2.368436         -1.751440  \n",
            "1            2.526845          2.232585  \n",
            "2            1.332646          0.981386  \n",
            "3            0.958799          0.497812  \n",
            "4           -0.887720         -0.716644  \n",
            "..                ...               ...  \n",
            "199         -0.462183         -1.340237  \n",
            "200         -0.585159         -0.618786  \n",
            "201          0.380308         -0.250470  \n",
            "202         -0.628381         -0.087680  \n",
            "203         -0.226352          0.432347  \n",
            "\n",
            "[204 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiUi44-jGIZ"
      },
      "source": [
        "#平均近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_1'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_1', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_1']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_1'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_1'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x96i5oZDM0dm"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (平均値により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_1']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBFhobtCbv6t"
      },
      "source": [
        "#線形近似バージョン\n",
        "#Draw histogram\n",
        "sns.distplot(\n",
        "    df['Residual_error_2'], bins=13, color='#123456', label='residual_error',\n",
        "    kde=False,\n",
        "    rug=False\n",
        ")\n",
        "plt.legend() # 凡例を表示\n",
        "plt.show()   # ヒストグラムを表示\n",
        "\n",
        "\n",
        "#Draw Graphs\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('gray')\n",
        "sns.lmplot(x='Corrected_estimate_2', y='target', data=df)\n",
        "plt.xlim(10,24)\n",
        "plt.ylim(10,24)\n",
        "\n",
        "corrected_AbsError = [abs(i) for i in df['Residual_error_2']]\n",
        "print('AveError: '+str(statistics.mean(df['Residual_error_2'])))\n",
        "print('StdError: '+str(statistics.stdev(df['Residual_error_2'])))\n",
        "print('AveAbsError: '+str(statistics.mean(corrected_AbsError)))\n",
        "print('StdAbsError: '+str(statistics.stdev(corrected_AbsError)))\n",
        "\n",
        "print('')\n",
        "print('-1<Error<1: '+ str(sum((i < 1 and i > -1 for i in df['Residual_error_2']))))\n",
        "print('-2<Error<2: '+ str(sum((i < 2 and i > -2 for i in df['Residual_error_2']))))\n",
        "print('Error<=-2: ' +  str(sum((i <= -2 for i in df['Residual_error_2']))))\n",
        "print('Error>=2: ' +  str(sum((i >= 2 for i in df['Residual_error_2']))))\n",
        "\n",
        "\n",
        "TP, FP, TN, FN = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]>= 18:\n",
        "        TP += 1\n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]>= 18:\n",
        "        FP += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]< 18:\n",
        "        FN += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]< 18:\n",
        "        TN += 1     \n",
        "\n",
        "print('')\n",
        "print('Hertel 18mm以上の検出精度')\n",
        "print('TP: '+str(TP))\n",
        "print('FP: '+str(FP))\n",
        "print('FN: '+str(FN))\n",
        "print('TN: '+str(TN))\n",
        "print('Sensitivity: '+str(TP/(TP+FN)))\n",
        "print('Specificity: '+str(TN/(FP+TN)))\n",
        "print('Positive predictive value: '+str(TP/(TP+FP)))\n",
        "print('Negative predictive value: '+str(TN/(TN+FN)))\n",
        "\n",
        "\n",
        "okpositive, minogashi, oknegative, kajyou = 0,0,0,0\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,1]>=16 and df.iloc[i,3]> 18:\n",
        "        okpositive += 1\n",
        "    if df.iloc[i,1]<16 and df.iloc[i,3]>= 18:\n",
        "        kajyou += 1\n",
        "    if df.iloc[i,1]>=18 and df.iloc[i,3]<= 16:\n",
        "        minogashi += 1 \n",
        "    if df.iloc[i,1]<18 and df.iloc[i,3]<= 16:\n",
        "        oknegative += 1     \n",
        "\n",
        "print('')\n",
        "print('推測18mm以上だが実は16mm未満(過剰): '+str(kajyou)+'例')\n",
        "print('推測16mm未満だが実は18mm以上（見逃がし）: '+str(minogashi)+'例')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPJMCKTFqFnQ"
      },
      "source": [
        "#Bland-Altman-Plot using corrected value (線形近似により補正)\n",
        "\n",
        "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
        "    data1     = np.asarray(data1)\n",
        "    data2     = np.asarray(data2)\n",
        "    mean      = np.mean([data1, data2], axis=0)\n",
        "    diff      = data1 - data2                   # Difference between data1 and data2\n",
        "    md        = np.mean(diff)                   # Mean of the difference\n",
        "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
        "    plt.scatter(mean, diff, *args, **kwargs)\n",
        "    plt.axhline(md,           color='gray', linestyle='--')\n",
        "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
        "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "corrected_estimate = df.loc[:,'Corrected_estimate_2']\n",
        "target = df.loc[:,'target']\n",
        "\n",
        "bland_altman_plot(corrected_estimate, target)\n",
        "plt.title('Bland-Altman Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}