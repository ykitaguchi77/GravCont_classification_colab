{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled37.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GO extend dataset YOLOv5**"
      ],
      "metadata": {
        "id": "LXR--60tO5mS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xvbecME5IS",
        "outputId": "09eb9ae8-a61f-4efa-c11b-f01f65ce2a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from random import randint\n",
        "from time import sleep\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "# #ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  9 15:59:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZI4pHmFDXZ"
      },
      "source": [
        "#Google colabã‚’ãƒã‚¦ãƒ³ãƒˆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrhEditFGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b90f7a-bad8-44b0-9f31-e48911729719"
      },
      "source": [
        "'''\n",
        "ãƒ»dlibã‚’ç”¨ã„ã¦ç›®ã‚’åˆ‡ã‚ŠæŠœã\n",
        "ãƒ»æ¨ªå¹…ã‚’2å€ã€ç¸¦å¹…ã‚’ä¸Šã«1å€è¿½åŠ /ä¸‹ã«0.5å€è¿½åŠ ã—ãŸä¸¡çœ¼ã®ç”»åƒãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«åˆ‡ã‚Šå–ã‚‹ï¼ˆç›®ã®å…¨å¹…ã€çœ‰æ¯›ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7fAuwXxNka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cd2009-9470-41b2-d6d5-05976d3e8312"
      },
      "source": [
        "#æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ®‹ã‚Šæ™‚é–“ : 11.80"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSA2Rm9MFXoZ"
      },
      "source": [
        "#ãƒ†ã‚¹ãƒˆç”»åƒ\n",
        "test_path = '/content/drive/MyDrive/Deep_learning/Face_Images/IMG_3110.JPG'\n",
        "\n",
        "# GO_extended_datasetã‚’ colabä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€ã«å±•é–‹\n",
        "zip_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip'\n",
        "!unzip $zip_path -d \"/content\"\n",
        "in_path_list  = ['/content/GO_extended_dataset/Control_photo_1886mai', '/content/GO_extended_dataset/treatable']\n",
        "#ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_path_list = ['/content/GO_extended_dataset/cont_for_yolo', '/content/GO_extended_dataset/grav_for_yolo']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2mKFMmwfTOi"
      },
      "source": [
        "#é¡”ã®ç”»åƒã‹ã‚‰ç›®ã‚’æ¤œå‡ºã—ã¦åˆ‡ã‚ŠæŠœãã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n",
        "ãƒ»Haarcascade_eyeã‚’ä½¿ç”¨<br>\n",
        "ãƒ»ç›®ãŒæ¤œå‡ºã§ããªã„ã‚‚ã®ã¯skipã™ã‚‹<br>\n",
        "ãƒ»æ¨ªå¹…ã‚’1/4å€ã€ç¸¦å¹…ã‚’ä¸Šä¸‹ã«1/4å€è¿½åŠ ã—ã¦ç”»åƒã‚’åˆ‡ã‚Šå–ã‚‹ï¼ˆç›®ã®å…¨å¹…ã€çœ‰æ¯›ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n",
        "\n",
        "ãƒ»åˆ‡ã‚Šå–ã£ãŸç”»åƒã‚’æ¨ªå¹…640pxã«resizeã™ã‚‹<br>\n",
        "ãƒ»ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã‚’ä¸€æ‹¬å¤‰æ›ã—ã¦åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0shkziUPn1c"
      },
      "source": [
        "#Haarcascadeã‚’æŒ‡å®š"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfu_RX-kIlmx"
      },
      "source": [
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "# righteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_righteye_2splits.xml'\n",
        "# lefteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_lefteye_2splits.xml'\n",
        "\n",
        "\n",
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ†é¡å™¨ã®ç‰¹å¾´é‡å–å¾—\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# righteye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# lefteye_cascade = cv2.CascadeClassifier(eye_cascade_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãŸã¾ã¾æ¨ªã‚’400pixelã«ç¸®å°ã™ã‚‹\n",
        "def scale_to_width(img, width):\n",
        "    scale = width / img.shape[1]\n",
        "    return cv2.resize(img, dsize=None, fx=scale, fy=scale)\n",
        "\n",
        "#å›³ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "def show_image(img):\n",
        "    #img = cv2.imread(out_path)\n",
        "    dst = scale_to_width(img, 200)\n",
        "    cv2_imshow(dst)\n",
        "\n",
        "# def show_image_pillow(img):\n",
        "#     src = cv2.cvtColor(img_resized_list[0], cv2.COLOR_BGR2RGB)\n",
        "#     plt.imshow(src)\n",
        "\n",
        "def my_round(val, digit=0):\n",
        "    p = 10 ** digit\n",
        "    return int((val * p * 2 + 1) // 2 / p)\n",
        "\n",
        "def scale_to_width(img, width):\n",
        "    \"\"\"å¹…ãŒæŒ‡å®šã—ãŸå€¤ã«ãªã‚‹ã‚ˆã†ã«ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’å›ºå®šã—ã¦ã€ãƒªã‚µã‚¤ã‚ºã™ã‚‹ã€‚\n",
        "    \"\"\"\n",
        "    h, w = img.shape[:2]\n",
        "    height = round(h * (width / w))\n",
        "    dst = cv2.resize(img, dsize=(width, height))\n",
        "\n",
        "    return dst"
      ],
      "metadata": {
        "id": "SMbQsnPTHf-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_bilateral(in_path, class_num, size, showImage=True):\n",
        "    img_resized_list,side_list = [],[]\n",
        "\n",
        "    img = cv2.imread(in_path) \n",
        "    img2 = img.copy()\n",
        "\n",
        "    if showImage:\n",
        "        show_image(img)\n",
        "\n",
        "    # ç”»åƒã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–\n",
        "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    #300pixä»¥ä¸Šã®ã‚‚ã®ã§ç›®ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚’æŠ½å‡º\n",
        "    eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "    print(\"\")\n",
        "    print('image path = ',in_path)\n",
        "\n",
        "    # çœ¼æ¤œå‡ºåˆ¤å®š\n",
        "    if len(eye_list) >= 1:\n",
        "        print('ç›®ãŒ' + str(len(eye_list)) +'å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸ')\n",
        "        pass\n",
        "    else:\n",
        "        print(\"no eye detected\")\n",
        "        pass\n",
        "\n",
        "    print(f\"eye_list: {eye_list}\")\n",
        "\n",
        "    #ç”»åƒã®åˆ‡ã‚ŠæŠœãã¨ä¿å­˜ï¼ˆé€£ç•ªã«ã™ã‚‹ï¼‰\n",
        "    if len(eye_list)== 2: \n",
        "\n",
        "        \n",
        "        for (ex, ey, ew, eh) in eye_list:\n",
        "            print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "            \n",
        "            try:\n",
        "                cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "                #åˆ‡ã‚ŠæŠœãç¯„å›²ãŒå…ƒç”»åƒã‚’ã¯ã¿å‡ºã‚‹å ´åˆã¯é»’ç”»åƒã§åŸ‹ã‚ã‚‹\n",
        "                top = max(0, ey-int(eh/4))\n",
        "                bottom = min(grayscale_img.shape[0], int(ey + eh*5/4))\n",
        "                left = max(0,int(ex-int(ew/4)))\n",
        "                right = min(grayscale_img.shape[1], int(ex + ew*5/4))\n",
        "\n",
        "                #print(f\"top:{top}, bottom:{bottom}, left:{left}, right:{right}\")\n",
        "\n",
        "                img_cropped = img[top: bottom,left:right]\n",
        "                height, width = img_cropped.shape[:2]\n",
        "\n",
        "                #ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã‚’è¡¨ç¤º\n",
        "                if showImage:\n",
        "                    show_image(img_cropped)\n",
        "            except: \n",
        "                pass\n",
        "\n",
        "       \n",
        "        ex = min(eye_list[0][0], eye_list[1][0])\n",
        "        ey = min(eye_list[0][1], eye_list[1][1])\n",
        "        ew = max(eye_list[0][0]+eye_list[0][2], eye_list[1][0]+eye_list[1][2]) - ex\n",
        "        eh = max(eye_list[0][1]+eye_list[0][3], eye_list[1][1]+eye_list[1][3]) - ey\n",
        "\n",
        "        print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "\n",
        "        try:\n",
        "            cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "            #åˆ‡ã‚ŠæŠœãç¯„å›²ãŒå…ƒç”»åƒã‚’ã¯ã¿å‡ºã‚‹å ´åˆã¯é»’ç”»åƒã§åŸ‹ã‚ã‚‹\n",
        "            top = max(0, int(ey-eh/4))\n",
        "            bottom = min(grayscale_img.shape[0], int(ey+7/6*eh))\n",
        "            left = max(0,int(ex-ew/10))\n",
        "            right = min(grayscale_img.shape[1], int(ex + 11/10*ew))\n",
        "\n",
        "            print(f\"top:{top}, bottom:{bottom}, left:{left}, right:{right}\")\n",
        "\n",
        "            img_cropped = img[top: bottom,left:right]\n",
        "            height, width = img_cropped.shape[:2]\n",
        "\n",
        "            img_resized = scale_to_width(img_cropped, size) #1è¾ºã‚’æŒ‡å®šã—ãŸpixã«resize \n",
        "\n",
        "            #ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã‚’è¡¨ç¤º\n",
        "            if showImage:\n",
        "                show_image(img_resized)\n",
        "            print(img2.shape)\n",
        "\n",
        "            #ç¸¦ã€æ¨ªã«å¯¾ã™ã‚‹å‰²åˆ\n",
        "            X = round((right+left)/2/img2.shape[1], 6)\n",
        "            Y = round((top+bottom)/2/img2.shape[0], 6)\n",
        "            W = round((right-left)/img.shape[1], 6)\n",
        "            H = round((bottom-top)/img.shape[0], 6)\n",
        "            txt = f\"{class_num} {X} {Y} {W} {H}\"\n",
        "            return img_resized, txt\n",
        "\n",
        "        except:\n",
        "            print('crop error')\n"
      ],
      "metadata": {
        "id": "aR56JrxipDoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, txt = crop_bilateral(test_path, class_num=0, size=640)\n",
        "print(txt)\n",
        "\n",
        "with open(\"test.txt\", mode='w') as f:\n",
        "    f.write(txt)\n",
        "\n",
        "\n",
        "# #æ¤œå‡ºã•ã‚ŒãŸç”»åƒã‚’ç¢ºèª\n",
        "# src = cv2.cvtColor(img_resized_list[0], cv2.COLOR_BGR2RGB)\n",
        "# plt.imshow(src)\n"
      ],
      "metadata": {
        "id": "sQkblQvvgl9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Aquisition of bounding boxes**\n",
        "\n",
        "ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"
      ],
      "metadata": {
        "id": "Z8R1kiD9lU-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# orig_folder = \"/content/GO_extended_dataset/Control_photo_1886mai\" \n",
        "# dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/cont\"\n",
        "# class_num = 0 #classã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ›¸ãè¾¼ã‚€(0:cont, 1:grav)\n",
        "\n",
        "\n",
        "orig_folder = \"/content/GO_extended_dataset/treatable\" \n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/grav\"\n",
        "class_num = 1 #classã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ›¸ãè¾¼ã‚€(0:cont, 1:grav)\n",
        "\n",
        "path_list = glob.glob(orig_folder+\"/*\")\n",
        "path = path_list[1]\n",
        "path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8gIkLcQWmH9d",
        "outputId": "2288c940-9d4d-4fdd-b40a-fe9376e67bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GO_extended_dataset/treatable/5906-20190509-75-102501_1b7f8b82f6c7c4a016f4dae73d0c91cc3e05404f4cdd6eca55b2b48e4dba2c08.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = glob.glob(orig_folder+\"/*\")\n",
        "#path_list = [path_list[0]] #ãƒ†ã‚¹ãƒˆç”¨\n",
        "dst_folder = dst_folder\n",
        "\n",
        "#å‡¦ç†æ™‚é–“ã®è¨ˆæ¸¬\n",
        "start = time.time()\n",
        "\n",
        "#ã‚‚ã—dst_folderãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦æ–°ã—ãä½œã‚Šç›´ã™\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "os.makedirs(f\"{dst_folder}/images\") #imageæ ¼ç´ç”¨\n",
        "os.makedirs(f\"{dst_folder}/images_cropped\") #cropped_imageæ ¼ç´ç”¨ (YOLOã§ã¯ä½¿ç”¨ã—ãªã„)\n",
        "os.makedirs(f\"{dst_folder}/labels\") #labelæ ¼ç´ç”¨\n",
        "\n",
        "\n",
        "num=0\n",
        "for path in path_list:\n",
        "    try: #ç›®ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼å›é¿\n",
        "        img, txt = crop_bilateral(path, class_num=class_num, size=640, showImage=False)  #ä¸¡çœ¼æŠœãå‡ºã—ã¦640pxã§ä¿å­˜ï¼ˆcropæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã‚‚ã®ã¯å‰Šé™¤ã•ã‚Œã‚‹ï¼‰\n",
        "        img2 = cv2.imread(path).copy()\n",
        "        img2 = scale_to_width(img2, 640)  #åˆ‡ã‚ŠæŠœãå‰ã®ç”»åƒã‚’æ¨ªã®ã‚µã‚¤ã‚ºã‚’640ã«ãªã‚‹ã‚ˆã†ã«ç¸®å°\n",
        "        cv2.imwrite(f\"{dst_folder}/images/{os.path.basename(path).split('.')[0]}.JPG\", img2) #cropã›ãšã«ç¸®å°ã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¿å­˜\n",
        "        cv2.imwrite(f\"{dst_folder}/images_cropped/{os.path.basename(path).split('.')[0]}.JPG\", img) #cropã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹å ´åˆ\n",
        "\n",
        "        with open(f\"{dst_folder}/labels/{os.path.basename(path).split('.')[0]}.txt\", mode='w') as f:\n",
        "            f.write(txt)\n",
        "        num+=1\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"\")\n",
        "print('Process done!!')\n",
        "elapsed_time = time.time() - start\n",
        "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
        "print (f\"image_num:{num}\")\n"
      ],
      "metadata": {
        "id": "R8k494hphZs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLO_v5 trainingç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ**\n",
        "\n",
        "datasetã‚’trainã¨valã«åˆ†ã‘ã‚‹\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/\n",
        "\n"
      ],
      "metadata": {
        "id": "VPi74ZCZrVDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "-----dataset-----train-----images\n",
        "              |         |--labels \n",
        "              |--valid-----images\n",
        "              |         |--labels\n",
        "              |--dataset.yaml\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YiuPobEMYWKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO\"\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testã«åå‰ãŒä¸€è‡´ã™ã‚‹txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠœãå‡ºã™\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "    \n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n",
        "\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")"
      ],
      "metadata": {
        "id": "hHiTlYEnLx_u",
        "outputId": "a5a7abde-c6c0-443b-e15d-c904b1b0f2b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 1657\n",
            "cont: 1656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupKfolds\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "num_folds = 5 #number of folds\n",
        "\n",
        "img_train, img_val, label_train, label_val =  [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)], [[] for i in range(0, num_folds)]\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(cont_image_list, groups=cont_id_idx):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(cont_image_list[idx])\n",
        "        label_train[i].append(cont_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(cont_image_list[idx])\n",
        "        label_val[i].append(cont_label_list[idx])    \n",
        "    i+=1\n",
        "i=0\n",
        "for train_idxs, val_idxs in gkf.split(grav_image_list, groups=grav_id_idx):\n",
        "    for idx in train_idxs:\n",
        "        img_train[i].append(grav_image_list[idx])\n",
        "        label_train[i].append(grav_label_list[idx])\n",
        "    for idx in val_idxs:\n",
        "        img_val[i].append(grav_image_list[idx])\n",
        "        label_val[i].append(grav_label_list[idx])    \n",
        "    i+=1\n",
        "\n",
        "print(f\"img_train: {len(img_train[0])}\")    \n",
        "print(f\"img_val: {len(img_val[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ypkajhq4Yjp",
        "outputId": "9d94aa18-858f-4a27-a212-45a27857f714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_train: 2649\n",
            "img_val: 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv5ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨\n",
        "#ã‚‚ã—dst_folderãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦æ–°ã—ãä½œã‚Šç›´ã™\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\"\n",
        "\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "for i in [\"train\", \"valid\"]:\n",
        "    for j in [\"images\", \"labels\"]:\n",
        "        os.makedirs(f\"{dst_folder}/{i}/{j}\")\n",
        "        #os.makedirs(f\"{dst_folder}/labels\")\n",
        "\n",
        "for file in img_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/images/{os.path.basename(file)}\")\n",
        "for file in img_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/images/{os.path.basename(file)}\")\n",
        "for file in label_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/labels/{os.path.basename(file)}\")            \n",
        "for file in label_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/labels/{os.path.basename(file)}\") \n"
      ],
      "metadata": {
        "id": "lKe9k8SirUGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAUdjy9A0YZw",
        "outputId": "5d8631eb-b096-471d-96c5-0f3913a7ff55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # classåã‚’å®šç¾©"
      ],
      "metadata": {
        "id": "giDFflceMi9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e0bdb6-f54e-47f9-e9f4-413245975212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "cdEoEk_996YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjV_xXLpd5__",
        "outputId": "476d809b-269b-4cd6-a0fe-82f4da46dd53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (12 CPUs, 83.5 GB RAM, 31.0/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train YOLOv5**"
      ],
      "metadata": {
        "id": "shiv0uvTdH7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 640 --batch 16 --epochs 100 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/dataset.yaml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "spn1bRX60hYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1261e6c4-dd82-4034-ed52-e063d58ca44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-01-31 09:30:02.140933: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n",
            "100% 3.87M/3.87M [00:00<00:00, 157MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1      9471  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1766623 parameters, 1766623 gradients, 4.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/labels... 2649 images, 0 backgrounds, 0 corrupt: 100% 2649/2649 [00:05<00:00, 508.53it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/labels... 664 images, 0 backgrounds, 0 corrupt: 100% 664/664 [00:02<00:00, 308.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.70 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      1.91G    0.05312    0.02456     0.0208         30        640: 100% 166/166 [00:22<00:00,  7.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:04<00:00,  4.27it/s]\n",
            "                   all        664        664      0.379      0.639       0.39      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      1.91G    0.03314    0.01597    0.01893         22        640: 100% 166/166 [00:18<00:00,  9.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.53it/s]\n",
            "                   all        664        664      0.468      0.908      0.564      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      1.91G    0.02925    0.01351    0.01724         22        640: 100% 166/166 [00:17<00:00,  9.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.50it/s]\n",
            "                   all        664        664      0.806      0.866      0.898      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      1.91G    0.02538    0.01192    0.01449         24        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
            "                   all        664        664      0.775      0.794      0.831      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      1.91G    0.02223     0.0112    0.01398         27        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.91it/s]\n",
            "                   all        664        664      0.678      0.843      0.867      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      1.91G    0.02158    0.01106     0.0139         27        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.68it/s]\n",
            "                   all        664        664      0.896      0.901      0.942      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      1.91G    0.02025     0.0103    0.01212         27        640: 100% 166/166 [00:17<00:00,  9.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.48it/s]\n",
            "                   all        664        664      0.826      0.873      0.941      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      1.91G    0.01846    0.01032    0.01212         28        640: 100% 166/166 [00:17<00:00,  9.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.56it/s]\n",
            "                   all        664        664      0.907      0.922      0.958      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      1.91G      0.018   0.009884     0.0122         28        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.81it/s]\n",
            "                   all        664        664      0.601      0.705      0.684      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      1.91G    0.01836     0.0099    0.01262         27        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.85it/s]\n",
            "                   all        664        664      0.852      0.902      0.958      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      1.91G    0.01752   0.009799    0.01161         27        640: 100% 166/166 [00:17<00:00,  9.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.884        0.9      0.955      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      1.91G    0.01703   0.009689    0.01201         28        640: 100% 166/166 [00:17<00:00,  9.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
            "                   all        664        664      0.828      0.862      0.932      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      1.91G    0.01723   0.009729    0.01189         20        640: 100% 166/166 [00:17<00:00,  9.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
            "                   all        664        664      0.915      0.924      0.954      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      1.91G    0.01747   0.009538    0.01121         25        640: 100% 166/166 [00:17<00:00,  9.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.853      0.894      0.953      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      1.91G    0.01648   0.009433    0.01169         25        640: 100% 166/166 [00:17<00:00,  9.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.831      0.901      0.947      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      1.91G    0.01665   0.009478    0.01133         29        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
            "                   all        664        664      0.893      0.919      0.964      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      1.91G    0.01621   0.009281    0.01061         29        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.59it/s]\n",
            "                   all        664        664      0.905      0.926      0.971      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      1.91G    0.01611   0.009289    0.01055         23        640: 100% 166/166 [00:17<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.59it/s]\n",
            "                   all        664        664      0.896      0.927      0.972      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      1.91G    0.01644   0.009125    0.01103         29        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.80it/s]\n",
            "                   all        664        664      0.884      0.938      0.965      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      1.91G    0.01543   0.008854    0.01033         26        640: 100% 166/166 [00:17<00:00,  9.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.906      0.914      0.969      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      1.91G    0.01583   0.008897    0.01057         26        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.895      0.942      0.974      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      1.91G    0.01415   0.008979    0.01013         21        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.59it/s]\n",
            "                   all        664        664      0.933      0.935      0.973      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      1.91G    0.01448   0.009125    0.01003         28        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.905       0.96      0.976      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      1.91G    0.01447   0.008803   0.009932         22        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.58it/s]\n",
            "                   all        664        664      0.895      0.914      0.963      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      1.91G    0.01437   0.008833   0.009798         24        640: 100% 166/166 [00:17<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.58it/s]\n",
            "                   all        664        664       0.91       0.95      0.977      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      1.91G    0.01452   0.008891   0.009614         26        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.65it/s]\n",
            "                   all        664        664       0.91      0.913      0.977      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      1.91G     0.0141   0.008641   0.009001         19        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.62it/s]\n",
            "                   all        664        664      0.871      0.973      0.983      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      1.91G    0.01422   0.008863    0.01011         27        640: 100% 166/166 [00:17<00:00,  9.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.53it/s]\n",
            "                   all        664        664      0.822      0.915      0.965      0.757\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      1.91G    0.01415   0.008829     0.0103         27        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
            "                   all        664        664      0.929       0.95      0.979      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      1.91G    0.01344   0.008641   0.009028         23        640: 100% 166/166 [00:17<00:00,  9.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.44it/s]\n",
            "                   all        664        664      0.928      0.944      0.979      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      1.91G    0.01443   0.008515   0.009309         26        640: 100% 166/166 [00:17<00:00,  9.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
            "                   all        664        664      0.911       0.92       0.97      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      1.91G    0.01411   0.008619   0.009714         19        640: 100% 166/166 [00:17<00:00,  9.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
            "                   all        664        664      0.902       0.95      0.976      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      1.91G    0.01389    0.00862   0.009341         25        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
            "                   all        664        664      0.895      0.908      0.977      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      1.91G    0.01388   0.008408   0.009004         29        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.79it/s]\n",
            "                   all        664        664      0.831      0.899      0.947      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      1.91G    0.01315   0.008404   0.008661         28        640: 100% 166/166 [00:17<00:00,  9.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.76it/s]\n",
            "                   all        664        664       0.93      0.926      0.979       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      1.91G    0.01362   0.008414   0.009474         23        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.934      0.925      0.977      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      1.91G     0.0137   0.008387   0.008817         26        640: 100% 166/166 [00:17<00:00,  9.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.90it/s]\n",
            "                   all        664        664       0.92      0.917      0.967       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      1.91G    0.01354   0.008462   0.009194         29        640: 100% 166/166 [00:17<00:00,  9.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.918      0.921      0.979      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      1.91G    0.01314   0.008265    0.00925         25        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.913      0.941      0.969      0.809\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      1.91G    0.01341   0.008396   0.009239         31        640: 100% 166/166 [00:17<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.66it/s]\n",
            "                   all        664        664      0.922      0.928      0.977      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      1.91G    0.01282   0.008312   0.008357         31        640: 100% 166/166 [00:17<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.43it/s]\n",
            "                   all        664        664      0.904      0.953      0.975      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      1.91G    0.01312   0.008268   0.008458         27        640: 100% 166/166 [00:17<00:00,  9.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.93it/s]\n",
            "                   all        664        664      0.935      0.936      0.979      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      1.91G    0.01315   0.008422   0.007996         27        640: 100% 166/166 [00:17<00:00,  9.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
            "                   all        664        664      0.917      0.923      0.976      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      1.91G    0.01298     0.0084   0.008252         25        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.58it/s]\n",
            "                   all        664        664      0.891       0.91       0.97      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      1.91G    0.01305   0.008144   0.008747         26        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.66it/s]\n",
            "                   all        664        664      0.877       0.96      0.976      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      1.91G     0.0129   0.008253   0.008063         27        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
            "                   all        664        664      0.884      0.956      0.973      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      1.91G    0.01342   0.008242   0.009251         21        640: 100% 166/166 [00:17<00:00,  9.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.63it/s]\n",
            "                   all        664        664      0.933      0.931      0.973      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      1.91G    0.01289   0.008237   0.008811         22        640: 100% 166/166 [00:17<00:00,  9.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.59it/s]\n",
            "                   all        664        664      0.931      0.941      0.979      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      1.91G    0.01321   0.008168   0.008809         25        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
            "                   all        664        664      0.946      0.914      0.978       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      1.91G    0.01207   0.008087    0.00777         23        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
            "                   all        664        664      0.871      0.923      0.968      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      1.91G    0.01229   0.008075   0.008802         25        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.72it/s]\n",
            "                   all        664        664      0.942      0.949      0.984      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      1.91G    0.01339   0.008216   0.008693         30        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
            "                   all        664        664      0.925       0.95      0.977      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      1.91G    0.01241   0.008089   0.008131         26        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.72it/s]\n",
            "                   all        664        664      0.944      0.958      0.982      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      1.91G    0.01341   0.008014   0.008492         28        640: 100% 166/166 [00:17<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.946      0.949      0.981       0.83\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      1.91G     0.0125   0.008117   0.008122         22        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.926      0.943       0.98      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      1.91G    0.01299   0.008027    0.00762         27        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.68it/s]\n",
            "                   all        664        664      0.927      0.943      0.977      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      1.91G     0.0123   0.008051   0.007768         26        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.59it/s]\n",
            "                   all        664        664      0.939      0.944      0.979      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      1.91G    0.01238    0.00816   0.008149         21        640: 100% 166/166 [00:17<00:00,  9.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.67it/s]\n",
            "                   all        664        664      0.938      0.946      0.982      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      1.91G    0.01221   0.007963   0.007693         26        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.66it/s]\n",
            "                   all        664        664      0.935      0.947      0.982      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      1.91G    0.01225   0.007868   0.008116         24        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.74it/s]\n",
            "                   all        664        664       0.91      0.941      0.976       0.83\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      1.91G     0.0115   0.007913    0.00695         27        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
            "                   all        664        664      0.941      0.939      0.976       0.83\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      1.91G    0.01244   0.007955   0.007397         21        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.916      0.928      0.972      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      1.91G    0.01228    0.00781     0.0073         25        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.58it/s]\n",
            "                   all        664        664      0.937      0.928      0.973      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      1.91G    0.01209   0.008045   0.008584         25        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.74it/s]\n",
            "                   all        664        664      0.919      0.935      0.973      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      1.91G    0.01217    0.00814   0.007944         33        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.77it/s]\n",
            "                   all        664        664      0.935      0.941      0.976      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      1.91G    0.01186   0.007735   0.007893         23        640: 100% 166/166 [00:17<00:00,  9.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.876      0.922      0.967      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      1.91G     0.0121   0.007864   0.007351         25        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
            "                   all        664        664      0.934      0.955       0.98      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      1.91G    0.01205    0.00788   0.007576         28        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.34it/s]\n",
            "                   all        664        664      0.924      0.953      0.978      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      1.91G    0.01184   0.007792   0.007579         27        640: 100% 166/166 [00:17<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
            "                   all        664        664      0.951      0.953      0.986      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      1.91G    0.01173   0.007783   0.007868         27        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.66it/s]\n",
            "                   all        664        664      0.889      0.928      0.974       0.83\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      1.91G    0.01136   0.007786   0.007072         29        640: 100% 166/166 [00:17<00:00,  9.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.65it/s]\n",
            "                   all        664        664      0.937      0.935      0.977      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      1.91G    0.01174   0.007784   0.007161         25        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.76it/s]\n",
            "                   all        664        664       0.94      0.955      0.982       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      1.91G    0.01187   0.007659   0.007676         24        640: 100% 166/166 [00:17<00:00,  9.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
            "                   all        664        664      0.923      0.953      0.975      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      1.91G    0.01155   0.007871   0.007212         23        640: 100% 166/166 [00:17<00:00,  9.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.61it/s]\n",
            "                   all        664        664      0.946      0.952      0.981      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      1.91G    0.01168    0.00789   0.007564         25        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.63it/s]\n",
            "                   all        664        664      0.928      0.933      0.972      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      1.91G    0.01172   0.007759   0.007225         27        640: 100% 166/166 [00:17<00:00,  9.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
            "                   all        664        664      0.953      0.937      0.976      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      1.91G    0.01161   0.007758   0.006937         27        640: 100% 166/166 [00:17<00:00,  9.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.61it/s]\n",
            "                   all        664        664      0.942      0.937      0.976       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      1.91G    0.01081   0.007746   0.006949         31        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.60it/s]\n",
            "                   all        664        664      0.933       0.94      0.973      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      1.91G    0.01115   0.007726   0.007014         23        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
            "                   all        664        664      0.939      0.948      0.981       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      1.91G    0.01079   0.007587   0.006314         25        640: 100% 166/166 [00:17<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
            "                   all        664        664      0.945      0.951      0.983      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      1.91G    0.01087   0.007717   0.006109         27        640: 100% 166/166 [00:17<00:00,  9.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.78it/s]\n",
            "                   all        664        664      0.936       0.94      0.982       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      1.91G    0.01132   0.007653   0.007145         24        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.68it/s]\n",
            "                   all        664        664      0.943      0.959      0.984      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      1.91G    0.01159   0.007749    0.00737         26        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
            "                   all        664        664       0.93      0.958      0.983      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      1.91G    0.01159   0.007506   0.006489         25        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.70it/s]\n",
            "                   all        664        664      0.936      0.941      0.978      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      1.91G    0.01073   0.007517   0.006596         25        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.76it/s]\n",
            "                   all        664        664      0.936      0.945      0.979      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      1.91G     0.0105   0.007646   0.006193         26        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
            "                   all        664        664      0.941      0.946      0.979      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      1.91G    0.01082   0.007753   0.006447         26        640: 100% 166/166 [00:17<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.63it/s]\n",
            "                   all        664        664      0.937      0.961      0.981       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      1.91G    0.01111   0.007711   0.006343         25        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.73it/s]\n",
            "                   all        664        664      0.948      0.956      0.985      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      1.91G    0.01105   0.007484   0.006723         24        640: 100% 166/166 [00:17<00:00,  9.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.50it/s]\n",
            "                   all        664        664      0.943      0.927      0.975      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      1.91G    0.01085   0.007432    0.00721         24        640: 100% 166/166 [00:17<00:00,  9.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.75it/s]\n",
            "                   all        664        664      0.919      0.948      0.975      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      1.91G    0.01063   0.007593    0.00643         28        640: 100% 166/166 [00:17<00:00,  9.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.74it/s]\n",
            "                   all        664        664      0.938      0.956      0.983      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      1.91G    0.01028   0.007495   0.005539         24        640: 100% 166/166 [00:17<00:00,  9.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664      0.939      0.951      0.981      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      1.91G    0.01065   0.007452   0.006502         26        640: 100% 166/166 [00:17<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.68it/s]\n",
            "                   all        664        664      0.927      0.936      0.975      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      1.91G    0.01083   0.007373   0.006362         25        640: 100% 166/166 [00:17<00:00,  9.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.64it/s]\n",
            "                   all        664        664       0.95      0.941      0.982      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      1.91G     0.0102   0.007557   0.005407         24        640: 100% 166/166 [00:17<00:00,  9.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.69it/s]\n",
            "                   all        664        664      0.942      0.952       0.98      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      1.91G    0.01025    0.00741   0.005452         30        640: 100% 166/166 [00:17<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
            "                   all        664        664      0.934      0.956      0.979      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      1.91G    0.01048   0.007359   0.005772         23        640: 100% 166/166 [00:17<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.71it/s]\n",
            "                   all        664        664      0.952       0.94      0.979      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      1.91G    0.01063   0.007442    0.00605         22        640: 100% 166/166 [00:17<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.76it/s]\n",
            "                   all        664        664      0.945      0.949       0.98       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      1.91G     0.0104   0.007532   0.005701         28        640: 100% 166/166 [00:17<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.55it/s]\n",
            "                   all        664        664      0.946      0.949      0.981      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      1.91G    0.01063   0.007413   0.006232         29        640: 100% 166/166 [00:17<00:00,  9.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:03<00:00,  5.62it/s]\n",
            "                   all        664        664       0.94      0.962      0.982      0.844\n",
            "\n",
            "100 epochs completed in 0.596 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 3.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 3.8MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 21/21 [00:04<00:00,  4.92it/s]\n",
            "                   all        664        664      0.941      0.951       0.98      0.854\n",
            "                  cont        664        332      0.938      0.959       0.98      0.847\n",
            "                  grav        664        332      0.943      0.943      0.981      0.861\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best.pyã‚’renameã—ã¦gdriveã«ç§»å‹•ã—ã¦ãŠã\n",
        "orig_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\"\n",
        "dst_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "shutil.copy(orig_pt, dst_pt)"
      ],
      "metadata": {
        "id": "2_mRrhFn-ONj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "951a6753-9a5b-4e71-e026-7416d32bcc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5 Intereference**"
      ],
      "metadata": {
        "id": "kX9AdOK31h1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference (folderå†…å…¨éƒ¨)\n",
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images"
      ],
      "metadata": {
        "id": "Du5NiwCDdTcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\")\n",
        "train = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\")\n",
        "\n",
        "print(len(train), len(valid))"
      ],
      "metadata": {
        "id": "oA6h6A4u_K7Z",
        "outputId": "430d02b5-7a51-42f0-f012-cd33f4d3178c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2649 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference (per image)\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[100]"
      ],
      "metadata": {
        "id": "jmg05lZkDKnS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt --img 640 --conf 0.25 --source $img"
      ],
      "metadata": {
        "id": "mQxqh5QMDrYR",
        "outputId": "66105c9d-2766-4fff-ef56-107bb88cda87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt'], source=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG: 448x640 1 grav, 18.4ms\n",
            "Speed: 0.7ms pre-process, 18.4ms inference, 38.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "mLCs5mn32MvY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[2]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "id": "54vbyhSR-EY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference Olympia dataset**"
      ],
      "metadata": {
        "id": "uzZr3wMsrxJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "cpKHAnmE_wFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8851aa3-9005-45b4-a358-1afb274dd14d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (12 CPUs, 83.5 GB RAM, 31.0/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "\n",
        "# æ¨ªå¹…ã‚’640pxã«ãƒªã‚µã‚¤ã‚ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "dataset_grav = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "dataset_cont = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/untreated_640px\""
      ],
      "metadata": {
        "id": "CrVmlh1Csdxz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "VPTVErBetQT9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "\n",
        "# calculate coordinates of the bounding box (640*640ã«paddingã•ã‚Œã¦ã„ã‚‹åˆ†ã®åº§æ¨™ã‚’è¶³ã™)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "_NeSLz6rtalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export coreML including non-max supression**"
      ],
      "metadata": {
        "id": "g7JhasvF89PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone Yolov5 repo\n",
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/hietalajulius/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -r requirements-export.txt"
      ],
      "metadata": {
        "id": "E7CfdEw-ylvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\""
      ],
      "metadata": {
        "id": "9uFOe6N9Aiwo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python export-nms.py --include coreml --weights $weight_path\n"
      ],
      "metadata": {
        "id": "tBf-4p1BArEe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}